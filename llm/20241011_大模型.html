<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.15" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>20241011_大模型 | 室内定位技术</title><meta name="description" content="20241011_大模型">
    <link rel="preload" href="/assets/style-DAdpyONk.css" as="style"><link rel="stylesheet" href="/assets/style-DAdpyONk.css">
    <link rel="modulepreload" href="/assets/app-CnelMD4P.js"><link rel="modulepreload" href="/assets/20241011_大模型.html-C-41kfRN.js">
    <link rel="prefetch" href="/assets/index.html-Sc4XVt1e.js" as="script"><link rel="prefetch" href="/assets/商务合作.html-Kzv94wKW.js" as="script"><link rel="prefetch" href="/assets/20240917_大模型.html-BpBv5AgD.js" as="script"><link rel="prefetch" href="/assets/20241004_大模型.html-C2cAYdqy.js" as="script"><link rel="prefetch" href="/assets/20241009_大模型.html-BFXl43Th.js" as="script"><link rel="prefetch" href="/assets/20241010_大模型.html-DZon7tS2.js" as="script"><link rel="prefetch" href="/assets/20241013_大模型.html-CxOMHWtm.js" as="script"><link rel="prefetch" href="/assets/20241016_大模型.html-jQEW77yi.js" as="script"><link rel="prefetch" href="/assets/20241020_大模型.html-Bj7I2H-S.js" as="script"><link rel="prefetch" href="/assets/20241029_大模型.html-BLxcdeGd.js" as="script"><link rel="prefetch" href="/assets/index.html-t4_qCgLN.js" as="script"><link rel="prefetch" href="/assets/20240911_室内定位.html-B_1kQ9Em.js" as="script"><link rel="prefetch" href="/assets/20240916_室内定位.html-D3fRvBQH.js" as="script"><link rel="prefetch" href="/assets/20240920_室内定位.html-DMDp4TkO.js" as="script"><link rel="prefetch" href="/assets/20240925_室内定位.html-DfJTkJur.js" as="script"><link rel="prefetch" href="/assets/20240930_室内定位.html-5hDrqfZe.js" as="script"><link rel="prefetch" href="/assets/20241004_室内定位.html-DAS2ioAc.js" as="script"><link rel="prefetch" href="/assets/20241009_室内定位.html-DmpYC0QM.js" as="script"><link rel="prefetch" href="/assets/20241010_室内定位.html-C9LQKQDH.js" as="script"><link rel="prefetch" href="/assets/20241011_室内定位.html-LNnTZdH1.js" as="script"><link rel="prefetch" href="/assets/20241013_室内定位.html-CSNWv0SP.js" as="script"><link rel="prefetch" href="/assets/20241016_室内定位.html-Ch03dqoU.js" as="script"><link rel="prefetch" href="/assets/20241020_室内定位.html-CvqDg72p.js" as="script"><link rel="prefetch" href="/assets/20241029_室内定位.html-XS3ItuGL.js" as="script"><link rel="prefetch" href="/assets/index.html-QFQB3B5h.js" as="script"><link rel="prefetch" href="/assets/404.html--oR-di-n.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://lark-assets-prod-aliyun.oss-cn-hangzhou.aliyuncs.com/yuque/0/2024/jpeg/354158/1717584738049-5a4ffdae-d469-44a9-b298-f86934b6e14c.jpeg?date=1717585212400" alt="室内定位技术"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">室内定位技术</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">论文列表 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20240917_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20240917_大模型"><!---->20240917_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241004_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241004_大模型"><!---->20241004_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241009_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241009_大模型"><!---->20241009_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241010_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241010_大模型"><!---->20241010_大模型<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/llm/20241011_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241011_大模型"><!---->20241011_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241013_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241013_大模型"><!---->20241013_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241016_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241016_大模型"><!---->20241016_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241020_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241020_大模型"><!---->20241020_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241029_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241029_大模型"><!---->20241029_大模型<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h1 id="理解对话式人工智能系统中的用户意图和上下文" tabindex="-1"><a class="header-anchor" href="#理解对话式人工智能系统中的用户意图和上下文"><span>理解对话式人工智能系统中的用户意图和上下文</span></a></h1><h2 id="研究问题" tabindex="-1"><a class="header-anchor" href="#研究问题"><span>研究问题</span></a></h2><p>如何使对话式AI系统更好地理解和处理用户的意图及上下文，特别是在应对复杂请求或含糊输入时？</p><h2 id="提出方法" tabindex="-1"><a class="header-anchor" href="#提出方法"><span>提出方法</span></a></h2><p>该研究采用定性分析与定量评估相结合的方式。定性部分涉及对现有对话日志进行分析以识别用户和AI助手之间的常见误解和误读，并根据错误类型（例如同音词混淆、上下文理解失误）将这些案例分类。在定量方面，我们开发了一个改进的对话模型，该模型结合了语义角色标注、依存关系解析等高级自然语言处理技术以及基于上下文的对话管理系统。通过诸如理解用户意图的准确性、响应的相关性及用户满意度评分等指标对增强后的模型与基线系统进行评估。</p><h2 id="创新点" tabindex="-1"><a class="header-anchor" href="#创新点"><span>创新点</span></a></h2><ol><li><strong>基于上下文的对话管理</strong>：我们的方法整合了从前一次互动中获取的背景信息，以更好地解释当前请求。</li><li><strong>增强的NLP技术</strong>：采用高级自然语言处理工具有助于解决同音词问题并识别用户查询中的细微差别。</li><li><strong>用户反馈循环</strong>：通过引入持续反馈机制使系统能够根据实际使用模式进行迭代改进。</li></ol><h1 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h1><p>研究表明，通过结合基于上下文的对话管理和增强的NLP技术，对话式AI系统能够在理解和处理复杂或含糊不清的用户输入方面显著提高能力。这将导致更准确和相关性的响应，从而提升整体用户体验满意度。未来的研究应侧重于通过广泛的实际应用及持续反馈收集来完善这些方法。</p><h2 id="原文链接" tabindex="-1"><a class="header-anchor" href="#原文链接"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.01957</p><h1 id="如何利用深度模型进行说话人无关的多说话人语音分离" tabindex="-1"><a class="header-anchor" href="#如何利用深度模型进行说话人无关的多说话人语音分离"><span>如何利用深度模型进行说话人无关的多说话人语音分离？</span></a></h1><h2 id="研究问题-1" tabindex="-1"><a class="header-anchor" href="#研究问题-1"><span>研究问题</span></a></h2><p>如何利用深度模型进行说话人无关的多说话人语音分离？</p><h2 id="提出方法-1" tabindex="-1"><a class="header-anchor" href="#提出方法-1"><span>提出方法</span></a></h2><p>提出了排列不变训练（Permutation Invariant Training，PIT）方法，该方法能够处理任意数量的说话人在未经训练的数据集中的情况。通过优化目标函数使得对于不同说话人的排列组合都能保持一致性能。</p><h2 id="创新点-1" tabindex="-1"><a class="header-anchor" href="#创新点-1"><span>创新点</span></a></h2><ul><li>引入了PIT技术，解决了多说话人语音分离中常见的排列不变性问题。</li><li>使模型在未知的说话人配置下仍能有效工作。</li></ul><h3 id="结论-1" tabindex="-1"><a class="header-anchor" href="#结论-1"><span>结论</span></a></h3><p>该方法成功地提高了多说话人在场景下的声音分离效果，证明了PIT框架的有效性和鲁棒性。</p><h2 id="原文链接-1" tabindex="-1"><a class="header-anchor" href="#原文链接-1"><span>原文链接</span></a></h2><p>https://portal.research.lu.se/files/196591300/IPINwip_ARMPIT_final.pdf</p><h1 id="bubblecam-远程视距协助中的隐私保护" tabindex="-1"><a class="header-anchor" href="#bubblecam-远程视距协助中的隐私保护"><span>BubbleCam：远程视距协助中的隐私保护</span></a></h1><h2 id="研究问题-2" tabindex="-1"><a class="header-anchor" href="#研究问题-2"><span>研究问题：</span></a></h2><ul><li>如何在远程视距协助中解决隐私保护的问题？</li></ul><h2 id="提出方法-2" tabindex="-1"><a class="header-anchor" href="#提出方法-2"><span>提出方法：</span></a></h2><ul><li>开发BubbleCam，一种通过视频通话实现的辅助技术。</li><li>通过对用户行为、交互和反馈的研究来评估其效果。</li></ul><h2 id="创新点-2" tabindex="-1"><a class="header-anchor" href="#创新点-2"><span>创新点：</span></a></h2><ul><li>引入了“气泡过滤”功能，使用户提供者在特定时间段内无法看到用户的周围环境，从而保护隐私。</li><li>用户可以通过手势控制来调整此功能以适应不同情境的需求。</li></ul><h3 id="结论-2" tabindex="-1"><a class="header-anchor" href="#结论-2"><span>结论：</span></a></h3><p>BubbleCam提供了有效的隐私保护措施，同时确保远程视距协助的实用性。研究表明用户对于这一设计感到满意，并且能够通过手势轻松操控隐私过滤功能。</p><hr><h1 id="视觉障碍人群的大规模多模态模型-lmm-辅助新兴实践-对设计的影响" tabindex="-1"><a class="header-anchor" href="#视觉障碍人群的大规模多模态模型-lmm-辅助新兴实践-对设计的影响"><span>视觉障碍人群的大规模多模态模型（LMM）辅助新兴实践：对设计的影响</span></a></h1><h2 id="研究问题-3" tabindex="-1"><a class="header-anchor" href="#研究问题-3"><span>研究问题：</span></a></h2><ul><li>大型多模态模型（LMM）如何有效地辅助视力受损者？</li></ul><h2 id="提出方法-3" tabindex="-1"><a class="header-anchor" href="#提出方法-3"><span>提出方法：</span></a></h2><ul><li>通过用户研究和实验评估，探讨了当前的实践方法。</li><li>分析技术和社会因素对LMM设计的影响。</li></ul><h2 id="创新点-3" tabindex="-1"><a class="header-anchor" href="#创新点-3"><span>创新点：</span></a></h2><ul><li>提出了新的策略以增强LMM在视觉障碍人群中的使用效果。</li><li>强调了伦理考量及隐私保护的重要性。</li></ul><h3 id="结论-3" tabindex="-1"><a class="header-anchor" href="#结论-3"><span>结论：</span></a></h3><p>新兴的技术与实践表明，通过有效的设计和实施，LMM可以显著改善视力受损者的生活质量。然而，也指出了未来研究中需要进一步关注的问题。</p><hr><h1 id="大规模语言模型-llm-时代的人机协作在远程视距辅助中的应用-观点" tabindex="-1"><a class="header-anchor" href="#大规模语言模型-llm-时代的人机协作在远程视距辅助中的应用-观点"><span>大规模语言模型（LLM）时代的人机协作在远程视距辅助中的应用：观点</span></a></h1><h2 id="研究问题-4" tabindex="-1"><a class="header-anchor" href="#研究问题-4"><span>研究问题：</span></a></h2><ul><li>在大规模语言模型（LLM）时代，人与AI合作以提供远程视距协助的最佳实践是什么？</li></ul><h2 id="提出方法-4" tabindex="-1"><a class="header-anchor" href="#提出方法-4"><span>提出方法：</span></a></h2><ul><li>分析了现有技术及其局限性。</li><li>通过用户反馈和案例研究来评估不同协作模式的效果。</li></ul><h2 id="创新点-4" tabindex="-1"><a class="header-anchor" href="#创新点-4"><span>创新点：</span></a></h2><ul><li>探讨了在当前技术框架下改进用户体验的可能性。</li><li>强调了需要综合考虑人机互动中的伦理与社会问题。</li></ul><h3 id="结论-4" tabindex="-1"><a class="header-anchor" href="#结论-4"><span>结论：</span></a></h3><p>研究表明，在LLM的协助下，人类与AI的合作可以更有效地支持远程视距辅助，并且通过合理的设计和应用能够更好地满足用户的实际需求。</p><h2 id="原文链接-2" tabindex="-1"><a class="header-anchor" href="#原文链接-2"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.04005</p><h1 id="标题-大型语言模型与下一代网络技术的融合-综述" tabindex="-1"><a class="header-anchor" href="#标题-大型语言模型与下一代网络技术的融合-综述"><span>标题：大型语言模型与下一代网络技术的融合：综述</span></a></h1><h2 id="研究问题-5" tabindex="-1"><a class="header-anchor" href="#研究问题-5"><span>研究问题：</span></a></h2><p>网络技术的发展极大地改变了全球通信、信息共享和连通性。依赖静态配置和手动干预的传统网络面临着诸如可扩展性差、复杂性增加、安全威胁以及资源利用率低下等重大挑战。</p><h2 id="方法论" tabindex="-1"><a class="header-anchor" href="#方法论"><span>方法论：</span></a></h2><p>本综述文章采用全面分析的方法来研究大型语言模型与下一代网络技术的融合。该研究包括对两个领域近期进展的广泛文献回顾，并识别了能够增强网络能力和效率的关键协同效应。</p><h2 id="创新-贡献" tabindex="-1"><a class="header-anchor" href="#创新-贡献"><span>创新/贡献：</span></a></h2><ol><li>识别将大型语言模型集成到网络基础设施中的潜在应用场景。</li><li>提出解决在网络中部署AI驱动解决方案所面临挑战的框架。</li><li>评估这些融合对网络性能、安全性和可扩展性的影响。</li><li>强调新兴趋势和未来研究与发展方向。</li></ol><h2 id="结论-5" tabindex="-1"><a class="header-anchor" href="#结论-5"><span>结论：</span></a></h2><p>综述得出结论，将大型语言模型集成到下一代网络技术可以显著改善网络管理，提升用户体验，并使通信系统更加智能高效。然而，解决技术挑战并确保强大的安全措施是实现这种融合全部潜力的关键步骤。</p><h2 id="原文链接-3" tabindex="-1"><a class="header-anchor" href="#原文链接-3"><span>原文链接</span></a></h2><p>https://www.mdpi.com/1999-5903/16/10/365</p><h1 id="解决医疗自然语言处理-nlp-中的挑战-最近发展的综述-重点关注数据隐私、概念规范化和模型可解释性" tabindex="-1"><a class="header-anchor" href="#解决医疗自然语言处理-nlp-中的挑战-最近发展的综述-重点关注数据隐私、概念规范化和模型可解释性"><span>解决医疗自然语言处理（NLP）中的挑战：最近发展的综述，重点关注数据隐私、概念规范化和模型可解释性</span></a></h1><h2 id="研究问题-6" tabindex="-1"><a class="header-anchor" href="#研究问题-6"><span>研究问题</span></a></h2><p>本研究旨在探讨近年来在医学自然语言处理（NLP）方面的最新进展，并重点讨论数据隐私问题、概念规范化技术以及提高AI模型可解释性的策略。</p><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><ul><li><strong>数据来源</strong>：使用PubMed、IEEE Xplore、arXiv、GitHub和主要的AI/ML会议记录等数据库进行综合文献回顾。</li><li><strong>搜索策略</strong>：关键词包括“医学NLP”、“医疗健康中的数据隐私”、“概念规范化”、“模型可解释性”，以及相关的同义词。</li><li><strong>纳入标准</strong>：2019年至2024年间发表的，讨论与医学数据隐私、概念规范化技术或提高AI模型可解释性的方法相关的文章。</li><li><strong>PRISMA-ScR检查表</strong>：应用系统评价的方法论和扩展至范畴性综述（PRISMA-ScR）以确保完整性和可靠性。</li></ul><h2 id="创新点-5" tabindex="-1"><a class="header-anchor" href="#创新点-5"><span>创新点</span></a></h2><ol><li><strong>数据隐私技术</strong><ul><li>提出的方法包括通过在训练数据中添加噪声来保护敏感信息的差异隐私技术。</li></ul></li><li><strong>概念规范化方法</strong><ul><li>引入了医学概念规范化（MCN）工具，如MedFilter，这些工具利用语言模型和知识图谱来标准化不同上下文中的医疗概念。</li></ul></li><li><strong>模型可解释性策略</strong><ul><li>使用本体论来解释人工神经网络的决策过程，帮助临床医生理解模型预测。</li></ul></li></ol><h2 id="结论-6" tabindex="-1"><a class="header-anchor" href="#结论-6"><span>结论</span></a></h2><p>近年来在医学自然语言处理（NLP）领域的最新进展解决了数据隐私、概念规范化和模型可解释性的关键问题。这些创新技术的整合有望显著提高医疗信息学水平，为临床应用提供更安全、标准化且易解释的人工智能驱动系统。</p><h2 id="原文链接-4" tabindex="-1"><a class="header-anchor" href="#原文链接-4"><span>原文链接</span></a></h2><p>https://medinform.jmir.org/2024/1/e62924/</p><h1 id="按参数大小和开发实体分类的大规模语言模型比较分析" tabindex="-1"><a class="header-anchor" href="#按参数大小和开发实体分类的大规模语言模型比较分析"><span>按参数大小和开发实体分类的大规模语言模型比较分析</span></a></h1><h2 id="研究问题-7" tabindex="-1"><a class="header-anchor" href="#研究问题-7"><span>研究问题</span></a></h2><p>不同大规模语言模型（LLMs）的性能指标、优化参数及应用领域在以参数大小和开发者身份划分的不同类别中是如何变化的？</p><h2 id="提出方法-5" tabindex="-1"><a class="header-anchor" href="#提出方法-5"><span>提出方法</span></a></h2><ul><li><strong>PRISMA流程图</strong>: 按照系统性回顾的过程，选择与大语言模型相关的研究。</li><li><strong>纳入标准</strong>: 专注于大语言模型的发展、性能评估或应用领域的研究被包含进来。</li><li><strong>数据提取</strong>: 从选定的文章中抽取参数，包括模型大小（参数数量）、开发实体、应用领域和具体性能指标。</li></ul><h2 id="创新点-6" tabindex="-1"><a class="header-anchor" href="#创新点-6"><span>创新点</span></a></h2><ul><li>开发了一个比较分析框架，按参数大小和开发者身份对大语言模型进行分类。</li><li>引入详细的PRISMA流程图，以说明选择研究文献的过程。</li><li>通过关键词搜索全面覆盖各种应用领域，包括医疗、教育、金融等。</li></ul><p>结论: 比较分析揭示了不同类别的大规模语言模型基于参数大小和开发者身份在性能指标方面的显著差异。确定了影响模型效率及多样性领域的适用性的特定优化参数。高光了一些挑战性问题，如黑盒问题、隐私担忧以及安全问题，这些问题需要进一步研究。</p><h2 id="原文链接-5" tabindex="-1"><a class="header-anchor" href="#原文链接-5"><span>原文链接</span></a></h2><p>https://discovery.ucl.ac.uk/id/eprint/10198134/7/Li_preprint-57400-accepted.pdf</p><h1 id="评估大型语言模型在急诊科提供临床建议的适用性" tabindex="-1"><a class="header-anchor" href="#评估大型语言模型在急诊科提供临床建议的适用性"><span>评估大型语言模型在急诊科提供临床建议的适用性</span></a></h1><h2 id="研究问题-8" tabindex="-1"><a class="header-anchor" href="#研究问题-8"><span>研究问题</span></a></h2><p>探究大型语言模型在急诊科提供临床建议的适用性。</p><h2 id="提出方法-6" tabindex="-1"><a class="header-anchor" href="#提出方法-6"><span>提出方法</span></a></h2><ol><li><strong>数据收集</strong>: 使用真实的急诊病例，涵盖不同的病症和情况。</li><li><strong>模型选择与准备</strong>: 选用大型预训练的语言模型，并对其进行微调以适应医疗环境的具体需求。</li><li><strong>实验设计</strong>: 对比医生实际推荐与AI生成建议的一致性及准确性。</li><li><strong>评估指标</strong>: <ul><li>准确率：AI给出的建议是否符合标准医疗指南或专家意见</li><li>效率：相较于传统方法，模型提供建议所需时间长短</li></ul></li><li><strong>用户反馈收集</strong>: 医护人员对使用大型语言模型进行临床决策的看法和体验。</li><li><strong>伦理审查</strong>: 确保所有数据处理遵守了HIPAA法规和其他相关医疗伦理准则。</li></ol><h2 id="创新点-7" tabindex="-1"><a class="header-anchor" href="#创新点-7"><span>创新点</span></a></h2><ul><li>将先进的自然语言处理技术应用于临床决策支持系统中，开拓新的研究领域。</li><li>首次全面评估大型语言模型在急诊科提供即时、个性化医学建议的能力。</li><li>开发了专门针对医疗场景优化的算法和数据集，使AI更贴近实际应用场景。</li></ul><p><strong>结论</strong> 大型语言模型能够显著提高急诊医生制定初步治疗方案的速度与质量。尽管仍存在一些挑战（如确保隐私安全性和防止误导性信息传播），但该技术展现出巨大潜力，在未来有望成为辅助临床决策的重要工具。</p><h2 id="原文链接-6" tabindex="-1"><a class="header-anchor" href="#原文链接-6"><span>原文链接</span></a></h2><p>https://www.nature.com/articles/s41467-024-52415-1</p><h1 id="利用双曲空间增强实用推理-hyplora的实证研究" tabindex="-1"><a class="header-anchor" href="#利用双曲空间增强实用推理-hyplora的实证研究"><span>利用双曲空间增强实用推理：HypLoRA的实证研究</span></a></h1><h2 id="研究问题-9" tabindex="-1"><a class="header-anchor" href="#研究问题-9"><span>研究问题</span></a></h2><p>将双曲空间引入语言模型（HypLoRA）在解决实际推理任务时，相对于传统的欧几里得方法，如何提升其性能？</p><h2 id="方法-1" tabindex="-1"><a class="header-anchor" href="#方法-1"><span>方法</span></a></h2><p>本研究对比了两个语言模型变体——LoRA和HypLoRA。两种模型均通过评估它们解决以文本问题形式呈现的基于算术的推理问题的能力来进行评价。</p><h3 id="评价标准" tabindex="-1"><a class="header-anchor" href="#评价标准"><span>评价标准</span></a></h3><ul><li><strong>准确性</strong>：数值结果的正确性。</li><li><strong>可靠性</strong>：在多次试验中产生正确答案的一致性。</li></ul><h2 id="创新点-8" tabindex="-1"><a class="header-anchor" href="#创新点-8"><span>创新点</span></a></h2><ol><li><strong>双曲空间集成</strong>：利用双曲线几何学更好地表示和处理层次化与关系型数据。</li><li><strong>改进的数值推理能力</strong>：证明了HypLoRA模型在解决算术问题方面具有更高的准确性和可靠性。</li><li><strong>增强的实际应用潜力</strong>：通过克服传统模型的局限性，有望改善现实世界中的问题解决方案。</li></ol><h2 id="结论-7" tabindex="-1"><a class="header-anchor" href="#结论-7"><span>结论</span></a></h2><p>研究表明，HypLoRA在实际推理任务（特别是算术计算）中优于LoRA，这得益于其双曲空间框架能够更好地捕捉此类问题内在的复杂关系。该研究强调了几何考虑因素对于增强语言模型处理复杂数值与关系数据能力的重要性。</p><h2 id="原文链接-7" tabindex="-1"><a class="header-anchor" href="#原文链接-7"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.04010</p><h1 id="标题" tabindex="-1"><a class="header-anchor" href="#标题"><span>标题</span></a></h1><p>统计意义下的近似：关于用Transformer模型模拟Turing机的案例研究</p><h2 id="研究问题-10" tabindex="-1"><a class="header-anchor" href="#研究问题-10"><span>研究问题</span></a></h2><p>如何利用现代的Transformer模型来近似模拟图灵机，并在此过程中探讨其统计上的有意义性？</p><h2 id="方法-2" tabindex="-1"><a class="header-anchor" href="#方法-2"><span>方法</span></a></h2><p>采用了一种新颖的方法，结合统计和机器学习技术来研究大型语言模型（LLM）在近似模拟图灵机方面的潜力。具体来说：</p><ul><li>利用现有的大规模预训练模型进行任务配置。</li><li>使用标准的Turing机作为基准，测试Transformer的有效性和准确性。</li></ul><h2 id="创新点-9" tabindex="-1"><a class="header-anchor" href="#创新点-9"><span>创新点</span></a></h2><p>本文的主要创新包括提出了一种新的方法来评估和利用现代深度学习架构（如Transformer）在模拟经典计算理论中的重要概念——图灵机时的能力。通过这种方法，我们能够更好地理解这些模型的学习和泛化能力，并揭示它们在处理抽象计算问题上的潜力。</p><h3 id="结论-8" tabindex="-1"><a class="header-anchor" href="#结论-8"><span>结论</span></a></h3><p>我们的实验结果显示，基于Transformer的大型语言模型可以有效且准确地近似模拟图灵机器的行为。这种能力不仅扩展了人们对现代深度学习架构的理解，也为未来研究提供了新的方向，探索更多复杂算法和理论计算机科学领域中的潜在应用价值。</p><h2 id="原文链接-8" tabindex="-1"><a class="header-anchor" href="#原文链接-8"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.03170</p><h1 id="通过神经结构编辑-nse-提高模型编辑效率" tabindex="-1"><a class="header-anchor" href="#通过神经结构编辑-nse-提高模型编辑效率"><span>通过神经结构编辑（NSE）提高模型编辑效率</span></a></h1><h2 id="研究问题-11" tabindex="-1"><a class="header-anchor" href="#研究问题-11"><span>研究问题：</span></a></h2><p>如何改进模型编辑技术的效率和有效性，特别是在顺序编辑任务中？</p><h2 id="方法-3" tabindex="-1"><a class="header-anchor" href="#方法-3"><span>方法：</span></a></h2><p>我们提出的方法——神经结构编辑（Neural Structure Editing, NSE），专注于选择性地修改神经元以实现高效的编辑。我们使用GPT2-XL和GPT-J模型，在不同的批处理大小下将该方法与现有的基准方法MEMIT进行比较，以评估顺序编辑任务中的性能。</p><h3 id="包含的步骤" tabindex="-1"><a class="header-anchor" href="#包含的步骤"><span>包含的步骤：</span></a></h3><ol><li><strong>数据集准备</strong>：利用Counterfact和ZSRE数据集来进行模型编辑实验。</li><li><strong>基线实施（MEMIT）</strong>：在各种条件下评估基线方法的性能表现。</li><li><strong>神经结构编辑（NSE）开发</strong>：设计NSE以识别对顺序编辑任务中的事实更新贡献显著的关键神经元。</li><li><strong>性能评估</strong>：评估不同批处理大小下，MEMIT和NSE的有效性和效率。</li></ol><h2 id="创新点-10" tabindex="-1"><a class="header-anchor" href="#创新点-10"><span>创新点：</span></a></h2><ul><li><strong>选择性神经元修改</strong>：通过聚焦关键神经元，旨在减少冗余的修改，从而实现更高效的编辑过程。</li><li><strong>批量尺寸敏感性分析</strong>：详细探讨在顺序编辑任务中，不同批处理大小对模型性能的影响。</li><li><strong>理解辅助视觉示例</strong>：提供来自Counterfact和ZSRE数据集的视觉演示，以帮助理解模型编辑的过程。</li></ul><h2 id="结论-9" tabindex="-1"><a class="header-anchor" href="#结论-9"><span>结论：</span></a></h2><p>我们的研究表明，在各种条件下，神经结构编辑（NSE）在效率和有效性方面显著优于MEMIT。最佳的选择神经元阈值被发现为0.8，导致不同批处理大小下的性能差异最小化。这项工作通过提供一种更具针对性的模型编辑方法，推进了该领域的发展，并为进一步提高神经网络适应性铺平道路。</p><ul><li>红线表示MEMIT性能。</li><li>蓝线表示NSE性能。</li></ul><p>| 选择神经元阈值（p） | Counterfact ZSRE 效率（↑Gen.↑Spe.）↑ 流畅度（↑）一致性（↑）效率（↑）生成质量（↑）具体性（↑）事实准确性（↑） | | --- | --- | --- | --- | --- | --- | --- | --- | --- | | 0.85 | 99.50±0.07 91.28±0.21 77.82±0.25 619.25±0.17 40.82±0.12 96.80±0.14 92.19±0.21 28.14±0.25 | | 0.89 | 99.55±0.06 91.92±0.22 78.96±0.25 620.49±0.16 40.24±0.12 96.87±0.14 91.33±0.22 28.66±0.25 | | 0.75 | 99.45±0.07 91.68±0.22 79.03±0.24 620.42±0.16 40.83±0.12 96.80±0.14 91.66±0.22 27.68±0.25 |</p><p><em>图8：ZsRE数据集的一个样本</em></p><h2 id="原文链接-9" tabindex="-1"><a class="header-anchor" href="#原文链接-9"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.04045</p><h1 id="基于大型语言模型的罕见病表型分析混合框架" tabindex="-1"><a class="header-anchor" href="#基于大型语言模型的罕见病表型分析混合框架"><span>基于大型语言模型的罕见病表型分析混合框架</span></a></h1><h2 id="研究问题-12" tabindex="-1"><a class="header-anchor" href="#研究问题-12"><span>研究问题</span></a></h2><p>如何有效地将大型语言模型（LLMs）整合到混合框架中，以改进基于电子健康记录（EHRs）的罕见疾病表型分析？</p><h2 id="方法-4" tabindex="-1"><a class="header-anchor" href="#方法-4"><span>方法</span></a></h2><ul><li>结合使用大型语言模型（LLMs）和自然语言处理（NLP）技术。</li><li>开发了一个混合框架，利用了LLMs 和传统NLP方法的优势来从EHRs中提取表型信息。</li></ul><h2 id="创新点-11" tabindex="-1"><a class="header-anchor" href="#创新点-11"><span>创新点</span></a></h2><ul><li>提出了一种新颖的方法，通过结合尖端的LLM技术和现有的NLP方法，增强了罕见疾病识别的准确性。</li><li>使用高级语言模型提升了处理复杂且模糊的医学文本的能力，这些常见于罕见病案例中。</li></ul><h2 id="结论-10" tabindex="-1"><a class="header-anchor" href="#结论-10"><span>结论</span></a></h2><p>与传统方法相比，该混合框架在罕见疾病的表型分析方面表现出显著改进。大型语言模型和自然语言处理技术的集成提供了一条更准确、更高效地从EHRs中提取临床信息的新途径。</p><h2 id="原文链接-10" tabindex="-1"><a class="header-anchor" href="#原文链接-10"><span>原文链接</span></a></h2><p>https://link.springer.com/article/10.1186/s12911-024-02698-7</p><h1 id="标题-1" tabindex="-1"><a class="header-anchor" href="#标题-1"><span>标题：</span></a></h1><p>HumanML3D：用于运动-语言理解的大规模数据集</p><h2 id="研究问题-13" tabindex="-1"><a class="header-anchor" href="#研究问题-13"><span>研究问题：</span></a></h2><p>该研究主要探讨如何使用大规模数据集（如HumanML3D）来训练能够理解和生成符合文本描述的人体动作序列的模型，并且探索不同的损失计算策略以及运动量化方法对模型性能的影响。</p><h2 id="提出方法-7" tabindex="-1"><a class="header-anchor" href="#提出方法-7"><span>提出方法：</span></a></h2><ol><li>数据准备：使用HumanML3D数据集，包含多样的人体动作和相应的自然语言描述。</li><li>模型架构：基于大语言模型（LLM），结合文本编码器和动作解码器，通过Transformer架构进行训练。</li><li>预训练：在大规模语料库上预训练模型以增强其对文本的理解能力。</li><li>损失计算策略： <ul><li>使用输出运动令牌来计算损失</li><li>采用混合方式，即同时使用输入的文本和生成的运动序列来计算损失</li></ul></li><li>运动量化：通过1D-LFQ和2D-LFQ两种方法进行运动数据的量化处理，并比较它们在不同基准上的表现。</li></ol><h2 id="创新点-12" tabindex="-1"><a class="header-anchor" href="#创新点-12"><span>创新点：</span></a></h2><ul><li>提出了一个大规模的人体动作-语言理解的数据集（HumanML3D）以推动相关研究的发展。</li><li>在预训练阶段使用文本先驱技术来提高模型对描述的理解能力以及跨任务泛化性能。</li><li>探索并验证了混合损失计算策略的有效性，该策略能够更好地防止灾难性遗忘现象，并有助于减轻过拟合问题。</li><li>通过引入二维量化方法在LFQ中显著提高了人体动作序列的表征能力。</li></ul><h2 id="结论-11" tabindex="-1"><a class="header-anchor" href="#结论-11"><span>结论：</span></a></h2><p>实验结果表明，与单一使用运动令牌相比，结合文本和运动令牌进行损失计算可以提高模型性能。此外，在较大的数据集上（例如Motion-X），我们的运动量化器优于其他方法，显示出更好的泛化能力和建模复杂动作模式的能力。</p><h2 id="原文链接-11" tabindex="-1"><a class="header-anchor" href="#原文链接-11"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.03311</p><h1 id="标题-2" tabindex="-1"><a class="header-anchor" href="#标题-2"><span>标题：</span></a></h1><p>迈向集体超级智能：利用对话群集放大团队IQ</p><h2 id="研究问题-14" tabindex="-1"><a class="header-anchor" href="#研究问题-14"><span>研究问题：</span></a></h2><p>如何通过利用对话群集智能（CSI）来增强复杂问题解决场景中的群体表现和见解？</p><h2 id="提出方法-8" tabindex="-1"><a class="header-anchor" href="#提出方法-8"><span>提出方法：</span></a></h2><p>该研究通过开发一项试点研究进行，旨在应用对话群集智能（CSI）原则。参与者使用专门设计的软件工具参与结构化对话，这些工具旨在促进类似于自然群集或集体有机体中观察到的动态互动模式。方法涉及测量诸如洞察生成速度和问题理解深度等群体绩效指标。</p><h2 id="创新点-13" tabindex="-1"><a class="header-anchor" href="#创新点-13"><span>创新点：</span></a></h2><p>关键创新在于在协作人类互动中整合人工智能以创建一个对话群集系统，该系统通过智能对话动力学最大化个体的独特优势，从而使团队更有效地实现集体目标。这种方法允许快速综合各种想法、加速决策过程，并提高适应不断变化条件的能力。</p><h2 id="结论-12" tabindex="-1"><a class="header-anchor" href="#结论-12"><span>结论：</span></a></h2><p>初步研究结果表明，利用CSI显著提高了群体应对复杂挑战的能力，通过创造一个环境来发挥个人独特的优势。结果预示着在商业战略、科学研究和社会问题解决等各个领域实现集体超级智能的一个有希望的途径。为了进一步完善技术并充分理解其对团队动态和绩效指标的长期影响，还需要进行更多的研究。</p><p>DOI: 10.5220/001268750000369</p><h2 id="原文链接-12" tabindex="-1"><a class="header-anchor" href="#原文链接-12"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.03690</p><h1 id="用于提高co2吸附容量的金属有机框架-mofs-中有机连接体的人机逆向设计" tabindex="-1"><a class="header-anchor" href="#用于提高co2吸附容量的金属有机框架-mofs-中有机连接体的人机逆向设计"><span>用于提高CO2吸附容量的金属有机框架(MOFs)中有机连接体的人机逆向设计</span></a></h1><h2 id="研究问题-15" tabindex="-1"><a class="header-anchor" href="#研究问题-15"><span>研究问题</span></a></h2><p>我们如何在分子量限制和避免潜在不稳定官能团的前提下，通过迭代设计优化MOF中的有机连接体以增强其CO2吸附容量？</p><h2 id="方法-5" tabindex="-1"><a class="header-anchor" href="#方法-5"><span>方法</span></a></h2><p>研究采用了闭合回路逆向设计方法，利用由GPT-4o驱动的AI系统dZiner。从初始有机连接体出发，在AI系统的建议下进行化学改性，并与人类设计师合作验证这些改性。整个过程旨在最大化CO2吸附容量的同时，将分子量控制在600 g/mol以下并避免使用硝基、氯代、氟胺等官能团。</p><h2 id="创新点-14" tabindex="-1"><a class="header-anchor" href="#创新点-14"><span>创新点</span></a></h2><ol><li><strong>人机协作</strong>: 研究展示了化学家与AI系统合作进行材料设计的有效性。</li><li><strong>逆向设计能力</strong>: 展示了通过迭代化学改性并在计算预测指导下实现预期材料性能的能力。</li><li><strong>约束处理</strong>: 在设计过程中有效地平衡CO2吸附容量和分子量等多个约束条件。</li></ol><h2 id="结论-13" tabindex="-1"><a class="header-anchor" href="#结论-13"><span>结论</span></a></h2><p>使用dZiner的迭代逆向设计方案显著提高了MOF有机连接体的CO2吸附能力（提高75%），并遵守了分子质量和稳定性指导原则。AI与人类专家的合作证明非常有效，暗示在材料科学创新领域具有广泛的应用潜力。</p><h2 id="原文链接-13" tabindex="-1"><a class="header-anchor" href="#原文链接-13"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.03963</p><h1 id="llm-planner-基于场景的少样本规划方法-用于实体代理中的大型语言模型" tabindex="-1"><a class="header-anchor" href="#llm-planner-基于场景的少样本规划方法-用于实体代理中的大型语言模型"><span>Llm-planner: 基于场景的少样本规划方法，用于实体代理中的大型语言模型</span></a></h1><h2 id="研究问题-16" tabindex="-1"><a class="header-anchor" href="#研究问题-16"><span>研究问题：</span></a></h2><p>如何利用大型语言模型为实体代理提供基于场景的规划能力。</p><h2 id="提出方法-9" tabindex="-1"><a class="header-anchor" href="#提出方法-9"><span>提出方法：</span></a></h2><p>提出了一种名为LLM-Planner的方法，该方法使用大型语言模型执行少样本任务，在给定环境中生成和执行指令序列以实现任务规划。此方法包含两个阶段：（1）从预训练的语言模型中提取有关环境的知识；（2）利用提取到的知识进行目标导向的任务规划。</p><h2 id="创新点-15" tabindex="-1"><a class="header-anchor" href="#创新点-15"><span>创新点：</span></a></h2><ul><li>将大型语言模型应用于实体代理，实现了基于场景的少样本规划。</li><li>提出了一种新颖的方法来使用语言模型中的知识来进行有效的任务规划和执行。</li></ul><h3 id="结论-14" tabindex="-1"><a class="header-anchor" href="#结论-14"><span>结论：</span></a></h3><p>实验结果显示，LLM-Planner在多项基准测试中超越了现有方法的表现。这项工作证明了将大型语言模型与实体环境相结合可以实现更加灵活且适应性强的任务规划能力。</p><hr><p>请注意：原始论文通常包含背景、相关研究、实验设置、结果和讨论等详细部分。以上总结基于提供的引文，可能未能涵盖原论文的所有方面。</p><p>在翻译过程中，我尽力保持了原文的学术严谨性和术语准确性，并保留了Markdown格式以确保结构清晰。</p><h2 id="原文链接-14" tabindex="-1"><a class="header-anchor" href="#原文链接-14"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2410.02823</p><h1 id="通过桌面演练评估ai系统安全中的红队技术" tabindex="-1"><a class="header-anchor" href="#通过桌面演练评估ai系统安全中的红队技术"><span>通过桌面演练评估AI系统安全中的红队技术</span></a></h1><h2 id="研究问题-17" tabindex="-1"><a class="header-anchor" href="#研究问题-17"><span>研究问题</span></a></h2><p>在桌面演练中，红队技术在识别人工智能系统的漏洞方面的有效性如何？</p><h2 id="方法-6" tabindex="-1"><a class="header-anchor" href="#方法-6"><span>方法</span></a></h2><p>本研究旨在采用政府、行业合作伙伴和学术研究人员之间的合作方式，设计并开展模拟真实世界场景的桌面演练。重点将放在评估美国国家标准与技术研究院（NIST）和MITRE等实体开发的人工智能风险管理框架（RMF）的有效性上。参与者来自不同背景，将在MITRE ATLAS平台上进行模拟攻击和防御策略的应用。关键要素包括情景开发、角色扮演以及演练后的分析，以评估人工智能系统在潜在威胁面前的韧性。</p><h2 id="创新点-16" tabindex="-1"><a class="header-anchor" href="#创新点-16"><span>创新点</span></a></h2><p>主要创新在于将红队实践与人工智能力量管理框架相结合，创建了一种全面的方法来评估AI系统的安全漏洞。此外，利用MITRE ATLAS等平台确保参与者能够模拟现实中的威胁场景，并有效评估防御措施的效果。</p><h2 id="结论-15" tabindex="-1"><a class="header-anchor" href="#结论-15"><span>结论</span></a></h2><p>红队演练为人工智能系统在面临实际网络攻击时的潜在弱点提供了关键洞察。通过纳入NIST等行业制定的人工智能特定风险管理体系框架，这些模拟提供了一种增强不同领域（如医疗保健、金融和国家国防）安全协议的有效方法。未来的研究应该侧重于将此类模型扩展到包括自动评估工具（如Dioptra），从而实现对人工智能系统韧性的持续评估。</p><h2 id="原文链接-15" tabindex="-1"><a class="header-anchor" href="#原文链接-15"><span>原文链接</span></a></h2><p>https://cset.georgetown.edu/wp-content/uploads/CSET-Securing-Critical-Infrastructure-in-the-Age-of-AI.pdf</p><h1 id="多模态情境分析-musa-用于分析扩展现实中的对话" tabindex="-1"><a class="header-anchor" href="#多模态情境分析-musa-用于分析扩展现实中的对话"><span>多模态情境分析（MuSA）用于分析扩展现实中的对话</span></a></h1><h2 id="研究问题-18" tabindex="-1"><a class="header-anchor" href="#研究问题-18"><span>研究问题</span></a></h2><p>如何在沉浸式环境中再现多模态交互以进行探索和分析？</p><h2 id="提出方法-10" tabindex="-1"><a class="header-anchor" href="#提出方法-10"><span>提出方法</span></a></h2><p>我们的开发流程包括以下阶段：</p><ol><li>数据采集</li><li>数据清理</li><li>数据同步</li><li>原型构建</li><li>部署到终端用户硬件</li></ol><p>我们进行了两项全面的用户研究，评估使用我们的应用程序在多模态对话探索中的可用性、用户采用和空间使用情况。</p><h2 id="创新点-17" tabindex="-1"><a class="header-anchor" href="#创新点-17"><span>创新点</span></a></h2><p>MuSA（多模态情境分析）是一种沉浸式环境原型设计，用于再现扩展现实环境中进行多模态对话的探索和分析。它将对话中使用的所有模式整合到一个沉浸式的设置中，通过情境化分析以展示数据及其空间和时间参考。</p><h2 id="结论-16" tabindex="-1"><a class="header-anchor" href="#结论-16"><span>结论</span></a></h2><p>在第一项用户研究中，我们探讨了12名坐姿参与者的对话（n=12）。在第二项研究中，我们考察了13名非坐姿移动参与者的对话（n=13）。</p><p>在开发阶段获得了关键的洞察，并从这两项用户研究中收集了实证结果和反馈。这些发现表明MuSA为分析扩展现实环境中的多模态对话提供了一种新颖的方法。</p><h2 id="原文链接-16" tabindex="-1"><a class="header-anchor" href="#原文链接-16"><span>原文链接</span></a></h2><p>https://indigo.uic.edu/articles/thesis/Multimodal_Situated_Analytics_MuSA_for_Analyzing_Conversations_in_Extended_Reality/27152562</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: zhangleilikejay@gmail.com">zhanglei</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/llm/20241010_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241010_大模型"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>20241010_大模型</span></div></a><a class="route-link auto-link next" href="/llm/20241013_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241013_大模型"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>20241013_大模型</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CnelMD4P.js" defer></script>
  </body>
</html>
