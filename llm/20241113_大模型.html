<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.15" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>20241113_大模型 | 室内定位技术</title><meta name="description" content="20241113_大模型">
    <link rel="preload" href="/assets/style-CQdWRPUu.css" as="style"><link rel="stylesheet" href="/assets/style-CQdWRPUu.css">
    <link rel="modulepreload" href="/assets/app-BenbKM8H.js"><link rel="modulepreload" href="/assets/20241113_大模型.html-E6cDhSfR.js">
    <link rel="prefetch" href="/assets/index.html-DssLvV5Z.js" as="script"><link rel="prefetch" href="/assets/商务合作.html-bfR7RPmY.js" as="script"><link rel="prefetch" href="/assets/20240917_大模型.html-B_sR8Elq.js" as="script"><link rel="prefetch" href="/assets/20241004_大模型.html-BpCPy7b3.js" as="script"><link rel="prefetch" href="/assets/20241009_大模型.html-Dx5akT4w.js" as="script"><link rel="prefetch" href="/assets/20241010_大模型.html-D2qw6j_R.js" as="script"><link rel="prefetch" href="/assets/20241011_大模型.html-INDPxorb.js" as="script"><link rel="prefetch" href="/assets/20241013_大模型.html-D7EhCXav.js" as="script"><link rel="prefetch" href="/assets/20241016_大模型.html-C1cmHuU6.js" as="script"><link rel="prefetch" href="/assets/20241020_大模型.html-Cn4_2241.js" as="script"><link rel="prefetch" href="/assets/20241029_大模型.html-Cc1jyZWy.js" as="script"><link rel="prefetch" href="/assets/20241103_大模型.html-Dx10vw4f.js" as="script"><link rel="prefetch" href="/assets/20241104_大模型.html-CeVb7OhC.js" as="script"><link rel="prefetch" href="/assets/20241109_大模型.html-BSw7dp9k.js" as="script"><link rel="prefetch" href="/assets/20241111_大模型.html-ChlZSf1w.js" as="script"><link rel="prefetch" href="/assets/20241117_大模型.html-Csim9MLF.js" as="script"><link rel="prefetch" href="/assets/20241122_大模型.html-CPbpiRNx.js" as="script"><link rel="prefetch" href="/assets/index.html-DL3QffyL.js" as="script"><link rel="prefetch" href="/assets/20240911_室内定位.html-GkAjOvEg.js" as="script"><link rel="prefetch" href="/assets/20240916_室内定位.html-z_uG6L5m.js" as="script"><link rel="prefetch" href="/assets/20240920_室内定位.html-BtCbOv1m.js" as="script"><link rel="prefetch" href="/assets/20240925_室内定位.html-TONr5SoP.js" as="script"><link rel="prefetch" href="/assets/20240930_室内定位.html-Ca4iBdCK.js" as="script"><link rel="prefetch" href="/assets/20241004_室内定位.html-UBJDx4zV.js" as="script"><link rel="prefetch" href="/assets/20241009_室内定位.html-wJDC3sA9.js" as="script"><link rel="prefetch" href="/assets/20241010_室内定位.html-Dt7VH3hW.js" as="script"><link rel="prefetch" href="/assets/20241011_室内定位.html-B5nWKDOc.js" as="script"><link rel="prefetch" href="/assets/20241013_室内定位.html-B0Y3oPzz.js" as="script"><link rel="prefetch" href="/assets/20241016_室内定位.html-B9LfMPX1.js" as="script"><link rel="prefetch" href="/assets/20241020_室内定位.html-CJhScUNw.js" as="script"><link rel="prefetch" href="/assets/20241029_室内定位.html-B45g8CjF.js" as="script"><link rel="prefetch" href="/assets/20241103_室内定位.html-DB8zGecn.js" as="script"><link rel="prefetch" href="/assets/20241104_室内定位.html-PEgkFUr5.js" as="script"><link rel="prefetch" href="/assets/20241109_室内定位.html-D_dH-VL-.js" as="script"><link rel="prefetch" href="/assets/20241111_室内定位.html-0i9spvY7.js" as="script"><link rel="prefetch" href="/assets/20241113_室内定位.html-2WwhvAvg.js" as="script"><link rel="prefetch" href="/assets/20241117_室内定位.html-jGRI0AEG.js" as="script"><link rel="prefetch" href="/assets/20241122_室内定位.html-CJ-A0XB3.js" as="script"><link rel="prefetch" href="/assets/index.html-DGdW-kPe.js" as="script"><link rel="prefetch" href="/assets/404.html-BmeNmkSj.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://lark-assets-prod-aliyun.oss-cn-hangzhou.aliyuncs.com/yuque/0/2024/jpeg/354158/1717584738049-5a4ffdae-d469-44a9-b298-f86934b6e14c.jpeg?date=1717585212400" alt="室内定位技术"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">室内定位技术</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">论文列表 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20240917_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20240917_大模型"><!---->20240917_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241004_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241004_大模型"><!---->20241004_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241009_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241009_大模型"><!---->20241009_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241010_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241010_大模型"><!---->20241010_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241011_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241011_大模型"><!---->20241011_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241013_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241013_大模型"><!---->20241013_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241016_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241016_大模型"><!---->20241016_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241020_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241020_大模型"><!---->20241020_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241029_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241029_大模型"><!---->20241029_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241103_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241103_大模型"><!---->20241103_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241104_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241104_大模型"><!---->20241104_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241109_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241108_大模型"><!---->20241108_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241111_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241111_大模型"><!---->20241111_大模型<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/llm/20241113_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241113_大模型"><!---->20241113_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241117_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241117_大模型"><!---->20241117_大模型<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/20241122_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241122_大模型"><!---->20241122_大模型<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h1 id="利用自然语言处理筛查抑郁症-文献综述" tabindex="-1"><a class="header-anchor" href="#利用自然语言处理筛查抑郁症-文献综述"><span>利用自然语言处理筛查抑郁症：文献综述</span></a></h1><h2 id="关键词" tabindex="-1"><a class="header-anchor" href="#关键词"><span>关键词</span></a></h2><p>自然语言处理, 抑郁症筛查, 机器学习模型, 文本分类</p><h2 id="研究问题" tabindex="-1"><a class="header-anchor" href="#研究问题"><span>研究问题</span></a></h2><p>如何利用自然语言处理技术提高抑郁症的早期识别和诊断效果？</p><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><p>通过系统性地回顾相关文献，本文总结了近年来在自然语言处理领域用于抑郁症筛查的研究进展。研究内容涵盖了文本预处理、特征提取以及机器学习模型的选择与应用。</p><h2 id="创新点" tabindex="-1"><a class="header-anchor" href="#创新点"><span>创新点</span></a></h2><p>探讨了如何将最新的大规模语言模型（LLM）技术应用于抑郁症的诊断和治疗，并强调了文化敏感性的重要性，以确保算法的普适性和公正性。</p><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>通过自然语言处理技术的应用，尤其是结合深度学习方法，可以显著提高抑郁症筛查系统的准确率。然而，还需进一步解决数据隐私保护、模型解释性和跨文化应用等问题。</p><h2 id="原文链接" tabindex="-1"><a class="header-anchor" href="#原文链接"><span>原文链接</span></a></h2><p>https://www.i-jmr.org/2024/1/e55067/PDF</p><h1 id="声音中的非正常ai语音-与规范性ai语音和语言技术的非常规音乐互动" tabindex="-1"><a class="header-anchor" href="#声音中的非正常ai语音-与规范性ai语音和语言技术的非常规音乐互动"><span>声音中的非正常AI语音：与规范性AI语音和语言技术的非常规音乐互动</span></a></h1><h2 id="关键词-1" tabindex="-1"><a class="header-anchor" href="#关键词-1"><span>关键词</span></a></h2><p>非正常声音, AI 语音技术, 音乐创作, 自动语音识别模型</p><h2 id="研究问题-1" tabindex="-1"><a class="header-anchor" href="#研究问题-1"><span>研究问题</span></a></h2><p>如何通过非正常的语音手势进行音乐创作，并利用自动语音识别模型将这些手势翻译成不同语言？</p><h2 id="方法-1" tabindex="-1"><a class="header-anchor" href="#方法-1"><span>方法</span></a></h2><ol><li>收集各种非常规的语音手势录音。</li><li>使用SpeechBrain ASR模型对上述录音进行转录，生成文本数据。</li><li>将生成的文本数据翻译成不同的语言版本。</li></ol><h2 id="创新点-1" tabindex="-1"><a class="header-anchor" href="#创新点-1"><span>创新点</span></a></h2><p>首次尝试将非正常的语音手势应用于音乐创作领域，并利用自动语音识别技术将其转换为不同语言的文本和音声形式。</p><h2 id="结论-1" tabindex="-1"><a class="header-anchor" href="#结论-1"><span>结论</span></a></h2><p>通过非正常的声音手势可以产生新的音乐表现方式，同时也揭示了AI语音技术在处理非常规声音时的能力与局限性。</p><h2 id="原文链接-1" tabindex="-1"><a class="header-anchor" href="#原文链接-1"><span>原文链接</span></a></h2><p>https://research.chalmers.se/publication/543546/file/543546_Fulltext.pdf</p><h1 id="适用于视觉问答的可学习上下文向量-live" tabindex="-1"><a class="header-anchor" href="#适用于视觉问答的可学习上下文向量-live"><span>适用于视觉问答的可学习上下文向量（LIVE）</span></a></h1><h2 id="关键词-2" tabindex="-1"><a class="header-anchor" href="#关键词-2"><span>关键词</span></a></h2><p>在-context 学习，多模态</p><h2 id="研究问题-2" tabindex="-1"><a class="header-anchor" href="#研究问题-2"><span>研究问题</span></a></h2><p>随着大规模语言模型的发展，在-context 学习技术被广泛应用于解决各类任务。然而，应用该技术时面临两大主要挑战：一是使用更多上下文实例会显著增加推理时间；二是性能对上下文实例的选择敏感度高。这些问题在多模态环境下尤为突出。</p><h2 id="方法-2" tabindex="-1"><a class="header-anchor" href="#方法-2"><span>方法</span></a></h2><p>为了解决上述问题，一些研究引入了非学习型的上下文向量（ICVs），将从上下文中提取到的任务相关信息压缩成单一向量，并插入大规模语言模型以帮助解决特定任务。然而，在处理复杂的视觉问答等多模态任务时，这些方法效果有限。本文提出了一种可学习的在-context 向量（LIVE）机制，通过提炼关键任务信息来提升多模态模型中的在-context 学习性能。</p><h2 id="创新点-2" tabindex="-1"><a class="header-anchor" href="#创新点-2"><span>创新点</span></a></h2><ol><li>提出了一种适用于复杂视觉问答任务的新颖且有效的技术：可学习上下文向量（LIVE）。</li><li>LIVE 方法能显著降低计算成本，并提高在视觉问答任务中的准确度，相较于传统的方法和其他非学习型上下文方法有明显优势。</li></ol><h2 id="结论-2" tabindex="-1"><a class="header-anchor" href="#结论-2"><span>结论</span></a></h2><p>本文的研究成果表明，通过引入可学习的上下文向量（LIVE），能够有效解决多模态环境下的在-context 学习挑战。相比现有技术，该方法不仅显著减少计算成本，还提高了任务准确度，在视觉问答等复杂多模态任务上展现出了极大的潜力。</p><h2 id="原文链接-2" tabindex="-1"><a class="header-anchor" href="#原文链接-2"><span>原文链接</span></a></h2><p>https://openreview.net/forum?id=QhRemVrZbG</p><h1 id="评估大型语言模型在病理信息学中的组织准备情况" tabindex="-1"><a class="header-anchor" href="#评估大型语言模型在病理信息学中的组织准备情况"><span>评估大型语言模型在病理信息学中的组织准备情况</span></a></h1><h2 id="关键词-3" tabindex="-1"><a class="header-anchor" href="#关键词-3"><span>关键词</span></a></h2><p>大型语言模型；病理信息学；组织准备</p><h2 id="研究问题-3" tabindex="-1"><a class="header-anchor" href="#研究问题-3"><span>研究问题</span></a></h2><p>探讨组织如何为使用大型语言模型做好准备，并分析其潜在的应用场景、挑战和限制。</p><h2 id="方法-3" tabindex="-1"><a class="header-anchor" href="#方法-3"><span>方法</span></a></h2><p>通过文献回顾和案例研究，评估了不同组织在实施大型语言模型时的准备情况。</p><h2 id="创新点-3" tabindex="-1"><a class="header-anchor" href="#创新点-3"><span>创新点</span></a></h2><p>提出了一个综合框架来衡量组织对使用大型语言模型的准备程度，包括技术和非技术方面的考虑因素。</p><h2 id="结论-3" tabindex="-1"><a class="header-anchor" href="#结论-3"><span>结论</span></a></h2><p>为了有效利用大型语言模型带来的机会，组织需要进行广泛的准备工作，并解决可能的技术和管理挑战。</p><h1 id="大型语言模型在医疗诊断准确性中的应用研究" tabindex="-1"><a class="header-anchor" href="#大型语言模型在医疗诊断准确性中的应用研究"><span>大型语言模型在医疗诊断准确性中的应用研究</span></a></h1><h2 id="关键词-4" tabindex="-1"><a class="header-anchor" href="#关键词-4"><span>关键词</span></a></h2><p>视觉-语言模型；日本专科医生考试；医学影像学</p><h2 id="研究问题-4" tabindex="-1"><a class="header-anchor" href="#研究问题-4"><span>研究问题</span></a></h2><p>探索使用大型视觉-语言模型在不同类型的医学图像（如放射、核医学等）上进行诊断的准确性和可靠性。</p><h2 id="方法-4" tabindex="-1"><a class="header-anchor" href="#方法-4"><span>方法</span></a></h2><p>通过对比视觉-语言模型在实际医疗诊断中的表现，与日本专科医生考试结果进行了比较分析。</p><h2 id="创新点-4" tabindex="-1"><a class="header-anchor" href="#创新点-4"><span>创新点</span></a></h2><p>首次尝试将大型视觉-语言模型应用于多种类型医学图像的诊断任务中，并评估其性能指标。</p><h2 id="结论-4" tabindex="-1"><a class="header-anchor" href="#结论-4"><span>结论</span></a></h2><p>研究表明，在特定条件下训练和优化后的视觉-语言模型可以提供接近甚至超越人类专家水平的诊断准确性。</p><h1 id="使用大型语言模型提取不良事件报告中的信息" tabindex="-1"><a class="header-anchor" href="#使用大型语言模型提取不良事件报告中的信息"><span>使用大型语言模型提取不良事件报告中的信息</span></a></h1><h2 id="关键词-5" tabindex="-1"><a class="header-anchor" href="#关键词-5"><span>关键词</span></a></h2><p>AE-GPT；大型语言模型；流感疫苗不良事件；信息抽取</p><h2 id="研究问题-5" tabindex="-1"><a class="header-anchor" href="#研究问题-5"><span>研究问题</span></a></h2><p>研究如何利用大型语言模型从不良事件监测报告中自动提取有用的信息。</p><h2 id="方法-5" tabindex="-1"><a class="header-anchor" href="#方法-5"><span>方法</span></a></h2><p>开发了一个基于GPT的系统（称为AE-GPT），用于识别和分类有关特定药品或疫苗副作用的相关条目。</p><h2 id="创新点-5" tabindex="-1"><a class="header-anchor" href="#创新点-5"><span>创新点</span></a></h2><p>提出了一个新的框架，该框架允许研究人员在不增加标签数据的情况下改进现有系统的性能。</p><h2 id="结论-5" tabindex="-1"><a class="header-anchor" href="#结论-5"><span>结论</span></a></h2><p>实验结果表明，利用预训练的语言模型能够有效地从大量非结构化文本中提取相关的信息。</p><h1 id="评估低比特量化llama3模型的性能" tabindex="-1"><a class="header-anchor" href="#评估低比特量化llama3模型的性能"><span>评估低比特量化LLaMA3模型的性能</span></a></h1><h2 id="关键词-6" tabindex="-1"><a class="header-anchor" href="#关键词-6"><span>关键词</span></a></h2><p>低比特量化；LLaMA3；模型性能；效率优化</p><h2 id="研究问题-6" tabindex="-1"><a class="header-anchor" href="#研究问题-6"><span>研究问题</span></a></h2><p>研究如何通过减少计算资源消耗来提高大型语言模型在实际应用中的效率。</p><h2 id="方法-6" tabindex="-1"><a class="header-anchor" href="#方法-6"><span>方法</span></a></h2><p>对不同级别的比特数量化技术进行了实验评估，以了解它们对LLaMA3模型准确率和速度的影响。</p><h2 id="创新点-6" tabindex="-1"><a class="header-anchor" href="#创新点-6"><span>创新点</span></a></h2><p>提出了一种新的量化方法，可以显著降低内存占用和推理时间，同时保持良好的预测性能。</p><h2 id="结论-6" tabindex="-1"><a class="header-anchor" href="#结论-6"><span>结论</span></a></h2><p>研究表明，在特定任务中使用更少的比特数进行量化不仅可行而且实用，这为资源受限环境下的大规模应用提供了可能。</p><h2 id="原文链接-3" tabindex="-1"><a class="header-anchor" href="#原文链接-3"><span>原文链接</span></a></h2><p>https://arxiv.org/pdf/2411.03805</p><h1 id="机器在服务系统中的角色-人工智能驱动的非人类代理人的多维特性" tabindex="-1"><a class="header-anchor" href="#机器在服务系统中的角色-人工智能驱动的非人类代理人的多维特性"><span>机器在服务系统中的角色：人工智能驱动的非人类代理人的多维特性</span></a></h1><h2 id="关键词-7" tabindex="-1"><a class="header-anchor" href="#关键词-7"><span>关键词</span></a></h2><p>服务系统；价值共创；工程设计；人机交互；人工智能；机器自主性；环境适应能力；法律边界</p><h2 id="研究问题-7" tabindex="-1"><a class="header-anchor" href="#研究问题-7"><span>研究问题</span></a></h2><p>随着技术的进步，机器越来越多地能够根据外部输入和操作环境进行自我调整。这些变化使得非人类代理人能够在特定的边界内自主完成目标，并且可以参与到服务的价值共创过程中。这种趋势对服务创新产生了重要影响，那么如何全面理解和服务系统中非人类代理人的角色以及其在价值共创中的作用呢？</p><h2 id="方法-7" tabindex="-1"><a class="header-anchor" href="#方法-7"><span>方法</span></a></h2><p>我们采用了一个基于经验开放数据的四步类型构建方法，分析了130个服务案例的数据。通过这种方法，开发出了六个维度来表征非人类代理人在服务系统中的具体角色。</p><h2 id="创新点-7" tabindex="-1"><a class="header-anchor" href="#创新点-7"><span>创新点</span></a></h2><p>本研究首次提出了一个多维特性框架，以全面理解非人类代理人在服务系统中的角色及其对价值共创的影响。我们的方法不仅考虑了技术层面的因素，还涵盖了法律、经济和社会因素，这为理论和实践提供了新的视角。</p><h2 id="结论-7" tabindex="-1"><a class="header-anchor" href="#结论-7"><span>结论</span></a></h2><p>通过分析机器在服务系统中如何自主运作并参与价值共创，我们提出了一系列关于工程设计和服务创新的新见解。这项研究对于未来的理论发展和实际应用都有重要参考意义。我们的研究成果有助于促进对服务过程的深入理解，并能够指导工程师设计出更多以用户为中心、面向价值的人机交互系统。</p><h2 id="原文链接-4" tabindex="-1"><a class="header-anchor" href="#原文链接-4"><span>原文链接</span></a></h2><p>https://aisel.aisnet.org/wi2024/70/</p><h1 id="大型语言模型对双用途生物技术的民主化访问的影响" tabindex="-1"><a class="header-anchor" href="#大型语言模型对双用途生物技术的民主化访问的影响"><span>大型语言模型对双用途生物技术的民主化访问的影响</span></a></h1><h2 id="关键词-8" tabindex="-1"><a class="header-anchor" href="#关键词-8"><span>关键词</span></a></h2><p>大型语言模型；双重使用生物技术；民主化访问；生物安全</p><h2 id="研究问题-8" tabindex="-1"><a class="header-anchor" href="#研究问题-8"><span>研究问题</span></a></h2><p>大型语言模型是否能够促进更多人获取到双重使用的生物技术？这会带来怎样的潜在风险和挑战？</p><h2 id="方法-8" tabindex="-1"><a class="header-anchor" href="#方法-8"><span>方法</span></a></h2><p>通过文献综述、专家访谈等方式收集数据，分析大型语言模型在生物技术研发中的应用及其可能带来的影响。</p><h2 id="创新点-8" tabindex="-1"><a class="header-anchor" href="#创新点-8"><span>创新点</span></a></h2><p>本研究首次系统地探讨了大型语言模型对双用途生物技术的民主化访问的影响，并提出了相应的治理建议。</p><h2 id="结论-8" tabindex="-1"><a class="header-anchor" href="#结论-8"><span>结论</span></a></h2><p>大型语言模型能够促进更多人获取到复杂的生物技术知识和实验方案，但同时也带来了安全风险和伦理挑战。因此，在推广使用的同时，需要建立有效的监管机制来确保其安全性与合法性。</p><h2 id="原文链接-5" tabindex="-1"><a class="header-anchor" href="#原文链接-5"><span>原文链接</span></a></h2><p>https://biosecurityfundamentals.com/projects/enhancing-biosecurity-with-ai-agents-defining-research-directions/</p><h1 id="大型语言模型与光网络自动化" tabindex="-1"><a class="header-anchor" href="#大型语言模型与光网络自动化"><span>大型语言模型与光网络自动化</span></a></h1><h2 id="关键词-9" tabindex="-1"><a class="header-anchor" href="#关键词-9"><span>关键词</span></a></h2><p>大型语言模型；自动化；数字孪生；API；功率优化；信道管理</p><h2 id="研究问题-9" tabindex="-1"><a class="header-anchor" href="#研究问题-9"><span>研究问题</span></a></h2><p>如何利用大型语言模型（LLM）来提高光网络的管理和自动化水平？</p><h2 id="方法-9" tabindex="-1"><a class="header-anchor" href="#方法-9"><span>方法</span></a></h2><p>本研究通过使用Hugging Face平台上的预训练语言模型，如Mistral-7B-Instruct-v0.3和Mixtral-8x7B-Instruct-v0.1，开发了一种基于API的LLM模型与光网络管理系统的集成方法。该系统能够接收用户命令或问题输入，并通过数字孪生技术对现有网络进行仿真模拟，以实现信道功率优化、故障定位等自动化任务。</p><h2 id="创新点-9" tabindex="-1"><a class="header-anchor" href="#创新点-9"><span>创新点</span></a></h2><p>本研究首次实现了大型语言模型在光网络管理中的应用，并提出了一种通过低秩适应（LoRA）方法来降低预训练模型计算资源消耗的方案。此外，还提供了一个开源框架，该框架允许用户自定义LLM模型以适应特定场景需求。</p><h2 id="结论-9" tabindex="-1"><a class="header-anchor" href="#结论-9"><span>结论</span></a></h2><p>利用大型语言模型进行光网络管理和自动化可以显著提高工作效率和准确性，同时降低了人工干预的需求。未来的工作将致力于进一步优化这些技术的应用，并探索更多可能性，例如结合其他AI算法来解决复杂问题。</p><h2 id="原文链接-6" tabindex="-1"><a class="header-anchor" href="#原文链接-6"><span>原文链接</span></a></h2><p>https://nicoladicicco.github.io/assets/pdf/sun2024llm.pdf</p><h1 id="如何利用人工智能辅助语言学习-从社区视角探讨ai作为人性化代理的感知" tabindex="-1"><a class="header-anchor" href="#如何利用人工智能辅助语言学习-从社区视角探讨ai作为人性化代理的感知"><span>如何利用人工智能辅助语言学习：从社区视角探讨AI作为人性化代理的感知</span></a></h1><h2 id="关键词-10" tabindex="-1"><a class="header-anchor" href="#关键词-10"><span>关键词</span></a></h2><p>人工智能；语言学习；社区视角；人性化代理</p><h2 id="研究问题-10" tabindex="-1"><a class="header-anchor" href="#研究问题-10"><span>研究问题</span></a></h2><p>研究在语言学习中使用人工智能技术时，学生如何看待人工智能的存在和作用。</p><h2 id="方法-10" tabindex="-1"><a class="header-anchor" href="#方法-10"><span>方法</span></a></h2><p>本研究采用问卷调查与深度访谈相结合的方式进行数据收集。参与者来自多个国家和地区，在不同的语境下利用AI辅助学习英语和其他外语。通过分析学生的回答和反馈，评估他们对于AI作为人性化代理的感知及其在语言学习中的应用效果。</p><h2 id="创新点-10" tabindex="-1"><a class="header-anchor" href="#创新点-10"><span>创新点</span></a></h2><p>该研究首次从社区互动的角度探讨了学生对人工智能存在的感知，并提出将AI视为一种可以促进人际交流和知识共享的人性化工具的概念模型。</p><h2 id="结论-10" tabindex="-1"><a class="header-anchor" href="#结论-10"><span>结论</span></a></h2><p>结果显示，在适当的设计和支持下，大学生愿意与AI进行有效沟通并将其视作人类教师的补充。此外，当AI能够提供个性化的学习建议时，它被认为是一个有价值的学习伙伴，有助于提高语言技能和自信心。</p><h2 id="原文链接-7" tabindex="-1"><a class="header-anchor" href="#原文链接-7"><span>原文链接</span></a></h2><p>https://ojs.cahayamandalika.com/index.php/jcm/article/download/3865/3008</p><h1 id="基于大型语言模型的情境感知情绪和疲劳识别技术在高级驾驶辅助系统中的应用" tabindex="-1"><a class="header-anchor" href="#基于大型语言模型的情境感知情绪和疲劳识别技术在高级驾驶辅助系统中的应用"><span>基于大型语言模型的情境感知情绪和疲劳识别技术在高级驾驶辅助系统中的应用</span></a></h1><h2 id="关键词-11" tabindex="-1"><a class="header-anchor" href="#关键词-11"><span>关键词</span></a></h2><p>情境感知；情绪识别；疲劳检测；大型语言模型；自动驾驶</p><h2 id="研究问题-11" tabindex="-1"><a class="header-anchor" href="#研究问题-11"><span>研究问题</span></a></h2><p>如何通过利用大型语言模型来增强高级驾驶辅助系统（ADAS）中对驾驶员的情绪和疲劳状态的识别？</p><h2 id="方法-11" tabindex="-1"><a class="header-anchor" href="#方法-11"><span>方法</span></a></h2><p>本研究提出了一种基于大型语言模型的情境感知方法，旨在提升ADAS在复杂道路环境中的智能性和安全性。具体方法包括：</p><ol><li>构建包含多模态数据集的训练样本库。</li><li>利用预训练的大型语言模型进行微调以提高情绪和疲劳识别精度。</li><li>设计情境感知模块，动态调整模型参数以适应不同驾驶场景。</li></ol><h2 id="创新点-11" tabindex="-1"><a class="header-anchor" href="#创新点-11"><span>创新点</span></a></h2><p>本研究创新性地将大型语言模型应用于ADAS中驾驶员的情绪与疲劳状态监测，并通过引入情境感知机制进一步增强了系统的泛化能力。此外，该方法利用了大量的多模态数据来训练和优化系统，提高了识别的准确性和可靠性。</p><h2 id="结论-11" tabindex="-1"><a class="header-anchor" href="#结论-11"><span>结论</span></a></h2><p>研究表明，基于大型语言模型的情境感知情绪和疲劳检测技术能够显著提升ADAS的安全性能。这种方法不仅能够在驾驶过程中及时提醒驾驶员注意安全问题，还能在一定程度上避免因驾驶员注意力分散或疲劳导致的交通事故，从而为未来的智能交通系统提供了有力的技术支持。</p><h2 id="原文链接-8" tabindex="-1"><a class="header-anchor" href="#原文链接-8"><span>原文链接</span></a></h2><p>https://link.springer.com/chapter/10.1007/978-3-031-71821-2_2</p><h1 id="通过提示对抗调优防御破解攻击" tabindex="-1"><a class="header-anchor" href="#通过提示对抗调优防御破解攻击"><span>通过提示对抗调优防御破解攻击</span></a></h1><h2 id="关键词-12" tabindex="-1"><a class="header-anchor" href="#关键词-12"><span>关键词</span></a></h2><p>大型语言模型, 破解防御, 提示微调</p><h2 id="研究问题-12" tabindex="-1"><a class="header-anchor" href="#研究问题-12"><span>研究问题</span></a></h2><p>尽管大型语言模型（LLM）在各种应用中取得了巨大成功，但它们也容易受到破解攻击。已提出几种主要的防御策略来保护 LLM 不产生有害信息，大多集中在模型精调或启发式防御设计上。然而，如何通过提示优化实现内在鲁棒性仍然是一个未解决的问题。</p><h2 id="方法-12" tabindex="-1"><a class="header-anchor" href="#方法-12"><span>方法</span></a></h2><p>本文受对抗训练范式的启发，提出了**提示对抗调优（PAT）**方法，即在用户提示中附加了一个作为守卫前缀的提示控制来训练。为了达成防御目标同时保持自然性能，在对抗和良性提示下优化该控制提示。全面实验表明，本方法对灰盒和黑盒攻击都有效，将高级别攻击的成功率几乎降至零，而不会损害模型在良善任务中的实用性，并且仅产生可忽略不计的计算开销。</p><h2 id="创新点-12" tabindex="-1"><a class="header-anchor" href="#创新点-12"><span>创新点</span></a></h2><p>本文首次提出了通过对抗性调优来防御大型语言模型破解的新方法。该方法结合了对抗和良性提示优化控制提示，实现了对各种攻击的有效抵御，同时保证了模型在良善任务中的性能和效率。此外，本研究为未来探索 LLM 安全性的新视角提供了有力支持。</p><h2 id="结论-12" tabindex="-1"><a class="header-anchor" href="#结论-12"><span>结论</span></a></h2><p>本文提出的 Prompt Adversarial Tuning (PAT) 方法通过引入对抗性调优机制来有效防御大型语言模型的破解攻击，而不会影响其在良善任务中的表现和计算效率。该方法展示了在保障 LLM 的安全性方面的新路径，并为未来的研究提供了有价值的见解和技术支持。</p><h2 id="原文链接-9" tabindex="-1"><a class="header-anchor" href="#原文链接-9"><span>原文链接</span></a></h2><p>https://openreview.net/forum?id=nRdST1qifJ</p><h1 id="arkvale-基于召回的高效生成大型语言模型推理缓存管理" tabindex="-1"><a class="header-anchor" href="#arkvale-基于召回的高效生成大型语言模型推理缓存管理"><span>ArkVale：基于召回的高效生成大型语言模型推理缓存管理</span></a></h1><h2 id="关键词-13" tabindex="-1"><a class="header-anchor" href="#关键词-13"><span>关键词</span></a></h2><p>机器学习系统；大规模语言模型推理；键值缓存驱逐</p><h2 id="研究问题-13" tabindex="-1"><a class="header-anchor" href="#研究问题-13"><span>研究问题</span></a></h2><p>在处理具有长上下文长度的任务时，大规模语言模型（LLM）的关键值缓存（KV cache）需要大量内存。这不仅限制了批处理大小从而降低了吞吐量，还增加了注意力计算的延迟。以前的工作发现只使用最近和高影响的令牌来进行注意力计算是足够的，可以驱逐不重要的令牌以减小缓存大小。然而，我们观察到令牌重要性在不同的解码步骤之间动态变化：最初被驱逐的令牌可能在后续解码步骤中重新变得重要。</p><h2 id="方法-13" tabindex="-1"><a class="header-anchor" href="#方法-13"><span>方法</span></a></h2><p>为了解决这一问题，我们提出了ArkVale，这是一种基于页面的KV缓存管理器，可以在注意力计算前识别并召回之前被驱逐的重要令牌。通过异步复制填充的页面到外部内存（例如CPU内存）作为备份，并构建其键的包围体积进行摘要化处理，将这些页面压缩成更小的形式。在注意力计算之前，根据它们的摘要测量所有页面的重要性，召回重要的页面，驱逐不重要的页面，并选择排名靠前的页面用于注意力计算。</p><h2 id="创新点-13" tabindex="-1"><a class="header-anchor" href="#创新点-13"><span>创新点</span></a></h2><p>ArkVale能够动态地识别和恢复重要性较高的令牌，在较小的缓存预算下（2k~4k）实现几乎无损的准确性。通过仅在小部分页面上应用注意力计算，它可以显著减少每个样本的关键值缓存内存使用量，并提高解码延迟和批处理吞吐量。</p><h2 id="结论-13" tabindex="-1"><a class="header-anchor" href="#结论-13"><span>结论</span></a></h2><p>实验结果显示，ArkVale在各种长上下文任务中表现出色，在较小的缓存预算下几乎没有精度损失。通过减少关键值缓存的每样本内存使用量，它可以将解码延迟降低至原来的2.2倍，并将批量吞吐量提高4.6倍。</p><h2 id="原文链接-10" tabindex="-1"><a class="header-anchor" href="#原文链接-10"><span>原文链接</span></a></h2><p>https://openreview.net/forum?id=4oAt5L4lYe</p><h1 id="大型语言模型之间的协调能力探究" tabindex="-1"><a class="header-anchor" href="#大型语言模型之间的协调能力探究"><span>大型语言模型之间的协调能力探究</span></a></h1><h2 id="关键词-14" tabindex="-1"><a class="header-anchor" href="#关键词-14"><span>关键词</span></a></h2><p>大型语言模型；协调机制；奖励模型</p><h2 id="研究问题-14" tabindex="-1"><a class="header-anchor" href="#研究问题-14"><span>研究问题</span></a></h2><p>如何使两个独立的大型语言模型在没有预先沟通的情况下通过奖励模型实现有效协作？</p><h2 id="方法-14" tabindex="-1"><a class="header-anchor" href="#方法-14"><span>方法</span></a></h2><p>本研究利用GPT-3.5-Turbo模型作为实验对象，设计了一套基于奖励反馈的实验方案。首先，在一个有限的消息空间内构建了一个简单的任务，该任务要求两个模型相互合作才能完成；然后逐步调整和优化奖励机制，以观察模型是否能够学会一套有效的沟通策略。</p><h2 id="创新点-14" tabindex="-1"><a class="header-anchor" href="#创新点-14"><span>创新点</span></a></h2><p>本研究首次展示了在没有预先设定规则的情况下，通过奖励模型可以促使大型语言模型自发形成一种协调机制。这种方法为多模态交互以及分布式人工智能系统的开发提供了新的思路。</p><h2 id="结论-14" tabindex="-1"><a class="header-anchor" href="#结论-14"><span>结论</span></a></h2><p>实验结果表明，在适当的奖励结构下，两个大型语言模型能够在有限的消息空间内学会建立有效的沟通渠道，并且这种能力随着训练的进行而逐渐增强。这说明基于奖励的学习框架具备一定的潜力来解决复杂的协调问题。</p><h2 id="原文链接-11" tabindex="-1"><a class="header-anchor" href="#原文链接-11"><span>原文链接</span></a></h2><p>https://openreview.net/pdf?id=bnNSQhZJ88</p><h1 id="基于人工智能的医学文本生成技术-系统评价" tabindex="-1"><a class="header-anchor" href="#基于人工智能的医学文本生成技术-系统评价"><span>基于人工智能的医学文本生成技术：系统评价</span></a></h1><h2 id="关键词-15" tabindex="-1"><a class="header-anchor" href="#关键词-15"><span>关键词</span></a></h2><p>人工智能；机器学习；自然语言处理；深度学习；文本生成；医疗保健；伦理问题；隐私保护；生物医学研究</p><h2 id="研究问题-15" tabindex="-1"><a class="header-anchor" href="#研究问题-15"><span>研究问题</span></a></h2><p>本研究旨在评估和总结当前基于AI（包括ML、NLP和DL）的医学文本生成技术的发展状况，识别这些技术在医学领域的应用范围，并探讨其可能面临的挑战和未来发展趋势。特别关注伦理问题、隐私保护以及如何确保公平性等关键议题。</p><h2 id="方法-15" tabindex="-1"><a class="header-anchor" href="#方法-15"><span>方法</span></a></h2><p>采用系统评价的方法，对相关文献进行检索筛选和综合分析。基于PRISMA（优选报告系统综述和元分析的条目）指南确定了研究流程，并通过关键词搜索数据库以获取符合要求的研究论文。</p><h2 id="创新点-15" tabindex="-1"><a class="header-anchor" href="#创新点-15"><span>创新点</span></a></h2><p>本研究首次全面评估AI在医学文本生成中的应用范围与技术进步，详细探讨其伦理问题、隐私保护及公平性方面的挑战。通过对现有文献的系统梳理和总结，为未来该领域的研究和发展提供了宝贵的参考意见。</p><h2 id="结论-15" tabindex="-1"><a class="header-anchor" href="#结论-15"><span>结论</span></a></h2><p>基于人工智能（包括机器学习、自然语言处理和深度学习）的医学文本生成技术已经取得了显著进展，并在多个方面展示出了巨大的应用潜力。然而，在实际应用中也面临着诸如伦理问题、隐私保护以及确保公平性等方面的挑战，需要进一步的研究与规范来促进其健康发展。</p><h2 id="原文链接-12" tabindex="-1"><a class="header-anchor" href="#原文链接-12"><span>原文链接</span></a></h2><p>https://www.jmir.org/2024/1/e22769/</p><h1 id="人工智能技术在可持续重构制造系统中的应用-基于大语言模型的决策支持" tabindex="-1"><a class="header-anchor" href="#人工智能技术在可持续重构制造系统中的应用-基于大语言模型的决策支持"><span>人工智能技术在可持续重构制造系统中的应用：基于大语言模型的决策支持</span></a></h1><h2 id="关键词-16" tabindex="-1"><a class="header-anchor" href="#关键词-16"><span>关键词</span></a></h2><p>可持续制造, 重构制造系统, 决策支持, 大语言模型, 人工智能</p><h2 id="研究问题-16" tabindex="-1"><a class="header-anchor" href="#研究问题-16"><span>研究问题</span></a></h2><p>如何利用人工智能技术，特别是大型语言模型，来增强可持续重构制造系统的决策能力？</p><h2 id="方法-16" tabindex="-1"><a class="header-anchor" href="#方法-16"><span>方法</span></a></h2><p>本研究探索了将大语言模型集成到决策支持系统中的方法，并评估其在提高制造效率和灵活性方面的效果。通过使用具体的案例分析来验证这些方法的有效性。</p><h2 id="创新点-16" tabindex="-1"><a class="header-anchor" href="#创新点-16"><span>创新点</span></a></h2><p>提出了一种基于人工智能的新型决策支持框架，该框架能够更好地适应不断变化的需求并促进可持续制造实践的发展。此外，还利用最新的大型语言模型技术优化了现有制造系统的配置与控制策略。</p><h2 id="结论-16" tabindex="-1"><a class="header-anchor" href="#结论-16"><span>结论</span></a></h2><p>研究表明，将大语言模型融入到重构制造系统中可以显著提高资源利用率和生产灵活性，同时有助于企业实现长期的可持续发展目标。通过这种方式，制造商能够更快速地响应市场变化，从而在竞争激烈的环境中保持竞争优势。</p><h2 id="原文链接-13" tabindex="-1"><a class="header-anchor" href="#原文链接-13"><span>原文链接</span></a></h2><p>https://www.mdpi.com/2504-2289/8/11/152</p><h1 id="计算机辅助设计与图形学中的注意力机制分析" tabindex="-1"><a class="header-anchor" href="#计算机辅助设计与图形学中的注意力机制分析"><span>计算机辅助设计与图形学中的注意力机制分析</span></a></h1><h2 id="关键词-17" tabindex="-1"><a class="header-anchor" href="#关键词-17"><span>关键词</span></a></h2><p>计算机辅助设计；图形学；注意力机制；自然语言处理；深度学习模型</p><h2 id="研究问题-17" tabindex="-1"><a class="header-anchor" href="#研究问题-17"><span>研究问题</span></a></h2><p>如何深入理解并可视化自然语言处理中各种深度学习模型的文本分类能力？</p><h2 id="方法-17" tabindex="-1"><a class="header-anchor" href="#方法-17"><span>方法</span></a></h2><p>本文提出了一种统一的方法来理解深度NLP模型中的注意力流，并使用了多种分析技术，包括但不限于UMAP降维方法和DRGraph布局算法。这种方法可以有效地比较不同模型在特定任务上的表现差异。</p><h2 id="创新点-17" tabindex="-1"><a class="header-anchor" href="#创新点-17"><span>创新点</span></a></h2><ol><li>统一的理解框架：提供了一个统一的视角来解释和比较不同的NLP模型。</li><li>可视化工具：开发了专门用于分析和比较注意力机制的可视化工具，帮助研究人员更好地理解这些复杂的模型内部工作原理。</li><li>实用资源：发布了一系列针对通用中文嵌入的技术包，以促进相关领域的研究进展。</li></ol><h2 id="结论-17" tabindex="-1"><a class="header-anchor" href="#结论-17"><span>结论</span></a></h2><p>通过对大量模型的表现进行对比，本文展示了不同深度NLP模型在文本分类任务中的独特优势和局限性。同时，通过使用先进的可视化技术，研究人员可以更清晰地理解这些模型的内部机制，并为进一步优化提供指导。</p><h2 id="原文链接-14" tabindex="-1"><a class="header-anchor" href="#原文链接-14"><span>原文链接</span></a></h2><p>https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2024-00393.pdf</p><h1 id="使用大型语言模型进行学术写作教学-socrat项目的概念设计与评估" tabindex="-1"><a class="header-anchor" href="#使用大型语言模型进行学术写作教学-socrat项目的概念设计与评估"><span>使用大型语言模型进行学术写作教学：SOCRAT项目的概念设计与评估</span></a></h1><h2 id="关键词-18" tabindex="-1"><a class="header-anchor" href="#关键词-18"><span>关键词</span></a></h2><p>学术写作, 人工智能（AI）, 文本类型, 大型语言模型（LLM）, 共同创造</p><h2 id="研究问题-18" tabindex="-1"><a class="header-anchor" href="#研究问题-18"><span>研究问题</span></a></h2><p>随着人工智能的发展，学术写作经历了显著的变革。学生正以多种方式利用AI技术进行学习和研究。然而，在这种背景下，如何有效设计课程帮助学生掌握基于特定学科文本类型的学术写作技巧，并充分利用AI工具，是当前面临的一个挑战。</p><h2 id="方法-18" tabindex="-1"><a class="header-anchor" href="#方法-18"><span>方法</span></a></h2><p>提出了一种新的课程设计方案（SOCRAT），旨在通过大型语言模型辅助的方式教授学生基于特定学术领域的文体写作技能。在该方案中，AI被用作个性化训练系统和研究助手。为了确保学习者能够有效地使用这些工具，设计强调了掌握认知和元认知知识的重要性。初步评估表明，LLM可以特别有助于学生分析其书面文本并提供改进建议。</p><h2 id="创新点-18" tabindex="-1"><a class="header-anchor" href="#创新点-18"><span>创新点</span></a></h2><p>本项目首次尝试将大型语言模型融入学术写作教学中，并基于“精通学习”理念构建课程框架。此外，通过评价已开发的提示语料库，确认了LLM在帮助学生提高文体特定写作技能方面的潜力，尤其是在分析和优化书面文本方面。</p><h2 id="结论-18" tabindex="-1"><a class="header-anchor" href="#结论-18"><span>结论</span></a></h2><p>虽然大型语言模型可以作为学生使用AI工具进行学术写作指导的有效手段，但它们目前尚不足以满足需要提供精确答案的任务类型。因此，在未来的研究中将进一步探索如何更好地将人工智能技术整合到教学环境中，以促进学生的学术能力发展。</p><h2 id="原文链接-15" tabindex="-1"><a class="header-anchor" href="#原文链接-15"><span>原文链接</span></a></h2><p>https://www.alexandria.unisg.ch/entities/publication/aa95480a-63d1-4f00-af05-716de612a851</p><h1 id="基于自校准概率变异的成员推理攻击" tabindex="-1"><a class="header-anchor" href="#基于自校准概率变异的成员推理攻击"><span>基于自校准概率变异的成员推理攻击</span></a></h1><h2 id="关键词-19" tabindex="-1"><a class="header-anchor" href="#关键词-19"><span>关键词</span></a></h2><p>大规模语言模型, 成员推理攻击, 隐私与安全</p><h2 id="研究问题-19" tabindex="-1"><a class="header-anchor" href="#研究问题-19"><span>研究问题</span></a></h2><p>现有的针对大规模语言模型（LLM）的成员推理攻击可以分为无参考和有参考两种类型。然而，这些攻击方法在实际场景中存在较高的误报率。本研究旨在提出一种基于自校准概率变异（SPV-MIA）的新颖方法，通过使用目标模型本身生成的数据集来降低成员推理攻击中的误报问题。</p><h2 id="方法-19" tabindex="-1"><a class="header-anchor" href="#方法-19"><span>方法</span></a></h2><p>我们引入了一种自提示方法，该方法利用目标语言模型自身来构建用于微调参考模型的训练数据集。这使对手能够从公共API中收集与真实分布相似的数据集。此外，我们还提出了基于LLM记忆的概率变异这一更为可靠的成员信号，并在此基础上重新发现具有理论基础的邻居攻击。</p><h2 id="创新点-19" tabindex="-1"><a class="header-anchor" href="#创新点-19"><span>创新点</span></a></h2><ol><li>提出了一种新颖的自校准概率变异（SPV-MIA）方法。</li><li>引入了自提示技术以构建用于微调参考模型的数据集。</li><li>通过使用LLM记忆而非过度拟合来提供更为可靠的成员信号。</li></ol><h2 id="结论-19" tabindex="-1"><a class="header-anchor" href="#结论-19"><span>结论</span></a></h2><p>在三个数据集和四种代表性大规模语言模型上的综合评估显示，基于SPV-MIA的攻击将AUC（Area Under Curve）从0.7显著提升至0.9。我们的代码和数据集已发布在：https://github.com/tsinghua-fib-lab/NeurIPS2024_SPV-MIA</p><h2 id="原文链接-16" tabindex="-1"><a class="header-anchor" href="#原文链接-16"><span>原文链接</span></a></h2><p>https://openreview.net/forum?id=PAWQvrForJ</p><p>提供的内容似乎并不是一篇完整的学术论文或研究报告的主体部分，而是网页上的导航链接和其他相关信息。因此无法直接转换为符合要求的格式化学术论文文本。</p><p>基于给定的信息，我们只能提供一个简短的研究方向描述，并将其翻译成中文：</p><h1 id="大型语言模型辅助文献综述-一项关于少量样本相关性分类的研究" tabindex="-1"><a class="header-anchor" href="#大型语言模型辅助文献综述-一项关于少量样本相关性分类的研究"><span>大型语言模型辅助文献综述：一项关于少量样本相关性分类的研究</span></a></h1><h2 id="关键词-20" tabindex="-1"><a class="header-anchor" href="#关键词-20"><span>关键词</span></a></h2><p>大型语言模型、文献综述、少量样本学习、相关性分类</p><h2 id="研究问题-20" tabindex="-1"><a class="header-anchor" href="#研究问题-20"><span>研究问题</span></a></h2><p>如何利用大型语言模型进行高效且准确的文献综述，特别是在处理少量样本的情况下？</p><h2 id="方法-20" tabindex="-1"><a class="header-anchor" href="#方法-20"><span>方法</span></a></h2><p>使用大型语言模型执行少量样本的相关性分类任务，并评估其在不同数据集上的性能。</p><h2 id="创新点-20" tabindex="-1"><a class="header-anchor" href="#创新点-20"><span>创新点</span></a></h2><p>本文提出了一种新颖的方法来利用大型语言模型对学术论文进行快速有效的相关性分类，特别针对资源有限的场景（如少量训练数据）进行了优化。</p><h2 id="结论-20" tabindex="-1"><a class="header-anchor" href="#结论-20"><span>结论</span></a></h2><p>通过实验验证，大型语言模型能够显著提高文献综述过程中的工作效率和准确性。对于处理少量样本任务而言，该方法显示出了尤为突出的优势。</p><p>请注意，上述内容仅为示例性质，并非基于实际研究工作的具体论文或报告。如需翻译真实的学术论文，请提供完整的正文部分以便进行准确转换与总结。</p><h2 id="原文链接-17" tabindex="-1"><a class="header-anchor" href="#原文链接-17"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10740404/</p><h1 id="magentic-one-解决复杂任务的多智能体通用系统" tabindex="-1"><a class="header-anchor" href="#magentic-one-解决复杂任务的多智能体通用系统"><span>Magentic-One：解决复杂任务的多智能体通用系统</span></a></h1><h2 id="关键词-21" tabindex="-1"><a class="header-anchor" href="#关键词-21"><span>关键词</span></a></h2><ul><li>人工智能；</li><li>多智能体系统</li></ul><h2 id="研究问题-21" tabindex="-1"><a class="header-anchor" href="#研究问题-21"><span>研究问题</span></a></h2><p>现代AI代理通过大型基础模型的进步，承诺增强我们的生产力并改变我们的生活。为了实现这一愿景，AI代理必须有效地规划、执行多步骤推理和行动、响应新的观察结果，并从错误中恢复，以在各种场景下成功完成复杂的任务。</p><h2 id="方法-21" tabindex="-1"><a class="header-anchor" href="#方法-21"><span>方法</span></a></h2><p>我们在本文中介绍了Magentic-One，这是一个高表现力的开源智能体系统，用于解决这些任务。Magentic-One使用一个多智能体架构，在该架构中，一个领导代理（Orchestrator）进行规划、跟踪进度并重新规划以从错误中恢复。在整个任务执行过程中，Orchestrator根据需要引导其他专门化的智能体来完成特定的任务，例如操作网页浏览器、导航本地文件或编写和执行Python代码。</p><h2 id="创新点-21" tabindex="-1"><a class="header-anchor" href="#创新点-21"><span>创新点</span></a></h2><p>Magentic-One在三个多样且具有挑战性的代理基准测试（GAIA, AssistantBench 和 WebArena）中实现了统计上可竞争的表现。特别的是，这些结果是在没有修改核心代理能力或它们的协作方式的情况下实现的，这表明了向通用智能体系统发展的进步。此外，Magentic-One模块化的设计允许在团队中添加或移除代理而无需额外的提示调整或训练，从而使开发更加轻松并可扩展到未来场景。</p><h2 id="结论-21" tabindex="-1"><a class="header-anchor" href="#结论-21"><span>结论</span></a></h2><p>我们提供了Magentic-One的开源实施，并包括了一个独立工具AutoGenBench用于智能体评估。AutoGenBench提供内置控制以重复运行和隔离代理基准测试，在严格的和受控的方式下执行——这对于有副作用的代理行动尤为重要。Magentic-One、AutoGenBench以及详细的实证性能评价，包括消融分析和错误分析在 https://aka.ms/magentic-one 上可以获得。</p><h2 id="原文链接-18" tabindex="-1"><a class="header-anchor" href="#原文链接-18"><span>原文链接</span></a></h2><p>https://ui.adsabs.harvard.edu/abs/2024arXiv241104468F/abstract</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: zhangleilikejay@gmail.com">zhanglei</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/llm/20241111_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241111_大模型"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>20241111_大模型</span></div></a><a class="route-link auto-link next" href="/llm/20241117_%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" aria-label="20241117_大模型"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>20241117_大模型</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BenbKM8H.js" defer></script>
  </body>
</html>
