<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.15" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>20241016_室内定位 | 室内定位技术</title><meta name="description" content="20241016_室内定位">
    <link rel="preload" href="/assets/style-CQdWRPUu.css" as="style"><link rel="stylesheet" href="/assets/style-CQdWRPUu.css">
    <link rel="modulepreload" href="/assets/app-BNyMW1Pp.js"><link rel="modulepreload" href="/assets/20241016_室内定位.html-Balntghz.js">
    <link rel="prefetch" href="/assets/index.html-CN6bKgNh.js" as="script"><link rel="prefetch" href="/assets/商务合作.html-B_MZzLvb.js" as="script"><link rel="prefetch" href="/assets/20240917_大模型.html-X3OOYWbP.js" as="script"><link rel="prefetch" href="/assets/20241004_大模型.html-CBWN5Uzp.js" as="script"><link rel="prefetch" href="/assets/20241009_大模型.html-B6PzKIfN.js" as="script"><link rel="prefetch" href="/assets/20241010_大模型.html-BrdLK9SK.js" as="script"><link rel="prefetch" href="/assets/20241011_大模型.html-D0P1ze6b.js" as="script"><link rel="prefetch" href="/assets/20241013_大模型.html-Bs3WihAf.js" as="script"><link rel="prefetch" href="/assets/20241016_大模型.html-BrRt6qIt.js" as="script"><link rel="prefetch" href="/assets/20241020_大模型.html-DoMek0Tc.js" as="script"><link rel="prefetch" href="/assets/20241029_大模型.html-DKAwjp16.js" as="script"><link rel="prefetch" href="/assets/20241103_大模型.html-Mpvcw7pT.js" as="script"><link rel="prefetch" href="/assets/20241104_大模型.html-D-3xTwnR.js" as="script"><link rel="prefetch" href="/assets/20241109_大模型.html-BbNxPEnG.js" as="script"><link rel="prefetch" href="/assets/20241111_大模型.html-D3i6DeTL.js" as="script"><link rel="prefetch" href="/assets/20241113_大模型.html-B_YQKXXR.js" as="script"><link rel="prefetch" href="/assets/20241117_大模型.html-Ca56tr58.js" as="script"><link rel="prefetch" href="/assets/20241122_大模型.html-HxWcpDcy.js" as="script"><link rel="prefetch" href="/assets/20241125_大模型.html-D1EtwN2M.js" as="script"><link rel="prefetch" href="/assets/20241129_大模型.html-CSnUTIPm.js" as="script"><link rel="prefetch" href="/assets/index.html-C_LCynFL.js" as="script"><link rel="prefetch" href="/assets/20240911_室内定位.html-BFdMEQUj.js" as="script"><link rel="prefetch" href="/assets/20240916_室内定位.html-BJPJbT_H.js" as="script"><link rel="prefetch" href="/assets/20240920_室内定位.html-lrSGz_0s.js" as="script"><link rel="prefetch" href="/assets/20240925_室内定位.html-Bog0JN0o.js" as="script"><link rel="prefetch" href="/assets/20240930_室内定位.html-B9hMwxIg.js" as="script"><link rel="prefetch" href="/assets/20241004_室内定位.html-BgrTH2Wy.js" as="script"><link rel="prefetch" href="/assets/20241009_室内定位.html-B2LVVzQz.js" as="script"><link rel="prefetch" href="/assets/20241010_室内定位.html-DUn6dOkd.js" as="script"><link rel="prefetch" href="/assets/20241011_室内定位.html-BmTLgQg1.js" as="script"><link rel="prefetch" href="/assets/20241013_室内定位.html-DabVPX23.js" as="script"><link rel="prefetch" href="/assets/20241020_室内定位.html-Cvw4xHVR.js" as="script"><link rel="prefetch" href="/assets/20241029_室内定位.html-naMN3cmT.js" as="script"><link rel="prefetch" href="/assets/20241103_室内定位.html-D0e39Egn.js" as="script"><link rel="prefetch" href="/assets/20241104_室内定位.html-iWpK0plg.js" as="script"><link rel="prefetch" href="/assets/20241109_室内定位.html-C91Wj9qt.js" as="script"><link rel="prefetch" href="/assets/20241111_室内定位.html-iD_YoNXW.js" as="script"><link rel="prefetch" href="/assets/20241113_室内定位.html-CIlnpdvd.js" as="script"><link rel="prefetch" href="/assets/20241117_室内定位.html-C5sThFiI.js" as="script"><link rel="prefetch" href="/assets/20241122_室内定位.html-DMOx-29k.js" as="script"><link rel="prefetch" href="/assets/20241125_室内定位.html-BxxMjI3J.js" as="script"><link rel="prefetch" href="/assets/20241129_室内定位.html-Bxh_uwBi.js" as="script"><link rel="prefetch" href="/assets/index.html-BfmMMuC7.js" as="script"><link rel="prefetch" href="/assets/404.html-BgPKVjBy.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://lark-assets-prod-aliyun.oss-cn-hangzhou.aliyuncs.com/yuque/0/2024/jpeg/354158/1717584738049-5a4ffdae-d469-44a9-b298-f86934b6e14c.jpeg?date=1717585212400" alt="室内定位技术"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">室内定位技术</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">论文列表 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240911_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240911_室内定位"><!---->20240911_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240916_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240916_室内定位"><!---->20240916_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240920_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240920_室内定位"><!---->20240920_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240925_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240925_室内定位"><!---->20240925_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240930_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240930_室内定位"><!---->20240930_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241004_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241004_室内定位"><!---->20241004_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241009_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241009_室内定位"><!---->20241009_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241010_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241010_室内定位"><!---->20241010_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241011_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241011_室内定位"><!---->20241011_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241013_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241013_室内定位"><!---->20241013_室内定位<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/papers/20241016_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241016_室内定位"><!---->20241016_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241020_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241020_室内定位"><!---->20241020_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241029_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241029_室内定位"><!---->20241029_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241103_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241103_室内定位"><!---->20241103_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241104_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241104_室内定位"><!---->20241104_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241109_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241108_室内定位"><!---->20241108_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241111_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241111_室内定位"><!---->20241111_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241113_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241113_室内定位"><!---->20241113_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241117_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241117_室内定位"><!---->20241117_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241122_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241122_室内定位"><!---->20241122_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241125_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241125_室内定位"><!---->20241125_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241129_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241129_室内定位"><!---->20241129_室内定位<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h2 id="vins-mono-一种稳健且灵活的单目视觉惯性状态估计器" tabindex="-1"><a class="header-anchor" href="#vins-mono-一种稳健且灵活的单目视觉惯性状态估计器"><span>VINS-Mono: 一种稳健且灵活的单目视觉惯性状态估计器</span></a></h2><h3 id="研究问题" tabindex="-1"><a class="header-anchor" href="#研究问题"><span>研究问题</span></a></h3><p>如何设计一个稳健且灵活的单目视觉惯性状态估计器，以解决机器人在动态环境中导航和定位的问题？</p><h3 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h3><p>VINS-Mono 使用单一相机与惯性测量单元（IMU）的数据进行联合处理。该方法结合了来自视觉输入的姿态信息和来自IMU的速度及角速度信息。通过构建滑动窗口内的状态估计器，并采用扩展卡尔曼滤波器（EKF）对非线性系统进行优化，以确保状态估计的准确性。</p><h3 id="创新点" tabindex="-1"><a class="header-anchor" href="#创新点"><span>创新点</span></a></h3><ul><li><strong>单目相机与惯性传感器结合</strong>：利用单一视觉源提供的丰富几何结构和IMU数据中的高速率运动信息。</li><li><strong>滑动窗口内的非线性滤波器框架</strong>：允许在保持实时性能的同时进行精确的状态估计。</li><li><strong>鲁棒性的提高</strong>：通过设计特定的观测模型和误差补偿策略，增强算法对环境变化及传感器噪声的适应能力。</li></ul><h3 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h3><p>VINS-Mono 提供了一种有效的单目视觉惯性导航方案，能够应对复杂多变的应用场景。实验结果表明该方法在多种环境下具有优越性能与鲁棒性。</p><hr><h2 id="基于学习的快速单目视觉惯性初始化" tabindex="-1"><a class="header-anchor" href="#基于学习的快速单目视觉惯性初始化"><span>基于学习的快速单目视觉惯性初始化</span></a></h2><h3 id="研究问题-1" tabindex="-1"><a class="header-anchor" href="#研究问题-1"><span>研究问题</span></a></h3><p>如何实现快速且准确的单目视觉惯性初始化，以支持机器人系统的实时应用？</p><h3 id="方法-1" tabindex="-1"><a class="header-anchor" href="#方法-1"><span>方法</span></a></h3><p>提出了一种基于预训练神经网络模型的单视图深度估计方法来辅助VIO（Visual-Inertial Odometry）系统进行初始化。该方法利用从单一图像中提取场景深度信息，并结合IMU数据和视觉特征匹配技术，实现快速的姿态及位置估算。</p><h3 id="创新点-1" tabindex="-1"><a class="header-anchor" href="#创新点-1"><span>创新点</span></a></h3><ul><li><strong>学习深度感知</strong>：通过迁移学习获得强大的单视角深度估计能力。</li><li><strong>融合多模态传感器输入</strong>：有效结合相机与IMU信号，提高初始化过程的稳定性和精确度。</li><li><strong>实时性能增强</strong>：优化算法流程以适应快速变化环境下的即时需求。</li></ul><h3 id="结论-1" tabindex="-1"><a class="header-anchor" href="#结论-1"><span>结论</span></a></h3><p>所提出的单目视觉惯性初始化方案能够显著加快VIO系统的启动时间，并提供可靠的初始姿态估计。这为在动态环境中实现高效机器人操作提供了可能。</p><h2 id="原文链接" tabindex="-1"><a class="header-anchor" href="#原文链接"><span>原文链接</span></a></h2><p>https://www.algorithmic-robotics.org/papers/14_Visual_Inertial_State_Estim.pdf</p><h1 id="dp-vins-基于平面结构的动态自适应视觉惯性slam方法用于自动驾驶车辆" tabindex="-1"><a class="header-anchor" href="#dp-vins-基于平面结构的动态自适应视觉惯性slam方法用于自动驾驶车辆"><span>DP-VINS：基于平面结构的动态自适应视觉惯性SLAM方法用于自动驾驶车辆</span></a></h1><h2 id="研究问题-2" tabindex="-1"><a class="header-anchor" href="#研究问题-2"><span>研究问题</span></a></h2><p>本研究旨在解决自主驾驶车辆在同时定位与地图构建（Simultaneous Localization and Mapping, SLAM）中的挑战，特别关注通过根据环境中的平面特征进行动态调整来改进视觉惯性里程计。目标是提高SLAM算法在不同环境条件下的精度、鲁棒性和实时性能。</p><h2 id="提出方法" tabindex="-1"><a class="header-anchor" href="#提出方法"><span>提出方法</span></a></h2><p>DP-VINS方法整合了视觉惯性系统与自适应动力学模型，该模型可以根据环境中检测到的平面特征进行调整。这包括：</p><ul><li><strong>特征检测</strong>：从立体图像或单目相机数据中识别出平面。</li><li><strong>运动估计</strong>：结合惯性测量单元(IMU)的数据和基于平面的视觉线索来实现稳健的姿态估计。</li><li><strong>自适应动力学建模</strong>：根据环境变化和场景复杂度调整动态模型参数。</li></ul><h2 id="创新点-2" tabindex="-1"><a class="header-anchor" href="#创新点-2"><span>创新点</span></a></h2><ol><li><strong>动态适应机制</strong>：该方法通过根据检测到的平面特征调整其内部模型，从而在静态和动态环境中都能提高SLAM性能。</li><li><strong>增强鲁棒性和精度</strong>：利用基于平面的视觉线索，算法比仅依赖于点特征的传统方法实现更高的准确度和鲁棒性。</li><li><strong>实时性能</strong>：自适应的方法确保了高效的计算及实时操作，适合高速自动驾驶车辆的应用。</li></ol><h2 id="结论-2" tabindex="-1"><a class="header-anchor" href="#结论-2"><span>结论</span></a></h2><p>DP-VINS方法代表了自主驾驶车辆SLAM技术的一个重大进步。通过结合基于平面结构的动态调整机制，它在多种条件下提供了更优秀的精度、鲁棒性和实时性能。这项工作为自动驾驶场景中的可靠和高效导航系统铺平了道路。</p><h2 id="原文链接-1" tabindex="-1"><a class="header-anchor" href="#原文链接-1"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10711935/</p><h1 id="标题" tabindex="-1"><a class="header-anchor" href="#标题"><span>标题</span></a></h1><p>利用人工交流磁场的室外环境磁惯性里程计设计</p><h2 id="研究问题-3" tabindex="-1"><a class="header-anchor" href="#研究问题-3"><span>研究问题</span></a></h2><p>如何在户外环境中使用人工交流磁场设计磁惯性里程计？</p><h2 id="方法-2" tabindex="-1"><a class="header-anchor" href="#方法-2"><span>方法</span></a></h2><p>本研究提出了一种利用人工交流磁场（ACMF）的新颖磁惯性里程计（MIO）系统，旨在提升室外环境中的定位精度。该方法结合了低频和高频ACMF的特点，并通过分析不同频率下的磁场特性来优化MIO系统的性能。</p><h2 id="创新点-3" tabindex="-1"><a class="header-anchor" href="#创新点-3"><span>创新点</span></a></h2><ul><li>提出了一种基于人工交流磁场的创新设计。</li><li>有效解决了传统磁惯性里程计在户外复杂环境下导航精度的问题。</li><li>运用多传感器融合技术，增强了系统的鲁棒性和可靠性。</li></ul><h2 id="结论-3" tabindex="-1"><a class="header-anchor" href="#结论-3"><span>结论</span></a></h2><p>研究成功地设计并实现了一个利用人工交流磁场的磁惯性里程计系统，并通过实验验证了其在室外环境中的优越性能。未来的研究可以进一步探索更高频率ACMF的应用及其对MIO系统的影响。</p><h2 id="原文链接-2" tabindex="-1"><a class="header-anchor" href="#原文链接-2"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10705787/</p><h1 id="人工智能辅助地磁导航框架" tabindex="-1"><a class="header-anchor" href="#人工智能辅助地磁导航框架"><span>人工智能辅助地磁导航框架</span></a></h1><h2 id="研究问题-4" tabindex="-1"><a class="header-anchor" href="#研究问题-4"><span>研究问题</span></a></h2><p>如何有效地将人工智能技术集成到地磁导航系统中，以增强其准确性和可靠性？</p><h2 id="方法-3" tabindex="-1"><a class="header-anchor" href="#方法-3"><span>方法</span></a></h2><p>该研究采用了机器学习算法，特别是神经网络，来处理和分析地磁数据。研究涉及从不同地理区域和环境条件下收集大量的数据集。这些数据集被用来训练AI模型，并对新的测试案例进行预测。</p><h2 id="创新点-4" tabindex="-1"><a class="header-anchor" href="#创新点-4"><span>创新点</span></a></h2><ol><li>开发了一个自适应的神经网络框架，在不断采集的数据中能够学习并随着时间提升性能。</li><li>将实时传感器数据与历史数据库集成，提供上下文相关的导航辅助服务。</li><li>实施了强大的错误校正机制，以缓解由于环境干扰或设备故障导致的不准确问题。</li></ol><h2 id="结论-4" tabindex="-1"><a class="header-anchor" href="#结论-4"><span>结论</span></a></h2><p>研究表明，借助人工智能的地磁导航系统在各种应用中具有显著提高准确性及可靠性的潜力，包括自主车辆导向和精准农业。提出的框架不仅提升了现有的地磁导航技术，并且为该领域的未来发展开辟了新的路径。</p><p>本研究提供了有价值的见解，展示了如何利用人工智能来解决传统地磁导航系统的复杂问题。</p><h2 id="原文链接-3" tabindex="-1"><a class="header-anchor" href="#原文链接-3"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10713176/</p><h1 id="半自主移动机器人用于检查任务" tabindex="-1"><a class="header-anchor" href="#半自主移动机器人用于检查任务"><span>半自主移动机器人用于检查任务</span></a></h1><h2 id="研究问题-5" tabindex="-1"><a class="header-anchor" href="#研究问题-5"><span>研究问题</span></a></h2><p>随着工业自动化需求的增长，半自主移动机器人的应用变得越来越重要。本文探讨了在复杂环境中进行高效、安全且经济有效的检查操作所需的必要技术进步和方法。</p><ol><li>如何设计一种能够在多样化的物理条件下执行精确测量的机器人系统？</li><li>哪种类型的传感器最适合用于此类任务，并如何最佳地集成这些传感器以提高准确性？</li></ol><h2 id="提出方法-1" tabindex="-1"><a class="header-anchor" href="#提出方法-1"><span>提出方法</span></a></h2><p>为了实现上述研究目标，我们采用以下步骤：</p><ul><li>设计并制造了一个能够适应各种地形和环境条件的半自主移动机器人原型。</li><li>开发了先进的计算机视觉算法，以便在检查过程中准确识别关键特征。</li><li>集成了一系列高级传感器（包括激光雷达、超声波传感器等），以确保全面的数据采集能力。</li></ul><h2 id="创新点-5" tabindex="-1"><a class="header-anchor" href="#创新点-5"><span>创新点</span></a></h2><p>本文的主要贡献在于：</p><ol><li>提出了一个灵活且高度自适应的移动机器人架构，该架构能够在各种环境条件下执行高效的检查任务。</li><li>引入了一种新的数据融合方法，能够显著提高在复杂场景中的目标识别准确性。</li><li>通过实验证明了所提出的方法相较于现有技术具有优越的表现。</li></ol><h2 id="结论-5" tabindex="-1"><a class="header-anchor" href="#结论-5"><span>结论</span></a></h2><p>这项研究表明，在开发用于工业和基础设施检查的半自主移动机器人时，采用高度集成化的传感器技术和先进的图像处理算法是至关重要的。未来的研究应进一步探索如何利用机器学习改进数据处理效率以及提高系统的自我适应能力。</p><h2 id="原文链接-4" tabindex="-1"><a class="header-anchor" href="#原文链接-4"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10705242/</p><h1 id="基于偏差-方差权衡的新型无线指纹定位距离度量方法" tabindex="-1"><a class="header-anchor" href="#基于偏差-方差权衡的新型无线指纹定位距离度量方法"><span>基于偏差-方差权衡的新型无线指纹定位距离度量方法</span></a></h1><h2 id="研究问题-6" tabindex="-1"><a class="header-anchor" href="#研究问题-6"><span>研究问题</span></a></h2><p>本文旨在通过提出一种新的基于偏差-方差权衡的距离度量来提高无线指纹系统的定位精度。主要的研究问题是探讨这种新度量在基于无线信号特征进行室内定位时，能够多大程度地提升精确性和可靠性。</p><h2 id="提出方法-2" tabindex="-1"><a class="header-anchor" href="#提出方法-2"><span>提出方法</span></a></h2><p>该方法引入了一套全面的分析框架，用于评估无线指纹系统中使用的不同距离度量的有效性，重点在于平衡模型复杂性和实证数据拟合的能力。这包括：</p><ul><li>对现有距离度量的详尽回顾。</li><li>开发一种新的考虑偏差-方差权衡的新距离度量方法。</li><li>通过室内定位数据集进行实验验证。</li></ul><h2 id="创新点-6" tabindex="-1"><a class="header-anchor" href="#创新点-6"><span>创新点</span></a></h2><p>关键创新包括：</p><ol><li><strong>偏差-方差感知的距离度量</strong>：提出了一种新颖的方法，明确地考虑了模型复杂性和实证拟合之间的平衡，从而提高了指纹识别应用的准确性。</li><li><strong>全面评估框架</strong>：提供了一个广泛的评估方法论，用于在不同条件下评估各种距离度量的表现。</li></ol><h2 id="结论-6" tabindex="-1"><a class="header-anchor" href="#结论-6"><span>结论</span></a></h2><p>研究表明，采用提出的偏差-方差感知的距离度量与传统方法相比，在定位精度方面取得了显著提升。这为基于无线信号特征的室内定位系统改进开辟了新的途径。</p><h2 id="原文链接-5" tabindex="-1"><a class="header-anchor" href="#原文链接-5"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10711948/</p><h1 id="基于uwb技术的室内定位系统改进最小二乘法" tabindex="-1"><a class="header-anchor" href="#基于uwb技术的室内定位系统改进最小二乘法"><span>基于UWB技术的室内定位系统改进最小二乘法</span></a></h1><h2 id="研究问题-7" tabindex="-1"><a class="header-anchor" href="#研究问题-7"><span>研究问题：</span></a></h2><p>如何通过改进的最小二乘法提高使用超宽带（UWB）技术的室内定位系统的准确性和可靠性？</p><h2 id="提出方法-3" tabindex="-1"><a class="header-anchor" href="#提出方法-3"><span>提出方法：</span></a></h2><p>本研究采用了一种修改后的线性化最小二乘方法来估计封闭建筑物内移动站的位置。该方法包括信号处理、距离测量和位置计算等多个步骤。</p><ol><li><strong>信号处理</strong>：对来自UWB无线电的原始数据进行处理，以减少噪声并减轻非视距（NLOS）效应的影响。</li><li><strong>距离测量</strong>：使用精确的时间差到达（TDOA）测量来计算锚节点与移动站之间的距离。</li><li><strong>位置计算</strong>：应用改进的最小二乘方法解决定位问题，并考虑UWB信号和室内环境的特定特征。</li></ol><h2 id="创新点-7" tabindex="-1"><a class="header-anchor" href="#创新点-7"><span>创新点：</span></a></h2><ol><li><strong>修改后的线性化最小二乘法</strong>：提出的方法引入了一种新颖的方法，通过结合线性化技术来增强传统的最小二乘算法。</li><li><strong>噪声减少</strong>：采用先进的信号处理方法以降低噪声水平，从而提高距离测量的可靠性。</li><li><strong>NLOS缓解</strong>：专门针对UWB信号设计的技术有助于减轻室内环境中的非视距影响。</li></ol><h3 id="结论-7" tabindex="-1"><a class="header-anchor" href="#结论-7"><span>结论：</span></a></h3><p>改进后的最小二乘法显著提高了基于超宽带技术的室内定位系统的准确性和可靠性。该方法在精度和对噪声及非视距条件等环境挑战的鲁棒性方面优于现有方法。未来的工作可以进一步优化以适应更广泛的室内场景，从而提高性能。</p><h2 id="原文链接-6" tabindex="-1"><a class="header-anchor" href="#原文链接-6"><span>原文链接</span></a></h2><p>https://www.minarjournal.com/dergi/a-new-descriptive-estimate-of-distance-algorithms-utilising-uwb-technology20241002124352.pdf</p><h1 id="基于高分辨率雷达图像的定位方法研究" tabindex="-1"><a class="header-anchor" href="#基于高分辨率雷达图像的定位方法研究"><span>基于高分辨率雷达图像的定位方法研究</span></a></h1><h2 id="研究问题-8" tabindex="-1"><a class="header-anchor" href="#研究问题-8"><span>研究问题</span></a></h2><p>如何有效利用高分辨率雷达图象进行室内定位？</p><h2 id="方法-4" tabindex="-1"><a class="header-anchor" href="#方法-4"><span>方法</span></a></h2><p>提出了一种灵活的流水线作为实现各种检测、描述和匹配算法的基础，这些算法专门针对雷达图像进行了优化。关键贡献包括：</p><ul><li>使用特定于雷达的关键点探测器来识别可靠的跟踪关键点。</li><li>采用Detect Don’t Describe - Describe Don’t Detect（DeDoDe）描述符模型，该模型在独立的机器学习描述符中表现出最先进的性能。</li><li>结合恒虚警率（CFAR）算法与DeDoDe，创建了一种雷达视觉混合方法用于定位。</li></ul><h2 id="创新点-8" tabindex="-1"><a class="header-anchor" href="#创新点-8"><span>创新点</span></a></h2><ol><li><strong>灵活流水线</strong>：由于描述符模型的一般性，此流水线能够适应雷达图像以外的其他输入类型。</li><li><strong>SLAM系统中的闭环检测</strong>：旨在为未来的Simultaneous Localization And Mapping（SLAM）系统的闭环检测提供坚实的基础。</li><li><strong>无需再训练即可实现可靠性能</strong>：无需重新训练或微调描述符模型，就能在部署时达到可靠的性能。</li></ol><h2 id="结论-8" tabindex="-1"><a class="header-anchor" href="#结论-8"><span>结论</span></a></h2><p>本文提出并评估了一种基于高分辨率雷达图像的室内定位的有效雷达视觉混合方法。这种方法实现了相关SAR图像之间的中位欧几里得平移误差小于1厘米的目标。流水线的灵活性允许其适应各种SLAM应用，而不仅仅限于当前数据集。</p><hr><ul><li><strong>作者:</strong> Frank Holzmüller</li><li><strong>URN:</strong> urn:nbn🇩🇪bsz:753-opus4-33411</li><li><strong>评审人:</strong> Markus Enzweiler, Thao Dang</li><li><strong>导师:</strong> Yuma-Elia Ritterbusch</li><li><strong>文档类型:</strong> 硕士论文</li><li><strong>语言:</strong> 英文</li><li><strong>完成年份:</strong> 2024</li><li><strong>发布机构:</strong> Esslingen大学</li><li><strong>授予机构:</strong> Esslingen大学</li><li><strong>最终考试日期:</strong> 2024/10/01</li><li><strong>发布时间:</strong> 2024/10/10</li><li><strong>页数:</strong> 118</li><li><strong>开放获取:</strong> 可免费访问</li></ul><h2 id="原文链接-7" tabindex="-1"><a class="header-anchor" href="#原文链接-7"><span>原文链接</span></a></h2><p>https://hses.bsz-bw.de/frontdoor/index/index/docId/3341</p><h1 id="基于统一衰落模型的物联网边缘设备实时定位方法" tabindex="-1"><a class="header-anchor" href="#基于统一衰落模型的物联网边缘设备实时定位方法"><span>基于统一衰落模型的物联网边缘设备实时定位方法</span></a></h1><h2 id="研究问题-9" tabindex="-1"><a class="header-anchor" href="#研究问题-9"><span>研究问题</span></a></h2><p>如何利用统一衰落模型在物联网边缘设备上高效实现实时定位？</p><h2 id="方法-5" tabindex="-1"><a class="header-anchor" href="#方法-5"><span>方法</span></a></h2><p>本文提出使用统一衰落模型来增强物联网（IoT）边缘设备中的实时定位能力。该方法涉及整合各种通信信道和环境中观察到的不同衰落特性，从而提高准确性和可靠性。</p><h2 id="创新点-9" tabindex="-1"><a class="header-anchor" href="#创新点-9"><span>创新点</span></a></h2><ol><li><strong>统一衰落模型</strong>：引入了一个综合的衰落模型，合并了不同的信道条件和环境因素。</li><li><strong>实时处理</strong>: 设计高效的算法以实现在边缘设备上对实时数据进行处理，确保即时反馈和响应能力。</li><li><strong>可扩展性和灵活性</strong>: 系统设计考虑了适应不同物联网部署以及未来技术进步的需求。</li></ol><h2 id="结论-9" tabindex="-1"><a class="header-anchor" href="#结论-9"><span>结论</span></a></h2><p>所提出的方法成功解决了物联网定位中的关键挑战，提供了一个增强准确度、可靠性和实时性能的稳健框架。这种方法为需要精确位置服务的边缘设备应用设定了新标准。</p><h2 id="原文链接-8" tabindex="-1"><a class="header-anchor" href="#原文链接-8"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10713179/</p><h1 id="利用改进的线性最小二乘法与uwb技术实现增强型室内定位系统" tabindex="-1"><a class="header-anchor" href="#利用改进的线性最小二乘法与uwb技术实现增强型室内定位系统"><span>利用改进的线性最小二乘法与UWB技术实现增强型室内定位系统</span></a></h1><h2 id="研究问题-10" tabindex="-1"><a class="header-anchor" href="#研究问题-10"><span>研究问题</span></a></h2><p>如何利用超宽带（UWB）技术并通过采用改进的线性最小二乘方法来提高室内定位系统的精度和可靠性？</p><h2 id="提出方法-4" tabindex="-1"><a class="header-anchor" href="#提出方法-4"><span>提出方法</span></a></h2><p>本研究的方法是利用现有的商用无线电模块在UWB环境中建立距离测量。采用一种新颖的算法，即改进的线性最小二乘法，对受限空间如建筑物内的位置估计进行精化，以缓解非视距（NLOS）条件等影响距离测量准确性的问题。</p><h3 id="步骤" tabindex="-1"><a class="header-anchor" href="#步骤"><span>步骤：</span></a></h3><ol><li>在封闭建筑内设置一个包含多个定位锚节点和至少一个移动站的U沃布（UWB）定位网络。</li><li>使用商用无线电模块测量移动站与每个锚节点之间的距离，并考虑到可能对测距准确性产生影响的NLOS因素。</li><li>实施改进的线性最小二乘算法，基于所测得的距离数据进行位置估计的迭代精化。</li><li>通过计算估算位置和实际位置之间的精度指标来评估定位系统的性能。</li></ol><h2 id="创新点-10" tabindex="-1"><a class="header-anchor" href="#创新点-10"><span>创新点</span></a></h2><ol><li><strong>自适应信道探测:</strong> 为确保可靠的UWB通信，采用一种动态调整传输功率和定时的方法，并根据信道条件使用PID控制器进行优化。</li><li><strong>NLOS缓解策略:</strong> 系统集成了一个强大的NLOS检测机制，能够识别并纠正受障碍物或反射表面影响的位置估计，从而提高整体准确性。</li><li><strong>节能性:</strong> 通过限制移动传感器的感知范围只包含那些对定位精度有显著贡献的节点来减少能源消耗，同时不牺牲性能。</li></ol><h2 id="结论-10" tabindex="-1"><a class="header-anchor" href="#结论-10"><span>结论</span></a></h2><p>在UWB技术基础上的室内定位系统中应用改进的线性最小二乘方法极大地提高了位置准确性和可靠性，特别是在挑战性的NLOS条件下。该创新方法不仅超越了传统的最小二乘法，还集成了自适应信道探测以实现通信质量和能源效率的最大化。结果证实了此技术在支持各种行业的准确和高效的室内跟踪应用方面的潜力。</p><hr><p>确保每个部分保持原意并符合原始结构要求。</p><h2 id="原文链接-9" tabindex="-1"><a class="header-anchor" href="#原文链接-9"><span>原文链接</span></a></h2><p>https://www.minarjournal.com/dergi/a-new-descriptive-estimate-of-distance-algorithms-utilising-uwb-technology20241002124352.pdf</p><h1 id="vins-mono-稳健且多功能的单目视觉惯性状态估计器" tabindex="-1"><a class="header-anchor" href="#vins-mono-稳健且多功能的单目视觉惯性状态估计器"><span>VINS-Mono：稳健且多功能的单目视觉惯性状态估计器</span></a></h1><h2 id="研究问题-11" tabindex="-1"><a class="header-anchor" href="#研究问题-11"><span>研究问题</span></a></h2><p>如何构建一个稳健且多用途的单目视觉惯性状态估计器，以实现鲁棒和准确的状态估计。</p><h2 id="提出方法-5" tabindex="-1"><a class="header-anchor" href="#提出方法-5"><span>提出方法</span></a></h2><p>该论文提出了一种基于单目相机和惯性传感器的数据融合技术。具体来说，它利用了EKF（扩展卡尔曼滤波）框架来处理非线性的系统模型，并通过引入右不变误差状态的表示法确保了系统的稳健性和一致性。此外，还讨论了如何有效初始化视觉惯性估计器以及如何在实际应用中提高性能。</p><h2 id="创新点-11" tabindex="-1"><a class="header-anchor" href="#创新点-11"><span>创新点</span></a></h2><p>该论文的主要贡献在于开发了一种鲁棒且高效的单目视觉惯性状态估计算法VINS-Mono，它结合了EKF和右不变误差状态表示的优点，适用于广泛的应用场景。此外，提出的方法在处理大规模数据集时能够保持高效性和准确性。</p><h3 id="结论-11" tabindex="-1"><a class="header-anchor" href="#结论-11"><span>结论</span></a></h3><p>实验结果表明，所提出的VINS-Mono算法能够在各种条件下实现稳健的状态估计，并且具有良好的实际应用潜力。通过详细的分析与对比测试，论文验证了其相较于其他方法的优越性。</p><hr><h1 id="利用学习单视图深度信息快速初始化单目视觉惯性导航系统" tabindex="-1"><a class="header-anchor" href="#利用学习单视图深度信息快速初始化单目视觉惯性导航系统"><span>利用学习单视图深度信息快速初始化单目视觉惯性导航系统</span></a></h1><h2 id="研究问题-12" tabindex="-1"><a class="header-anchor" href="#研究问题-12"><span>研究问题</span></a></h2><p>如何快速初始化单目视觉惯性导航系统，以利用学习到的单视图深度信息提高性能。</p><h2 id="提出方法-6" tabindex="-1"><a class="header-anchor" href="#提出方法-6"><span>提出方法</span></a></h2><p>该论文提出了一种基于学习模型的方法来估计单目图像中的深度信息，并使用这些深度数据进行高效的初始定位。具体来说，它结合了机器学习算法与传统VINS框架，通过从大量数据中提取有用的特征和模式来加速初始化过程。</p><h2 id="创新点-12" tabindex="-1"><a class="header-anchor" href="#创新点-12"><span>创新点</span></a></h2><p>利用预先训练的深度学习模型来辅助视觉惯性导航系统的初始化，显著减少了初始化时间，并提高了精度。这种策略在快速动态环境中特别有效。</p><h3 id="结论-12" tabindex="-1"><a class="header-anchor" href="#结论-12"><span>结论</span></a></h3><p>实验结果表明，在多种场景下，所提出的方法能够以更快的速度完成单目视觉惯性初始化任务，并且保持了较高的估计准确性。</p><hr><h1 id="基于平方根滤波器的超快vins" tabindex="-1"><a class="header-anchor" href="#基于平方根滤波器的超快vins"><span>基于平方根滤波器的超快VINS</span></a></h1><h2 id="研究问题-13" tabindex="-1"><a class="header-anchor" href="#研究问题-13"><span>研究问题</span></a></h2><p>如何构建一种超快的滤波器来改善视觉惯性导航系统的性能。</p><h2 id="提出方法-7" tabindex="-1"><a class="header-anchor" href="#提出方法-7"><span>提出方法</span></a></h2><p>该论文介绍了一种基于平方根滤波器（SRF）的方法，旨在提高VINS的计算效率和鲁棒性。通过优化算法结构和参数设置，使系统在处理大规模数据时依然保持高效性和准确性。</p><h2 id="创新点-13" tabindex="-1"><a class="header-anchor" href="#创新点-13"><span>创新点</span></a></h2><p>提出了基于优化的EKF与右不变误差状态相结合的新方法，在保证估计精度的同时极大提升了计算效率。</p><h3 id="结论-13" tabindex="-1"><a class="header-anchor" href="#结论-13"><span>结论</span></a></h3><p>实验表明，所提的方法能够有效改善VINS系统的性能，并且能够在不同的动态环境中实现稳定的运行效果。这为实际应用提供了可靠的解决方案和技术支持。</p><hr><h1 id="评估视觉-惯性-里程计生成轨迹的质量教程" tabindex="-1"><a class="header-anchor" href="#评估视觉-惯性-里程计生成轨迹的质量教程"><span>评估视觉（-惯性）里程计生成轨迹的质量教程</span></a></h1><h2 id="研究问题-14" tabindex="-1"><a class="header-anchor" href="#研究问题-14"><span>研究问题</span></a></h2><p>如何准确评估视觉（-惯性）里程计生成轨迹的质量。</p><h2 id="提出方法-8" tabindex="-1"><a class="header-anchor" href="#提出方法-8"><span>提出方法</span></a></h2><p>本文提供了一套详细的指导说明，用于定量分析和评价视觉（或视觉-惯性）里程计的结果。该教程涵盖了多种常用的评测指标，并提供了实施这些评测的具体步骤和建议。</p><h2 id="创新点-14" tabindex="-1"><a class="header-anchor" href="#创新点-14"><span>创新点</span></a></h2><p>为研究人员与开发者提供了评估其工作成果的一系列标准工具和技术，从而促进了这一领域的发展进步。</p><h3 id="结论-14" tabindex="-1"><a class="header-anchor" href="#结论-14"><span>结论</span></a></h3><p>通过遵循本文所介绍的指导原则，用户能够更加客观地评价他们的视觉（或视觉-惯性）里程计性能，并从中获得有价值的见解和反馈意见。这将有助于改进现有技术并推动未来的研究方向。</p><hr><h1 id="如何构建一个鲁棒且高效的单目视觉惯性状态估计器" tabindex="-1"><a class="header-anchor" href="#如何构建一个鲁棒且高效的单目视觉惯性状态估计器"><span>如何构建一个鲁棒且高效的单目视觉惯性状态估计器</span></a></h1><h2 id="研究问题-15" tabindex="-1"><a class="header-anchor" href="#研究问题-15"><span>研究问题</span></a></h2><p>如何构建一个鲁棒且高效的单目视觉惯性状态估计器。</p><h2 id="提出方法-9" tabindex="-1"><a class="header-anchor" href="#提出方法-9"><span>提出方法</span></a></h2><p>该论文探讨了利用扩展卡尔曼滤波（EKF）框架并引入右不变误差表示的方法来提高VINS的性能。通过优化算法结构和参数设置，使系统在处理大规模数据时依然保持高效性和准确性。</p><h2 id="创新点-15" tabindex="-1"><a class="header-anchor" href="#创新点-15"><span>创新点</span></a></h2><p>提出了基于优化的EKF与右不变误差状态相结合的新方法，在保证估计精度的同时极大提升了计算效率。</p><h3 id="结论-15" tabindex="-1"><a class="header-anchor" href="#结论-15"><span>结论</span></a></h3><p>实验表明，所提的方法能够有效改善VINS系统的性能，并且能够在不同的动态环境中实现稳定的运行效果。这为实际应用提供了可靠的解决方案和技术支持。</p><h2 id="原文链接-10" tabindex="-1"><a class="header-anchor" href="#原文链接-10"><span>原文链接</span></a></h2><p>https://www.algorithmic-robotics.org/papers/14_Visual_Inertial_State_Estim.pdf</p><h1 id="dp-vins-适用于自主车辆的动态自适应平面基视觉惯性同时定位与地图构建系统" tabindex="-1"><a class="header-anchor" href="#dp-vins-适用于自主车辆的动态自适应平面基视觉惯性同时定位与地图构建系统"><span>DP-VINS：适用于自主车辆的动态自适应平面基视觉惯性同时定位与地图构建系统</span></a></h1><h2 id="研究问题-16" tabindex="-1"><a class="header-anchor" href="#研究问题-16"><span>研究问题</span></a></h2><p>如何设计一种适用于自主车辆的视觉惯性同时定位与地图构建（Visual-Inertial Simultaneous Localization and Mapping, VINS）系统，该系统能够自适应地处理动态环境中的平面特征，并提高系统的鲁棒性和准确性？</p><h2 id="方法-6" tabindex="-1"><a class="header-anchor" href="#方法-6"><span>方法</span></a></h2><p>DP-VINS系统采用以下方法：</p><ol><li><strong>动态自适应算法</strong>：根据当前的运动状态和环境特性，调整SLAM算法中平面检测与跟踪的方法。</li><li><strong>基于平面的视觉惯性融合</strong>：通过提取并使用平面特征来改善位姿估计的质量，并减少误差累积。</li></ol><h2 id="创新点-16" tabindex="-1"><a class="header-anchor" href="#创新点-16"><span>创新点</span></a></h2><ul><li>引入了一种新的动态自适应机制，使系统能够更好地处理快速变化和复杂环境中的平面特征。</li><li>通过对平面特征的有效利用，显著提高了视觉惯性SLAM系统的鲁棒性和精度。</li></ul><h2 id="结论-16" tabindex="-1"><a class="header-anchor" href="#结论-16"><span>结论</span></a></h2><p>DP-VINS通过引入创新的自适应算法和技术，在提高自主车辆在动态环境中进行同时定位与地图构建的能力方面取得了重要进展。实验结果表明该系统能够有效地处理快速变化和复杂环境，并提供了更高的定位准确性。</p><h2 id="原文链接-11" tabindex="-1"><a class="header-anchor" href="#原文链接-11"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10711935/</p><h1 id="基于人工交流磁场的磁惯性里程计设计" tabindex="-1"><a class="header-anchor" href="#基于人工交流磁场的磁惯性里程计设计"><span>基于人工交流磁场的磁惯性里程计设计</span></a></h1><h2 id="研究问题-17" tabindex="-1"><a class="header-anchor" href="#研究问题-17"><span>研究问题</span></a></h2><p>如何利用人工交流磁场有效地设计磁惯性里程计，以提高室外环境中的定位精度和鲁棒性？</p><h2 id="方法-7" tabindex="-1"><a class="header-anchor" href="#方法-7"><span>方法</span></a></h2><p>本文提出了一种新颖的方法，通过结合人工交流磁场与惯性传感器实现精确的姿态估计。该方法包括部署多个电磁源发射空间可区分的交流磁场信号，并配合IMU（惯性测量单元）来测量加速度、角速度和姿态数据。采用滤波算法融合这些多传感器观测结果，从而提供车辆位置和姿态的连续估计。</p><h2 id="创新点-17" tabindex="-1"><a class="header-anchor" href="#创新点-17"><span>创新点</span></a></h2><ol><li><strong>人工磁场所部署</strong>：利用人工交流磁场作为定位时的一种额外环境线索。</li><li><strong>传感器融合算法</strong>：开发了一种稳健的传感器融合算法，有效结合IMU数据与磁场测量值以提升定位精度。</li><li><strong>室外鲁棒性</strong>：所提出的系统在具有挑战性的室外条件下（如树荫下或靠近金属结构）表现出高性能和可靠性。</li></ol><h2 id="结论-17" tabindex="-1"><a class="header-anchor" href="#结论-17"><span>结论</span></a></h2><p>本研究成功建立了一个新的范式，在室外导航中利用人工交流磁场并结合传统惯性传感器。该方法不仅提高了姿态估计的精度，还提供了显著优于传统方法的优势，特别是在多样环境下的鲁棒性和适应性方面。</p><h2 id="原文链接-12" tabindex="-1"><a class="header-anchor" href="#原文链接-12"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10705787/</p><h1 id="人工智能辅助地磁导航框架-1" tabindex="-1"><a class="header-anchor" href="#人工智能辅助地磁导航框架-1"><span>人工智能辅助地磁导航框架</span></a></h1><h2 id="研究问题-18" tabindex="-1"><a class="header-anchor" href="#研究问题-18"><span>研究问题</span></a></h2><p>如何利用人工智能增强地磁导航，以实现更加准确和可靠的定位？</p><h2 id="方法-8" tabindex="-1"><a class="header-anchor" href="#方法-8"><span>方法</span></a></h2><p>该研究涉及开发一个结合机器学习算法与地磁数据的AI辅助框架。具体步骤如下：</p><ol><li><strong>数据收集</strong>：从不同地点广泛采集地磁数据。</li><li><strong>预处理</strong>：清理并规范化所收集的数据，确保一致性。</li><li><strong>模型开发</strong>：在预处理数据上训练神经网络及其他机器学习模型。</li><li><strong>验证</strong>：通过模拟和实际应用测试AI辅助框架的准确性。</li></ol><h2 id="创新点-18" tabindex="-1"><a class="header-anchor" href="#创新点-18"><span>创新点</span></a></h2><p>创新之处在于将先进的机器学习技术与地磁导航相结合，在各种环境条件下增强了定位精度和鲁棒性。</p><h2 id="结论-18" tabindex="-1"><a class="header-anchor" href="#结论-18"><span>结论</span></a></h2><p>本研究证明了人工智能可以显著提高地磁导航系统的性能。提出的框架为增强定位精度提供了一种可靠的方法，并在该领域提供了新的研发机会。</p><h2 id="原文链接-13" tabindex="-1"><a class="header-anchor" href="#原文链接-13"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10713176/</p><h1 id="基于改进wknn算法的csi被动室内指纹定位方法" tabindex="-1"><a class="header-anchor" href="#基于改进wknn算法的csi被动室内指纹定位方法"><span>基于改进WKNN算法的CSI被动室内指纹定位方法</span></a></h1><h2 id="研究问题-19" tabindex="-1"><a class="header-anchor" href="#研究问题-19"><span>研究问题</span></a></h2><p>如何提高基于信道状态信息（CSI）的被动室内定位系统的准确性与可靠性，特别是在处理幅度和相位构造中干扰过多的问题。</p><h2 id="提出方法-10" tabindex="-1"><a class="header-anchor" href="#提出方法-10"><span>提出方法</span></a></h2><p>该研究提出了一种结合改进加权K近邻（WKNN）算法的新方法，用于处理信道状态信息以实现被动室内定位。这种方法包括两个阶段：</p><ol><li><p><strong>离线阶段</strong>:</p><ul><li>收集原始CSI数据。</li><li>使用隔离森林算法对采集的数据进行异常检测。</li><li>采用带改进阈值的小波域去噪技术滤除CSI测量中的噪声。</li></ul></li><li><p><strong>在线阶段</strong>:</p><ul><li>实时处理已清洗的CSI特征，利用改进的加权K近邻（WKNN）分类器进行定位。</li></ul></li></ol><h2 id="创新点-19" tabindex="-1"><a class="header-anchor" href="#创新点-19"><span>创新点</span></a></h2><ul><li>首次将隔离森林应用于原始CSI数据异常检测中，提高数据质量。</li><li>改进的小波域去噪技术采用自适应阈值优化噪声去除效果而不影响有用信号完整性。</li><li>特别针对处理后的CSI特征开发了改进的WKNN算法以用于室内定位，提升定位精度。</li></ul><h2 id="结论-19" tabindex="-1"><a class="header-anchor" href="#结论-19"><span>结论</span></a></h2><p>该方法通过解决幅度和相位测量中的干扰问题显著提高了基于信道状态信息的被动室内定位系统的准确性和可靠性。实验结果表明其性能优于现有方法。</p><h2 id="原文链接-14" tabindex="-1"><a class="header-anchor" href="#原文链接-14"><span>原文链接</span></a></h2><p>http://crestapress.org/index.php/sidr/article/view/71</p><h1 id="文档标题" tabindex="-1"><a class="header-anchor" href="#文档标题"><span>文档标题</span></a></h1><h2 id="研究问题-20" tabindex="-1"><a class="header-anchor" href="#研究问题-20"><span>研究问题</span></a></h2><ol><li>智能盲杖如何改善视力障碍人士的导航体验？</li><li>如何最好地将游戏和创新用户界面融入辅助技术中？</li><li>社交连接与增强感官反馈如何用于提高可访问性？</li></ol><h2 id="方法-9" tabindex="-1"><a class="header-anchor" href="#方法-9"><span>方法</span></a></h2><p>研究采用了定性和定量相结合的方法，包括对视力障碍者进行半结构化访谈、使用辅助导航设备的用户测试、现有系统的比较分析以及参与式设计。</p><h2 id="创新点-20" tabindex="-1"><a class="header-anchor" href="#创新点-20"><span>创新点</span></a></h2><ol><li><strong>智能盲杖</strong>：开发一款配备高级传感器的智能盲杖，以提高导航能力并提供实时信息。</li><li><strong>创新用户界面</strong>：创建基于游戏集成的用户界面，使辅助技术更加有趣且互动性更强。</li><li><strong>改进感官反馈系统</strong>：利用先进的感官反馈系统来改善用户的环境感知。</li></ol><h2 id="结论-20" tabindex="-1"><a class="header-anchor" href="#结论-20"><span>结论</span></a></h2><p>研究发现，将智能盲杖与创新用户界面以及改进后的感官反馈系统相结合，可以大大提升视力障碍人士的移动性和可访问性。此外，结果还表明辅助技术有潜力融入游戏和社交元素，从而创造一个更有趣且包容的环境。</p><h2 id="原文链接-15" tabindex="-1"><a class="header-anchor" href="#原文链接-15"><span>原文链接</span></a></h2><p>https://constellation.uqac.ca/id/eprint/9934/</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: zhangleilikejay@gmail.com">zhanglei</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/papers/20241013_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241013_室内定位"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>20241013_室内定位</span></div></a><a class="route-link auto-link next" href="/papers/20241020_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241020_室内定位"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>20241020_室内定位</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BNyMW1Pp.js" defer></script>
  </body>
</html>
