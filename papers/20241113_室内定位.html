<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.15" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>20241113_室内定位 | 室内定位技术</title><meta name="description" content="20241113_室内定位">
    <link rel="preload" href="/assets/style-CQdWRPUu.css" as="style"><link rel="stylesheet" href="/assets/style-CQdWRPUu.css">
    <link rel="modulepreload" href="/assets/app-BNyMW1Pp.js"><link rel="modulepreload" href="/assets/20241113_室内定位.html-CIlnpdvd.js">
    <link rel="prefetch" href="/assets/index.html-CN6bKgNh.js" as="script"><link rel="prefetch" href="/assets/商务合作.html-B_MZzLvb.js" as="script"><link rel="prefetch" href="/assets/20240917_大模型.html-X3OOYWbP.js" as="script"><link rel="prefetch" href="/assets/20241004_大模型.html-CBWN5Uzp.js" as="script"><link rel="prefetch" href="/assets/20241009_大模型.html-B6PzKIfN.js" as="script"><link rel="prefetch" href="/assets/20241010_大模型.html-BrdLK9SK.js" as="script"><link rel="prefetch" href="/assets/20241011_大模型.html-D0P1ze6b.js" as="script"><link rel="prefetch" href="/assets/20241013_大模型.html-Bs3WihAf.js" as="script"><link rel="prefetch" href="/assets/20241016_大模型.html-BrRt6qIt.js" as="script"><link rel="prefetch" href="/assets/20241020_大模型.html-DoMek0Tc.js" as="script"><link rel="prefetch" href="/assets/20241029_大模型.html-DKAwjp16.js" as="script"><link rel="prefetch" href="/assets/20241103_大模型.html-Mpvcw7pT.js" as="script"><link rel="prefetch" href="/assets/20241104_大模型.html-D-3xTwnR.js" as="script"><link rel="prefetch" href="/assets/20241109_大模型.html-BbNxPEnG.js" as="script"><link rel="prefetch" href="/assets/20241111_大模型.html-D3i6DeTL.js" as="script"><link rel="prefetch" href="/assets/20241113_大模型.html-B_YQKXXR.js" as="script"><link rel="prefetch" href="/assets/20241117_大模型.html-Ca56tr58.js" as="script"><link rel="prefetch" href="/assets/20241122_大模型.html-HxWcpDcy.js" as="script"><link rel="prefetch" href="/assets/20241125_大模型.html-D1EtwN2M.js" as="script"><link rel="prefetch" href="/assets/20241129_大模型.html-CSnUTIPm.js" as="script"><link rel="prefetch" href="/assets/index.html-C_LCynFL.js" as="script"><link rel="prefetch" href="/assets/20240911_室内定位.html-BFdMEQUj.js" as="script"><link rel="prefetch" href="/assets/20240916_室内定位.html-BJPJbT_H.js" as="script"><link rel="prefetch" href="/assets/20240920_室内定位.html-lrSGz_0s.js" as="script"><link rel="prefetch" href="/assets/20240925_室内定位.html-Bog0JN0o.js" as="script"><link rel="prefetch" href="/assets/20240930_室内定位.html-B9hMwxIg.js" as="script"><link rel="prefetch" href="/assets/20241004_室内定位.html-BgrTH2Wy.js" as="script"><link rel="prefetch" href="/assets/20241009_室内定位.html-B2LVVzQz.js" as="script"><link rel="prefetch" href="/assets/20241010_室内定位.html-DUn6dOkd.js" as="script"><link rel="prefetch" href="/assets/20241011_室内定位.html-BmTLgQg1.js" as="script"><link rel="prefetch" href="/assets/20241013_室内定位.html-DabVPX23.js" as="script"><link rel="prefetch" href="/assets/20241016_室内定位.html-Balntghz.js" as="script"><link rel="prefetch" href="/assets/20241020_室内定位.html-Cvw4xHVR.js" as="script"><link rel="prefetch" href="/assets/20241029_室内定位.html-naMN3cmT.js" as="script"><link rel="prefetch" href="/assets/20241103_室内定位.html-D0e39Egn.js" as="script"><link rel="prefetch" href="/assets/20241104_室内定位.html-iWpK0plg.js" as="script"><link rel="prefetch" href="/assets/20241109_室内定位.html-C91Wj9qt.js" as="script"><link rel="prefetch" href="/assets/20241111_室内定位.html-iD_YoNXW.js" as="script"><link rel="prefetch" href="/assets/20241117_室内定位.html-C5sThFiI.js" as="script"><link rel="prefetch" href="/assets/20241122_室内定位.html-DMOx-29k.js" as="script"><link rel="prefetch" href="/assets/20241125_室内定位.html-BxxMjI3J.js" as="script"><link rel="prefetch" href="/assets/20241129_室内定位.html-Bxh_uwBi.js" as="script"><link rel="prefetch" href="/assets/index.html-BfmMMuC7.js" as="script"><link rel="prefetch" href="/assets/404.html-BgPKVjBy.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://lark-assets-prod-aliyun.oss-cn-hangzhou.aliyuncs.com/yuque/0/2024/jpeg/354158/1717584738049-5a4ffdae-d469-44a9-b298-f86934b6e14c.jpeg?date=1717585212400" alt="室内定位技术"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">室内定位技术</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">论文列表 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240911_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240911_室内定位"><!---->20240911_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240916_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240916_室内定位"><!---->20240916_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240920_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240920_室内定位"><!---->20240920_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240925_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240925_室内定位"><!---->20240925_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240930_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240930_室内定位"><!---->20240930_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241004_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241004_室内定位"><!---->20241004_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241009_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241009_室内定位"><!---->20241009_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241010_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241010_室内定位"><!---->20241010_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241011_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241011_室内定位"><!---->20241011_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241013_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241013_室内定位"><!---->20241013_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241016_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241016_室内定位"><!---->20241016_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241020_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241020_室内定位"><!---->20241020_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241029_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241029_室内定位"><!---->20241029_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241103_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241103_室内定位"><!---->20241103_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241104_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241104_室内定位"><!---->20241104_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241109_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241108_室内定位"><!---->20241108_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241111_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241111_室内定位"><!---->20241111_室内定位<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/papers/20241113_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241113_室内定位"><!---->20241113_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241117_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241117_室内定位"><!---->20241117_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241122_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241122_室内定位"><!---->20241122_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241125_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241125_室内定位"><!---->20241125_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241129_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241129_室内定位"><!---->20241129_室内定位<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h1 id="天文导航算法在低成本视觉系统中的应用" tabindex="-1"><a class="header-anchor" href="#天文导航算法在低成本视觉系统中的应用"><span>天文导航算法在低成本视觉系统中的应用</span></a></h1><h2 id="关键词" tabindex="-1"><a class="header-anchor" href="#关键词"><span>关键词</span></a></h2><p>天文导航；自主无人机；GNSS拒止环境；稳定成像系统；星图识别；姿态估计；位置估算</p><h2 id="研究问题" tabindex="-1"><a class="header-anchor" href="#研究问题"><span>研究问题</span></a></h2><p>现代无人驾驶飞行器（UAV）中，很少使用天文学导航技术。传统的天文学导航依赖于稳定的成像系统，这不仅体积大且重量重，难以满足飞行器的性能需求。另外，在没有全球定位系统（GNSS）信号的情况下，如何实现精确和可靠的天文导航是一个重要的问题。</p><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><p>提出了一种基于低成本视觉系统的天文导航算法。该方法结合了星图识别技术和姿态估计技术，使用无人机携带的小型稳定成像设备来捕捉星空图像，并通过软件分析这些图像以确定位置和方向。具体步骤如下：</p><ol><li>使用摄像头拍摄天空中的恒星。</li><li>应用计算机视觉算法进行星图匹配，将所摄图像与已知星图数据库对比以识别特定的星星或星座。</li><li>依据识别到的星空信息来估计飞行器的姿态（姿态角包括俯仰角、偏航角和滚动角）和位置。</li></ol><h2 id="创新点" tabindex="-1"><a class="header-anchor" href="#创新点"><span>创新点</span></a></h2><ol><li><strong>算法优化</strong>：通过采用先进的计算机视觉技术和图像处理技术，使得星图匹配过程更加高效且准确。</li><li><strong>成本效益</strong>：所提出的天文导航系统基于低成本的硬件设备（如手机摄像头），从而大大降低了系统的整体成本。</li><li><strong>自主飞行能力增强</strong>：该系统能在GNSS拒止环境下提供可靠的位置和姿态信息，使无人机能够在复杂环境中实现更稳定的自主飞行。</li></ol><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>本研究提出了一种在无全球定位信号支持下通过低成本视觉设备进行天文导航的创新方法。这种方法成功地解决了传统天文学导航技术体积大、重量重的问题，并且在实际应用中证明了其成本效益和可靠性，为无人机在GNSS拒止环境下的自主飞行提供了一个有效的解决方案。</p><h2 id="原文链接" tabindex="-1"><a class="header-anchor" href="#原文链接"><span>原文链接</span></a></h2><p>https://www.mdpi.com/2504-446X/8/11/652</p><h1 id="通过增强生成网络的视觉化多维指纹数据扩充提高室内定位精度" tabindex="-1"><a class="header-anchor" href="#通过增强生成网络的视觉化多维指纹数据扩充提高室内定位精度"><span>通过增强生成网络的视觉化多维指纹数据扩充提高室内定位精度</span></a></h1><h2 id="关键词-1" tabindex="-1"><a class="header-anchor" href="#关键词-1"><span>关键词</span></a></h2><p>关键词：室内定位, 数据扩充, 视觉化多维指纹, 增强生成网络</p><h2 id="研究问题-1" tabindex="-1"><a class="header-anchor" href="#研究问题-1"><span>研究问题</span></a></h2><p>如何利用增强生成网络对室内空间中的多维传感器数据进行有效的数据扩充，以改善基于视觉化的多维度信号的室内定位精度。</p><h2 id="方法-1" tabindex="-1"><a class="header-anchor" href="#方法-1"><span>方法</span></a></h2><p>本研究提出了一种通过深度学习模型——特别是增强型生成对抗网络（GAN）来扩充和优化室内环境下的多维指纹数据的方法。该方法首先收集一系列具有代表性的室内环境中的无线信号强度、光强等多元传感器数据，并使用GAN进行模拟与真实场景相似的大量训练样本，以此提高定位系统中指纹库的质量。</p><h2 id="创新点-1" tabindex="-1"><a class="header-anchor" href="#创新点-1"><span>创新点</span></a></h2><ol><li>提出了利用增强生成网络技术来扩充多维指纹数据的新方案。</li><li>通过实验验证了该方法在提升室内定位精度方面的有效性。</li><li>解决了传统基于小规模训练集的机器学习模型面对复杂环境时表现不佳的问题，尤其是对于低密度标签的数据。</li></ol><h2 id="结论-1" tabindex="-1"><a class="header-anchor" href="#结论-1"><span>结论</span></a></h2><p>本研究证明了利用增强生成网络对多维指纹数据进行扩充的有效性。通过实验分析发现，该方法在提高室内定位精度方面具有显著效果，并为未来的研究提供了新的方向和视角。</p><h2 id="原文链接-1" tabindex="-1"><a class="header-anchor" href="#原文链接-1"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10747207/</p><h1 id="基于kolmogorov-arnold网络的室内定位模型研究" tabindex="-1"><a class="header-anchor" href="#基于kolmogorov-arnold网络的室内定位模型研究"><span>基于Kolmogorov-Arnold网络的室内定位模型研究</span></a></h1><h2 id="关键词-2" tabindex="-1"><a class="header-anchor" href="#关键词-2"><span>关键词</span></a></h2><p>室内定位, Kolmogorov-Arnold网络, 深度学习, 机器学习</p><h2 id="研究问题-2" tabindex="-1"><a class="header-anchor" href="#研究问题-2"><span>研究问题</span></a></h2><p>如何利用深度学习方法提高基于WiFi指纹的室内定位精度？</p><h2 id="方法-2" tabindex="-1"><a class="header-anchor" href="#方法-2"><span>方法</span></a></h2><p>本文提出了一种新的基于Kolmogorov-Arnold（KAN）网络的室内定位模型。该模型结合了传统的Wi-Fi信号强度信息，通过深度神经网络结构对复杂的空间位置特征进行建模，并使用监督学习和半监督学习方法来优化模型。</p><h2 id="创新点-2" tabindex="-1"><a class="header-anchor" href="#创新点-2"><span>创新点</span></a></h2><ol><li>提出了基于Kolmogorov-Arnold（KAN）网络的室内定位算法。</li><li>将传统的Wi-Fi指纹数据与深度神经网络相结合，以提高室内定位精度。</li><li>通过实验验证了所提方法的有效性，并且相比传统的方法在精度上有显著提升。</li></ol><h2 id="结论-2" tabindex="-1"><a class="header-anchor" href="#结论-2"><span>结论</span></a></h2><p>研究结果表明，基于Kolmogorov-Arnold（KAN）网络的模型能够有效提高基于Wi-Fi指纹的室内定位精度。相较于传统的机器学习和深度学习算法，在处理复杂的室内环境时具有更高的效率和准确性。</p><h2 id="原文链接-2" tabindex="-1"><a class="header-anchor" href="#原文链接-2"><span>原文链接</span></a></h2><p>https://www.espublisher.com/uploads/article_pdf/es1289.pdf</p><h1 id="wifi-rtt-slam-基于wifi-rtt和智能手机惯性传感器的未映射环境中的行人导航" tabindex="-1"><a class="header-anchor" href="#wifi-rtt-slam-基于wifi-rtt和智能手机惯性传感器的未映射环境中的行人导航"><span>WiFi-RTT SLAM：基于WiFi RTT和智能手机惯性传感器的未映射环境中的行人导航</span></a></h1><h2 id="关键词-3" tabindex="-1"><a class="header-anchor" href="#关键词-3"><span>关键词</span></a></h2><p>RTT, WIFI, RSSI, SLAM, 传感器融合, 室内导航, 行人导航, IMU, 航迹推算</p><h2 id="研究问题-3" tabindex="-1"><a class="header-anchor" href="#研究问题-3"><span>研究问题</span></a></h2><p>室内定位的核心问题是缺乏对环境的先验知识。目前基于WiFi RTT技术的室内定位依赖于预先构建的地图或信号模型，这限制了其在未映射环境中的应用。</p><h2 id="方法-3" tabindex="-1"><a class="header-anchor" href="#方法-3"><span>方法</span></a></h2><p>本研究提出了一种利用智能手机内置的惯性传感器（IMU）和Wi-Fi设备进行RTT测量的方法，以实现行人导航系统。通过结合实时采集的数据与滤波算法，能够在未预先建立地图的情况下完成位置估计和路径规划。该方法包括：</p><ol><li>利用智能手机中的Wi-Fi RTT技术获取距离信息。</li><li>采用IMU传感器收集加速度、角速度等数据。</li><li>应用卡尔曼滤波器或其他合适的滤波算法对以上两种来源的数据进行融合处理，提高位置估计的准确性。</li></ol><h2 id="创新点-3" tabindex="-1"><a class="header-anchor" href="#创新点-3"><span>创新点</span></a></h2><p>研究的主要创新在于开发了一种能够在未映射环境中运行的有效行人导航系统。这一方案不需要依赖预先建立的地图或复杂的计算模型，并且能够通过现有的智能手机硬件实现。</p><h2 id="结论-3" tabindex="-1"><a class="header-anchor" href="#结论-3"><span>结论</span></a></h2><p>本研究表明WiFi RTT结合惯性传感器可以在未映射的室内环境中有效地执行行人导航任务，为未来智能设备的应用提供了新的可能性。该方法不仅增强了定位精度和稳定性，而且大大简化了系统的部署过程。然而，在高动态变化或遮挡严重的场景中仍需进一步优化算法以提高鲁棒性和可靠性。</p><h2 id="原文链接-3" tabindex="-1"><a class="header-anchor" href="#原文链接-3"><span>原文链接</span></a></h2><p>https://sciforum.net/paper/view/19981</p><h1 id="基于lidar惯性导航的复杂地下环境姿态估计" tabindex="-1"><a class="header-anchor" href="#基于lidar惯性导航的复杂地下环境姿态估计"><span>基于LiDAR惯性导航的复杂地下环境姿态估计</span></a></h1><h2 id="关键词-4" tabindex="-1"><a class="header-anchor" href="#关键词-4"><span>关键词</span></a></h2><p>LiDAR惯性导航；地下环境；姿态估计</p><h2 id="研究问题-4" tabindex="-1"><a class="header-anchor" href="#研究问题-4"><span>研究问题</span></a></h2><p>在复杂的地下环境中，基于传统视觉信息的姿态估计方法往往效果不佳。本文旨在提出一种适应性强、精度高的基于LiDAR和IMU数据的姿态估计算法。</p><h2 id="方法-4" tabindex="-1"><a class="header-anchor" href="#方法-4"><span>方法</span></a></h2><p>采用Ouster LiDAR传感器结合惯性测量单元(IMU)进行姿态估计。首先利用LiDAR获取环境的点云数据，然后通过IMU提供加速度计与陀螺仪信息。通过对这两种不同类型的数据融合处理，构建了一个自适应的关键帧生成机制，并在此基础上进行了高效的LiDAR惯性里程计计算。</p><h2 id="创新点-4" tabindex="-1"><a class="header-anchor" href="#创新点-4"><span>创新点</span></a></h2><p>提出了适用于复杂地下环境的姿态估计算法，该算法在非视觉受限的环境中表现突出，能够实现高精度定位与导航功能。此外还设计了一套适合不同场景下的关键帧选取策略，极大提高了系统运行效率和鲁棒性。</p><h2 id="结论-4" tabindex="-1"><a class="header-anchor" href="#结论-4"><span>结论</span></a></h2><p>本文提出的方法能够在没有显著特征点或光照变化剧烈等不利条件下准确地估计出目标的姿态信息，在复杂地下环境中具有广泛的应用前景。</p><h2 id="原文链接-4" tabindex="-1"><a class="header-anchor" href="#原文链接-4"><span>原文链接</span></a></h2><p>https://isprs-archives.copernicus.org/articles/XLVIII-3-2024/57/2024/isprs-archives-XLVIII-3-2024-57-2024.pdf</p><h1 id="开放联邦定位与映射引擎-构建大规模分布式定位和服务系统" tabindex="-1"><a class="header-anchor" href="#开放联邦定位与映射引擎-构建大规模分布式定位和服务系统"><span>开放联邦定位与映射引擎：构建大规模分布式定位和服务系统</span></a></h1><h2 id="关键词-5" tabindex="-1"><a class="header-anchor" href="#关键词-5"><span>关键词</span></a></h2><p>分布式计算；并行处理；集群计算</p><h2 id="研究问题-5" tabindex="-1"><a class="header-anchor" href="#研究问题-5"><span>研究问题</span></a></h2><p>当前地图服务主要由少数大公司控制，并且主要集中在外围区域。随着室内定位技术的进步和基于位置的应用程序的普及，亟需一种可扩展、分布式的定位管理系统来覆盖私人空间。</p><h2 id="方法-5" tabindex="-1"><a class="header-anchor" href="#方法-5"><span>方法</span></a></h2><p>我们提出了一个名为OpenFLAME（开放联邦定位与映射引擎）的新系统，这是第一个分布式定位服务。该服务通过链接处理特定区域定位任务的服务器提供无缝的全球视图，并使用域名系统（DNS）进行服务发现和实现地图抽象以检索并融合不同地图之间的位置信息。</p><h2 id="创新点-5" tabindex="-1"><a class="header-anchor" href="#创新点-5"><span>创新点</span></a></h2><p>OpenFLAME利用DNS服务发现机制来解决跨独立提供商的服务整合问题，同时设计了高效的地图抽象机制。通过跟踪驱动的研究证明，在远程服务器上执行联邦定位是可行的，并且可以接受查询延迟。</p><h2 id="结论-5" tabindex="-1"><a class="header-anchor" href="#结论-5"><span>结论</span></a></h2><p>我们开发了一款用于大型室内空间的增强现实导航应用，展示了OpenFLAME成功地支持基于位置的应用程序的能力。该系统具备可扩展性和分布式的特性，能够有效地解决当前地图服务中出现的问题。</p><h2 id="原文链接-5" tabindex="-1"><a class="header-anchor" href="#原文链接-5"><span>原文链接</span></a></h2><p>https://ui.adsabs.harvard.edu/abs/2024arXiv241104271B/abstract</p><h1 id="基于视觉slam的无人机导航技术进展与挑战" tabindex="-1"><a class="header-anchor" href="#基于视觉slam的无人机导航技术进展与挑战"><span>基于视觉SLAM的无人机导航技术进展与挑战</span></a></h1><h2 id="关键词-6" tabindex="-1"><a class="header-anchor" href="#关键词-6"><span>关键词</span></a></h2><p>无人机；视觉SLAM；自主导航；机器人定位</p><h2 id="研究问题-6" tabindex="-1"><a class="header-anchor" href="#研究问题-6"><span>研究问题</span></a></h2><p>随着无人机在各种领域的广泛应用，基于视觉SLAM（Simultaneous Localization and Mapping）的导航方法因其无需外部设备、成本低廉等优点而受到重视。然而，现有技术依然面临一些挑战，如复杂环境下的稳定性不足、计算资源需求大等问题。</p><h2 id="方法-6" tabindex="-1"><a class="header-anchor" href="#方法-6"><span>方法</span></a></h2><p>本文综述了近年来基于视觉SLAM的无人机导航技术的发展状况，着重探讨了几种主要的研究方向和代表性的工作成果，并对其优缺点进行了分析比较。同时，文章还提出了未来可能的研究趋势和发展前景，旨在为该领域内进一步的技术突破提供参考思路。</p><h2 id="创新点-6" tabindex="-1"><a class="header-anchor" href="#创新点-6"><span>创新点</span></a></h2><p>本文对当前基于视觉SLAM的无人机自主导航技术进行全面梳理与深入剖析，系统总结了近年来在复杂环境下实现精确建图和定位方面的关键进展。此外，文中也提出了若干新颖的研究视角和技术路径以应对现有挑战。</p><h2 id="结论-6" tabindex="-1"><a class="header-anchor" href="#结论-6"><span>结论</span></a></h2><p>综上所述，基于视觉SLAM的无人机导航技术已经取得了显著进步，并展现出广阔的应用前景和发展潜力。然而，在面对更复杂的实际应用场景时仍需解决一系列理论与实践问题。未来研究应注重开发高效鲁棒的算法，优化系统架构设计，同时探索更多跨学科融合创新方向，推动该领域向更高层次迈进。</p><h2 id="原文链接-6" tabindex="-1"><a class="header-anchor" href="#原文链接-6"><span>原文链接</span></a></h2><p>https://www.ewadirect.com/proceedings/tns/article/view/16389</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: zhangleilikejay@gmail.com">zhanglei</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/papers/20241111_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241111_室内定位"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>20241111_室内定位</span></div></a><a class="route-link auto-link next" href="/papers/20241117_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241117_室内定位"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>20241117_室内定位</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BNyMW1Pp.js" defer></script>
  </body>
</html>
