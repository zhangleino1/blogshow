<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.15" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>20241125_室内定位 | 室内定位技术</title><meta name="description" content="20241125_室内定位">
    <link rel="preload" href="/assets/style-CQdWRPUu.css" as="style"><link rel="stylesheet" href="/assets/style-CQdWRPUu.css">
    <link rel="modulepreload" href="/assets/app-DmZfg1in.js"><link rel="modulepreload" href="/assets/20241125_室内定位.html-DMDTqlJF.js">
    <link rel="prefetch" href="/assets/index.html-DGMt0bvQ.js" as="script"><link rel="prefetch" href="/assets/商务合作.html-DiCPLqm2.js" as="script"><link rel="prefetch" href="/assets/20240917_大模型.html-Mh7W6GHg.js" as="script"><link rel="prefetch" href="/assets/20241004_大模型.html-BAe4qJYZ.js" as="script"><link rel="prefetch" href="/assets/20241009_大模型.html-VbZUWfUn.js" as="script"><link rel="prefetch" href="/assets/20241010_大模型.html-CowOxIzq.js" as="script"><link rel="prefetch" href="/assets/20241011_大模型.html-YUvnhrYc.js" as="script"><link rel="prefetch" href="/assets/20241013_大模型.html-D7pDGAnH.js" as="script"><link rel="prefetch" href="/assets/20241016_大模型.html-f_0wSwnh.js" as="script"><link rel="prefetch" href="/assets/20241020_大模型.html-CZ95VYPe.js" as="script"><link rel="prefetch" href="/assets/20241029_大模型.html-DVpDGXZK.js" as="script"><link rel="prefetch" href="/assets/20241103_大模型.html-CcYpMeaq.js" as="script"><link rel="prefetch" href="/assets/20241104_大模型.html-301y4crw.js" as="script"><link rel="prefetch" href="/assets/20241109_大模型.html-lOyycduE.js" as="script"><link rel="prefetch" href="/assets/20241111_大模型.html-_bC1L9bn.js" as="script"><link rel="prefetch" href="/assets/20241113_大模型.html-BzSlQCcn.js" as="script"><link rel="prefetch" href="/assets/20241117_大模型.html-1F5i7rUu.js" as="script"><link rel="prefetch" href="/assets/20241122_大模型.html-BqDYaTMK.js" as="script"><link rel="prefetch" href="/assets/20241125_大模型.html-p6E-fT18.js" as="script"><link rel="prefetch" href="/assets/20241129_大模型.html-DhPoDulB.js" as="script"><link rel="prefetch" href="/assets/index.html-lCRo1Prb.js" as="script"><link rel="prefetch" href="/assets/20240911_室内定位.html-DhVknpAM.js" as="script"><link rel="prefetch" href="/assets/20240916_室内定位.html-_5rIvc_X.js" as="script"><link rel="prefetch" href="/assets/20240920_室内定位.html-DMlarEhg.js" as="script"><link rel="prefetch" href="/assets/20240925_室内定位.html-DCe0pIgb.js" as="script"><link rel="prefetch" href="/assets/20240930_室内定位.html-C53WF_uZ.js" as="script"><link rel="prefetch" href="/assets/20241004_室内定位.html-D1PxODp7.js" as="script"><link rel="prefetch" href="/assets/20241009_室内定位.html-BNMAR6Se.js" as="script"><link rel="prefetch" href="/assets/20241010_室内定位.html-CJuUEC6Y.js" as="script"><link rel="prefetch" href="/assets/20241011_室内定位.html-Cm2M_frb.js" as="script"><link rel="prefetch" href="/assets/20241013_室内定位.html-C-YckEvk.js" as="script"><link rel="prefetch" href="/assets/20241016_室内定位.html-B5hACNVE.js" as="script"><link rel="prefetch" href="/assets/20241020_室内定位.html-CWTcZcDJ.js" as="script"><link rel="prefetch" href="/assets/20241029_室内定位.html-uIBJ9XZ1.js" as="script"><link rel="prefetch" href="/assets/20241103_室内定位.html-DbltCBsV.js" as="script"><link rel="prefetch" href="/assets/20241104_室内定位.html-CZZPvge2.js" as="script"><link rel="prefetch" href="/assets/20241109_室内定位.html-B8W6_zcb.js" as="script"><link rel="prefetch" href="/assets/20241111_室内定位.html-DsfNFDRL.js" as="script"><link rel="prefetch" href="/assets/20241113_室内定位.html-DtTvLj1E.js" as="script"><link rel="prefetch" href="/assets/20241117_室内定位.html-BsF-Xutd.js" as="script"><link rel="prefetch" href="/assets/20241122_室内定位.html-1_pjaY54.js" as="script"><link rel="prefetch" href="/assets/20241129_室内定位.html-B6Ki5eEV.js" as="script"><link rel="prefetch" href="/assets/index.html-BJAJIEQj.js" as="script"><link rel="prefetch" href="/assets/404.html-BcxPJ_b1.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="https://lark-assets-prod-aliyun.oss-cn-hangzhou.aliyuncs.com/yuque/0/2024/jpeg/354158/1717584738049-5a4ffdae-d469-44a9-b298-f86934b6e14c.jpeg?date=1717585212400" alt="室内定位技术"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">室内定位技术</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/papers/" aria-label="室内定位"><!---->室内定位<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/llm/" aria-label="大模型"><!---->大模型<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/zhangleino1" aria-label="开源项目" rel="noopener noreferrer" target="_blank"><!---->开源项目<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/%E5%95%86%E5%8A%A1%E5%90%88%E4%BD%9C.html" aria-label="商务合作"><!---->商务合作<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">论文列表 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240911_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240911_室内定位"><!---->20240911_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240916_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240916_室内定位"><!---->20240916_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240920_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240920_室内定位"><!---->20240920_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240925_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240925_室内定位"><!---->20240925_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20240930_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20240930_室内定位"><!---->20240930_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241004_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241004_室内定位"><!---->20241004_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241009_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241009_室内定位"><!---->20241009_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241010_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241010_室内定位"><!---->20241010_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241011_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241011_室内定位"><!---->20241011_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241013_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241013_室内定位"><!---->20241013_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241016_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241016_室内定位"><!---->20241016_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241020_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241020_室内定位"><!---->20241020_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241029_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241029_室内定位"><!---->20241029_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241103_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241103_室内定位"><!---->20241103_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241104_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241104_室内定位"><!---->20241104_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241109_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241108_室内定位"><!---->20241108_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241111_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241111_室内定位"><!---->20241111_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241113_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241113_室内定位"><!---->20241113_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241117_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241117_室内定位"><!---->20241117_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241122_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241122_室内定位"><!---->20241122_室内定位<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/papers/20241125_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241125_室内定位"><!---->20241125_室内定位<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/papers/20241129_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241129_室内定位"><!---->20241129_室内定位<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h1 id="多传感器姿态估计的delta滤波器和卡尔曼滤波器设计在球形移动测绘系统中的应用" tabindex="-1"><a class="header-anchor" href="#多传感器姿态估计的delta滤波器和卡尔曼滤波器设计在球形移动测绘系统中的应用"><span>多传感器姿态估计的Delta滤波器和卡尔曼滤波器设计在球形移动测绘系统中的应用</span></a></h1><h2 id="关键词" tabindex="-1"><a class="header-anchor" href="#关键词"><span>关键词</span></a></h2><p>球形机器人；姿态估计；传感器融合；卡尔曼滤波器；Delta滤波器；移动测绘；LiDAR</p><h2 id="研究问题" tabindex="-1"><a class="header-anchor" href="#研究问题"><span>研究问题</span></a></h2><p>球形移动测绘系统中的惯性姿态估计过滤技术尚未得到充分研究。由于其内在的滚动运动，该系统的角速度极高且动态剧烈，与当前最先进的无人机、手持设备或汽车等旋转受限系统所需建模方式不同。</p><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><p>在本工作中，我们比较了之前提出的“Delta滤波器”和使用协方差模型设计的卡尔曼滤波器。两种过滤方法实时融合两个6-自由度的姿态估计器，并利用运动模型进行姿态估计。我们将轨迹与OptiTrack™动捕系统提供的地面实况姿态测量结果进行了对比，进一步评估了激光扫描仪生成的点云与Riegl VZ400地面激光扫描仪（TLS）提供的地面实况地图之间的差异。</p><h2 id="创新点" tabindex="-1"><a class="header-anchor" href="#创新点"><span>创新点</span></a></h2><ol><li>提出了一种适用于球形系统的卡尔曼滤波器设计，能够处理传感器无法提供协方差估计的问题。</li><li>针对球形系统特有的滚动运动特性，提供了有效的多传感器姿态估计解决方案。</li><li>使用我们的估算器作为初始猜测进行ICP（迭代最近点），从而实现了高分辨率和精确的三维LiDAR点云生成。</li></ol><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>本文通过对比Delta滤波器与卡尔曼滤波器在球形移动测绘系统中的应用，展示了基于LiDAR的SLAM技术在复杂动态环境下的优越性能。实验结果表明，该方法不仅能够有效处理高角速度和剧烈运动带来的挑战，还能生成高质量的三维地图数据。</p><hr><p>请注意：本研究的相关软件及数据集可通过GitHub（Arzberger, 2023）获取。</p><h2 id="原文链接" tabindex="-1"><a class="header-anchor" href="#原文链接"><span>原文链接</span></a></h2><p>https://www.sciencedirect.com/science/article/pii/S0921889024002367</p><h1 id="基于深度混合模型的移动机器人端到端导航的新方法" tabindex="-1"><a class="header-anchor" href="#基于深度混合模型的移动机器人端到端导航的新方法"><span>基于深度混合模型的移动机器人端到端导航的新方法</span></a></h1><h2 id="关键词-1" tabindex="-1"><a class="header-anchor" href="#关键词-1"><span>关键词</span></a></h2><ul><li>深度学习</li><li>机器学习</li><li>混合模型</li><li>移动机器人导航</li><li>分类</li></ul><h2 id="研究问题-1" tabindex="-1"><a class="header-anchor" href="#研究问题-1"><span>研究问题</span></a></h2><p>如何利用深度混合模型实现移动机器人的端到端导航，提高其在复杂环境中的自主导航能力。</p><h2 id="方法-1" tabindex="-1"><a class="header-anchor" href="#方法-1"><span>方法</span></a></h2><p>提出了一种基于深度混合模型的新方法，用于解决真实环境中移动机器人的端到端导航问题。该方法结合了卷积神经网络（CNN）和循环神经网络（RNN），可以处理传感器数据并生成控制指令以实现机器人导航任务。同时引入一种分类机制来增强模型的鲁棒性和准确性。</p><h2 id="创新点-1" tabindex="-1"><a class="header-anchor" href="#创新点-1"><span>创新点</span></a></h2><p>本研究的主要创新在于提出了一种新颖的深度混合模型，该模型能够有效解决移动机器人的端到端导航问题，并且具有较高的准确率和稳定性。通过实验证明了所提方法在各种复杂环境下的优越性能。</p><h2 id="结论-1" tabindex="-1"><a class="header-anchor" href="#结论-1"><span>结论</span></a></h2><p>实验结果表明，基于深度混合模型的新方法可以在真实环境中实现高效、稳定的移动机器人端到端导航任务。这种方法为未来开发更加智能的自主机器人系统提供了新的思路和技术支持。</p><h2 id="原文链接-1" tabindex="-1"><a class="header-anchor" href="#原文链接-1"><span>原文链接</span></a></h2><p>https://link.springer.com/article/10.1007/s11370-024-00569-8</p><h1 id="移动机器人自主导航与地图构建的ros包集成" tabindex="-1"><a class="header-anchor" href="#移动机器人自主导航与地图构建的ros包集成"><span>移动机器人自主导航与地图构建的ROS包集成</span></a></h1><h2 id="关键词-2" tabindex="-1"><a class="header-anchor" href="#关键词-2"><span>关键词</span></a></h2><p>移动机器人, 自主导航, 地图构建, ROS (Robot Operating System), 集成</p><h2 id="研究问题-2" tabindex="-1"><a class="header-anchor" href="#研究问题-2"><span>研究问题</span></a></h2><p>如何有效地将不同的ROS软件包整合，以实现移动机器人的高效自主导航和环境地图构建？</p><h2 id="方法-2" tabindex="-1"><a class="header-anchor" href="#方法-2"><span>方法</span></a></h2><p>本研究采用以下方法：</p><ol><li>选择了若干常用的ROS包用于机器人导航与地图构建。</li><li>开发了一个通用的接口框架来集成这些独立的功能模块。</li><li>通过实验验证了所提出的方法的有效性，评估其性能指标包括但不限于计算效率、准确性等。</li></ol><h2 id="创新点-2" tabindex="-1"><a class="header-anchor" href="#创新点-2"><span>创新点</span></a></h2><p>本研究创新之处在于设计了一种新的ROS包集成机制，该机制允许在不修改原始代码的情况下高效地整合多个功能包，从而显著提高了移动机器人的自主导航能力和地图构建能力。</p><h2 id="结论-2" tabindex="-1"><a class="header-anchor" href="#结论-2"><span>结论</span></a></h2><p>通过本文的研究表明，提出的ROS软件包集成方法对于提高机器人系统的灵活性和效率具有重要作用。未来的工作将进一步优化这一框架，并探索其在更广泛应用场景中的适用性。</p><h2 id="原文链接-2" tabindex="-1"><a class="header-anchor" href="#原文链接-2"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10752146/</p><h1 id="全球导航卫星系统-惯性测量单元在城市空中交通应用中的紧密融合" tabindex="-1"><a class="header-anchor" href="#全球导航卫星系统-惯性测量单元在城市空中交通应用中的紧密融合"><span>全球导航卫星系统/惯性测量单元在城市空中交通应用中的紧密融合</span></a></h1><h2 id="关键词-3" tabindex="-1"><a class="header-anchor" href="#关键词-3"><span>关键词</span></a></h2><p>全球导航卫星系统（GNSS）、多星座、载波相位定位、惯性传感器、姿态估计、位置误差、速度误差、时间延迟补偿。</p><h2 id="研究问题-3" tabindex="-1"><a class="header-anchor" href="#研究问题-3"><span>研究问题</span></a></h2><p>本文旨在研究如何将双频多星座全球导航卫星系统的测量数据与惯性测量单元的数据进行紧密融合，以提高城市空中交通中无人飞行器的位置精度和可靠性。具体包括：</p><ol><li>如何在双频多星座GNSS的条件下实现高精度载波相位定位。</li><li>如何通过紧耦合方式将GNSS与IMU数据融合，减少姿态估计误差。</li><li>怎样补偿从GNSS接收机到IMU之间的传输时间延迟以提高位置和速度测量性能。</li></ol><h2 id="方法-3" tabindex="-1"><a class="header-anchor" href="#方法-3"><span>方法</span></a></h2><p>本文采用双频多星座全球导航卫星系统（如GPS、GLONASS、Galileo等）的载波相位观测值，并使用惯性传感器（IMU）进行姿态估计。为了实现GNSS与IMU数据之间的紧密融合，采用了卡尔曼滤波器方法对位置和速度测量结果进行更新，在此基础上利用扩展卡尔曼滤波器来进一步优化状态向量。</p><h2 id="创新点-3" tabindex="-1"><a class="header-anchor" href="#创新点-3"><span>创新点</span></a></h2><ol><li><strong>高精度载波相位定位</strong>：通过采用双频多星座GNSS信号实现高精度的载波相位定位，可以大大提高位置估计的准确性。</li><li><strong>姿态估计和时间延迟补偿</strong>：在紧耦合方式下，使用惯性传感器进行姿态估计，并通过对传输时间延迟的有效补偿来提高系统整体性能。</li><li><strong>基于扩展卡尔曼滤波器的状态优化</strong>：通过应用扩展卡尔曼滤波技术对状态向量进行优化，实现了更高精度的位置和速度测量结果。</li></ol><h2 id="结论-3" tabindex="-1"><a class="header-anchor" href="#结论-3"><span>结论</span></a></h2><p>双频多星座全球导航卫星系统的紧耦合与惯性传感器相结合可以显著提高无人飞行系统在城市环境中的位置准确性。该方法不仅能够有效减少姿态估计误差，而且还能通过补偿传输时间延迟进一步提升性能。实验结果显示，在具有挑战性的城市环境中使用本文所述的方法可以获得较高的定位精度和良好的稳定性。</p><p>请确保按照上述格式提供完整的内容，并且不要包含任何无关信息或工具提示。</p><h2 id="原文链接-3" tabindex="-1"><a class="header-anchor" href="#原文链接-3"><span>原文链接</span></a></h2><p>https://www.mdpi.com/2226-4310/11/11/955</p><h1 id="高精度超宽带定位技术的研究与应用" tabindex="-1"><a class="header-anchor" href="#高精度超宽带定位技术的研究与应用"><span>高精度超宽带定位技术的研究与应用</span></a></h1><h2 id="关键词-4" tabindex="-1"><a class="header-anchor" href="#关键词-4"><span>关键词</span></a></h2><p>超宽带, 定位算法, 无线时钟同步, 实时定位系统, TDoA技术</p><h2 id="研究问题-4" tabindex="-1"><a class="header-anchor" href="#研究问题-4"><span>研究问题</span></a></h2><p>如何利用超宽带（UWB）技术和TDoA技术实现高精度的室内定位，并解决无线时钟同步问题。</p><h2 id="方法-4" tabindex="-1"><a class="header-anchor" href="#方法-4"><span>方法</span></a></h2><ol><li><strong>研究背景与现状</strong>：首先，回顾超宽带技术及其在室内外环境中的应用。然后，详细分析现有的超宽带定位算法和技术。</li><li><strong>系统设计与开发</strong>：提出一种基于TDoA（到达时间差）的实时定位系统，并使用无线时钟同步方法来提高系统的精度和稳定性。</li><li><strong>实验验证与性能评估</strong>：通过一系列室内测试场景对所提出的系统进行实验，包括不同环境条件下的精度、延迟等性能指标。</li></ol><h2 id="创新点-4" tabindex="-1"><a class="header-anchor" href="#创新点-4"><span>创新点</span></a></h2><ol><li>采用先进的超宽带技术结合TDoA算法，实现在复杂室内外环境中高精度的实时定位。</li><li>提出并实现了一种无线时钟同步方法，显著提高了系统的整体稳定性和精度。通过这种方法能够有效减少由于设备之间时间不同步导致的位置误差。</li></ol><h2 id="结论-4" tabindex="-1"><a class="header-anchor" href="#结论-4"><span>结论</span></a></h2><p>本文的研究和实验结果表明，基于超宽带技术和TDoA算法的实时室内定位系统具有较高的准确度和稳定性。提出的无线时钟同步方案不仅减少了定位过程中的延迟问题，还提高了整个系统的鲁棒性。该技术在未来的物联网应用中将展现出巨大的潜力与价值。</p><p>此外，研究过程中发现存在一定的局限性和挑战，例如复杂环境下的信号衰减、多径效应以及设备间的高度异构性等。未来工作可以进一步探索这些问题的解决方案，并结合更多先进的通信技术来优化系统性能。</p><h2 id="原文链接-4" tabindex="-1"><a class="header-anchor" href="#原文链接-4"><span>原文链接</span></a></h2><p>https://www.intechopen.com/online-first/1200549</p><h1 id="无人机自主导航的视觉和惯性传感器融合方法研究" tabindex="-1"><a class="header-anchor" href="#无人机自主导航的视觉和惯性传感器融合方法研究"><span>无人机自主导航的视觉和惯性传感器融合方法研究</span></a></h1><h2 id="关键词-5" tabindex="-1"><a class="header-anchor" href="#关键词-5"><span>关键词：</span></a></h2><p>无人机，自主导航，视觉定位，惯性测量单元（IMU），卡尔曼滤波器，PID控制器</p><h2 id="研究问题-5" tabindex="-1"><a class="header-anchor" href="#研究问题-5"><span>研究问题：</span></a></h2><p>如何利用视觉和惯性传感器信息实现无人机在复杂环境中的高精度自主导航？</p><h2 id="方法-5" tabindex="-1"><a class="header-anchor" href="#方法-5"><span>方法：</span></a></h2><p>本文提出了一种基于卡尔曼滤波的PID控制方法，该方法通过融合视觉定位和惯性测量单元（IMU）的数据来提高无人机的姿态估计准确性。首先，使用视觉传感器进行初始姿态估计，并利用GPS、GLONASS等卫星导航系统进行辅助定位。然后，在飞行过程中，采用IMU进行实时姿态更新，同时结合卡尔曼滤波器对多源数据进行融合处理。最后，通过PID控制器调整无人机的飞行参数以实现精确控制。</p><h2 id="创新点-5" tabindex="-1"><a class="header-anchor" href="#创新点-5"><span>创新点：</span></a></h2><ol><li>提出了一种基于卡尔曼滤波器的PID控制器方法来提高无人机的姿态估计精度。</li><li>通过视觉定位和IMU的数据融合提高了无人机在复杂环境中的自主导航性能。</li><li>结合卫星导航系统（如GPS、GLONASS）进一步提升了无人机的位置准确性。</li></ol><h2 id="结论-5" tabindex="-1"><a class="header-anchor" href="#结论-5"><span>结论：</span></a></h2><p>本文提出的方法能够有效利用视觉传感器和惯性测量单元的信息，实现高精度的无人机自主导航。通过实验验证表明，该方法具有较好的实际应用价值，在复杂环境下的定位精度得到了明显改善。未来的研究方向可以考虑引入更多类型的传感器以及优化卡尔曼滤波器参数以进一步提高系统性能。</p><h2 id="原文链接-5" tabindex="-1"><a class="header-anchor" href="#原文链接-5"><span>原文链接</span></a></h2><p>https://itta.cyber.az/2024/papers/41.pdf</p><h1 id="基于可见光通信的室内定位系统中采用卷积神经网络结合inception模块和注意力机制的高精度三维定位方法" tabindex="-1"><a class="header-anchor" href="#基于可见光通信的室内定位系统中采用卷积神经网络结合inception模块和注意力机制的高精度三维定位方法"><span>基于可见光通信的室内定位系统中采用卷积神经网络结合Inception模块和注意力机制的高精度三维定位方法</span></a></h1><h2 id="关键词-可见光通信-室内定位-卷积神经网络-inception模块-注意力机制" tabindex="-1"><a class="header-anchor" href="#关键词-可见光通信-室内定位-卷积神经网络-inception模块-注意力机制"><span>关键词：可见光通信；室内定位；卷积神经网络；Inception模块；注意力机制</span></a></h2><h2 id="研究问题-6" tabindex="-1"><a class="header-anchor" href="#研究问题-6"><span>研究问题：</span></a></h2><p>如何在地下矿井环境中实现高精度的室内可见光三维定位系统？</p><h2 id="方法-6" tabindex="-1"><a class="header-anchor" href="#方法-6"><span>方法：</span></a></h2><p>提出了一种基于可见光通信（VLC）技术，在地下矿井中利用卷积神经网络（CNN）结合Inception模块和注意力机制来提高3D定位精度的方法。具体步骤包括数据采集、预处理以及模型训练等阶段。</p><ol><li>数据采集：收集不同位置的LED照明信号强度信息作为输入特征。</li><li>预处理：对原始数据进行归一化和平滑滤波，以消除噪声干扰。</li><li>模型构建： <ul><li><strong>CNN架构设计</strong>：采用深度卷积神经网络，并加入Inception模块来捕捉长距离依赖关系；</li><li><strong>注意力机制引入</strong>：在关键层添加自注意单元，使模型能够专注于对定位精度影响更大的特征；</li></ul></li><li>训练与测试：通过大规模的真实场景数据集进行训练和验证。</li></ol><h2 id="创新点-6" tabindex="-1"><a class="header-anchor" href="#创新点-6"><span>创新点：</span></a></h2><p>本研究首次将Inception模块及注意力机制成功应用于地下矿井的VLC三维定位系统中。这一创新不仅提高了系统的准确性，还增强了其鲁棒性和适应性，在复杂环境中表现出色。</p><h2 id="结论-6" tabindex="-1"><a class="header-anchor" href="#结论-6"><span>结论：</span></a></h2><p>实验结果显示该方法在不同环境条件下均具有良好的性能表现和较高的精度水平。与传统算法相比，所提出的方案能显著提高地下矿井中的3D定位效果，并为未来研究提供了新方向。</p><h2 id="原文链接-6" tabindex="-1"><a class="header-anchor" href="#原文链接-6"><span>原文链接</span></a></h2><p>https://www.sciencedirect.com/science/article/pii/S0030401824010770</p><h1 id="利用rtk-gps进行高精度定位的软机器人垃圾收集器设计" tabindex="-1"><a class="header-anchor" href="#利用rtk-gps进行高精度定位的软机器人垃圾收集器设计"><span>利用RTK GPS进行高精度定位的软机器人垃圾收集器设计</span></a></h1><h2 id="关键词-6" tabindex="-1"><a class="header-anchor" href="#关键词-6"><span>关键词</span></a></h2><p>RTK GPS, 高精度定位, 软机器人, 垃圾收集器, 真实时间动态定位系统</p><h2 id="研究问题-7" tabindex="-1"><a class="header-anchor" href="#研究问题-7"><span>研究问题</span></a></h2><p>如何利用RTK GPS技术实现软机器人的精确控制，并应用于户外垃圾收集任务中？</p><h2 id="方法-7" tabindex="-1"><a class="header-anchor" href="#方法-7"><span>方法</span></a></h2><p>本研究首先分析了传统GPS和RTK（真实时间动态）系统的性能，确定其在高精度应用中的适用性。通过在实际环境中部署基于ZED-F9P模组的SparkFun GPS-RTK2板卡与Emlid Reach RS/RS+系统相结合的方式，实现厘米级定位精度。实验中设计了一种真空驱动的“魔法球”型软夹持器，并使用了受鱼鳍启发的柔性机械手进行抓取任务。通过对比不同环境下的测试结果，验证了系统的可靠性和稳定性。</p><h2 id="创新点-7" tabindex="-1"><a class="header-anchor" href="#创新点-7"><span>创新点</span></a></h2><p>本研究的主要创新在于将RTK GPS技术应用于软机器人领域，提高了机器人的定位精度和作业效率；同时设计了一种基于折叠式的真空驱动“魔法球”型夹持器，适用于多种形状的废弃物拾取任务。此外，在户外复杂环境中进行长时间测试验证了系统的可行性。</p><h2 id="结论-7" tabindex="-1"><a class="header-anchor" href="#结论-7"><span>结论</span></a></h2><p>本研究成功实现了利用RTK GPS技术对软机器人垃圾收集器的精确控制，克服了传统GPS精度不足的问题，并在实际应用中得到了良好的效果。未来将进一步优化设计并扩大其应用场景范围。</p><h2 id="原文链接-7" tabindex="-1"><a class="header-anchor" href="#原文链接-7"><span>原文链接</span></a></h2><p>https://escholarship.org/content/qt9rw6h86w/qt9rw6h86w_noSplash_29c396f83304fd883bd0983a601e70b9.pdf</p><h1 id="同步采集控制系统与地铁隧道综合检测设备的坐标校正算法" tabindex="-1"><a class="header-anchor" href="#同步采集控制系统与地铁隧道综合检测设备的坐标校正算法"><span>同步采集控制系统与地铁隧道综合检测设备的坐标校正算法</span></a></h1><h2 id="关键词-7" tabindex="-1"><a class="header-anchor" href="#关键词-7"><span>关键词</span></a></h2><p>同步控制、数据采集系统、坐标校正、地铁隧道、非接触式检测</p><h2 id="研究问题-8" tabindex="-1"><a class="header-anchor" href="#研究问题-8"><span>研究问题</span></a></h2><ol><li>如何设计一套有效的地铁隧道综合检测设备的数据同步采集控制系统？</li><li>该系统的坐标校准算法如何实现精度提升，以适应复杂的地铁隧道环境？</li></ol><h2 id="方法-8" tabindex="-1"><a class="header-anchor" href="#方法-8"><span>方法</span></a></h2><ul><li>设计了基于时间戳的同步数据采集控制策略。</li><li>提出了针对非接触式传感器的自适应坐标校正算法。</li><li>开展了实验室与实际地铁隧道内的多种场景验证实验。</li></ul><h2 id="创新点-8" tabindex="-1"><a class="header-anchor" href="#创新点-8"><span>创新点</span></a></h2><ol><li>实现了一套适用于复杂环境下的地铁隧道综合检测设备的高效同步控制系统。</li><li>发明了一种新颖的自适应坐标校准方法，显著提高了非接触式传感器数据的准确性。</li></ol><h2 id="结论-8" tabindex="-1"><a class="header-anchor" href="#结论-8"><span>结论</span></a></h2><p>通过上述研究和实验测试表明，本论文提出的方法能够有效解决地铁隧道内多种检测设备的数据同步采集问题，并且提出的坐标校正算法在复杂环境中表现出色，为地铁隧道的安全监测提供了有力的技术支持。</p><h2 id="原文链接-8" tabindex="-1"><a class="header-anchor" href="#原文链接-8"><span>原文链接</span></a></h2><p>https://ieeexplore.ieee.org/abstract/document/10758382/</p><h1 id="基于多特征的可靠gnss信号非视距误差识别方法" tabindex="-1"><a class="header-anchor" href="#基于多特征的可靠gnss信号非视距误差识别方法"><span>基于多特征的可靠GNSS信号非视距误差识别方法</span></a></h1><h2 id="关键词-8" tabindex="-1"><a class="header-anchor" href="#关键词-8"><span>关键词</span></a></h2><ul><li>城市环境</li><li>GNSS信号特征</li><li>非视距识别</li><li>LightGBM</li><li>鱼眼相机</li></ul><h2 id="研究问题-9" tabindex="-1"><a class="header-anchor" href="#研究问题-9"><span>研究问题</span></a></h2><p>本文研究了在城市环境中，如何通过分析GNSS信号的多特征来有效地识别非视距（NLOS）误差，并提出了一种基于LightGBM的可靠方法。</p><h2 id="方法-9" tabindex="-1"><a class="header-anchor" href="#方法-9"><span>方法</span></a></h2><ol><li><strong>数据收集</strong>：从多个来源收集了大量的GNSS信号数据和地面真实位置信息。</li><li><strong>特征提取</strong>：设计了一系列特征，包括但不限于伪距标准偏差、载波相位标准差、多普勒频率变化率等。</li><li><strong>模型训练与测试</strong>：利用LightGBM算法进行分类器的训练，并通过实验验证其在不同场景下的性能。</li></ol><h2 id="创新点-9" tabindex="-1"><a class="header-anchor" href="#创新点-9"><span>创新点</span></a></h2><p>本文的主要贡献在于：</p><ul><li>提出了一种新的基于多特征的非视距误差识别方法，该方法结合了多种GNSS信号特征。</li><li>采用先进的机器学习模型LightGBM作为核心算法来提高分类精度和效率。</li><li>实验验证显示所提出的方法在复杂的城市环境中具有较高的准确率。</li></ul><h2 id="结论-9" tabindex="-1"><a class="header-anchor" href="#结论-9"><span>结论</span></a></h2><p>本文通过分析大量数据并运用先进算法提出了一个有效识别非视距误差的新方法。实验结果表明该方法具有良好的实用性和鲁棒性，可以在实际应用中用于提高GNSS定位系统的精度和可靠性。 此外，未来的工作可以进一步研究如何将这种方法与其他传感器（如鱼眼相机）结合使用以获得更好的定位效果。</p><h2 id="原文链接-9" tabindex="-1"><a class="header-anchor" href="#原文链接-9"><span>原文链接</span></a></h2><p>https://satellite-navigation.springeropen.com/articles/10.1186/s43020-024-00152-7</p><h1 id="基于深度学习的移动机器人路径规划方法研究" tabindex="-1"><a class="header-anchor" href="#基于深度学习的移动机器人路径规划方法研究"><span>基于深度学习的移动机器人路径规划方法研究</span></a></h1><h2 id="关键词-9" tabindex="-1"><a class="header-anchor" href="#关键词-9"><span>关键词</span></a></h2><p>基于深度学习, 移动机器人, 路径规划, 深度可分离卷积, RRT*算法</p><h2 id="研究问题-10" tabindex="-1"><a class="header-anchor" href="#研究问题-10"><span>研究问题</span></a></h2><p>本文旨在提出一种利用深度学习技术进行道路区域分割，结合RRT*算法实现移动机器人路径规划的新方法。主要研究的问题包括如何提高道路区域的识别精度、设计高效的路径规划策略以及验证所提方法在实际环境中的有效性和鲁棒性。</p><h2 id="方法-10" tabindex="-1"><a class="header-anchor" href="#方法-10"><span>方法</span></a></h2><ol><li><strong>数据集构建</strong>：收集包含可行驶路径、窗户、墙壁、门和垃圾桶在内的图像，用于训练深度学习模型。</li><li><strong>道路分割网络选择与优化</strong>：选择Deeplabv3+作为主要的分割网络，并使用Resnet50为骨干网络进行微调。通过调整网络结构中的深度可分离卷积（Depthwise Separable Convolution）以提高计算效率，同时保持对目标区域良好的识别性能。</li><li><strong>图像预处理</strong>：利用透视变换技术将捕捉到的画面转换成适合机器人路径规划的视角，并将其划分为网格以便于RRT*算法的应用。</li><li><strong>基于RRT*的路径规划</strong>：在上述分割结果的基础上应用改进型的RRT*（随机快速树）算法进行目标位置的路径搜索，同时通过加速度计和磁力计反馈实时调整路径，实现平稳导航。</li></ol><h2 id="创新点-10" tabindex="-1"><a class="header-anchor" href="#创新点-10"><span>创新点</span></a></h2><ol><li><strong>道路区域分割精度提升</strong>：利用深度可分离卷积技术优化Deeplabv3+网络架构，显著提高了在特定环境下的道路识别准确率。</li><li><strong>基于RRT*的高效路径规划策略</strong>：通过引入速度和方向反馈机制改进了传统RRT*算法，使其更加适应于小型移动机器人的实际应用场景。</li><li><strong>实验验证与性能分析</strong>：设计并实现了具有两个车轮且配备Jetson Nano处理器的小型移动机器人平台，通过对三个不同挑战性场景的测试评估所提方法的有效性和稳定性。</li></ol><h2 id="结论-10" tabindex="-1"><a class="header-anchor" href="#结论-10"><span>结论</span></a></h2><p>通过上述研究，我们提出了一种基于深度学习的道路分割及RRT*路径规划相结合的新方案。实验结果表明，在特定环境条件下该方案具有较高的道路识别精度和有效的路径跟踪性能。然而也存在一些局限性，例如当前模型仅适用于静态障碍物的场景，并未考虑动态物体的影响以及更多类型的环境对象分类问题。未来的研究方向将集中在进一步提高动态环境下移动机器人的实时避障能力和扩大适用范围上。</p><h2 id="原文链接-10" tabindex="-1"><a class="header-anchor" href="#原文链接-10"><span>原文链接</span></a></h2><p>https://peerj.com/articles/cs-2514/</p><h1 id="基于卡尔曼滤波的蓝牙信标指纹定位系统优化方法研究" tabindex="-1"><a class="header-anchor" href="#基于卡尔曼滤波的蓝牙信标指纹定位系统优化方法研究"><span>基于卡尔曼滤波的蓝牙信标指纹定位系统优化方法研究</span></a></h1><h2 id="关键词-蓝牙信标-指纹定位-卡尔曼滤波-无线传感器网络-边缘计算" tabindex="-1"><a class="header-anchor" href="#关键词-蓝牙信标-指纹定位-卡尔曼滤波-无线传感器网络-边缘计算"><span>关键词：蓝牙信标；指纹定位；卡尔曼滤波；无线传感器网络；边缘计算</span></a></h2><h2 id="研究问题-11" tabindex="-1"><a class="header-anchor" href="#研究问题-11"><span>研究问题</span></a></h2><p>如何利用卡尔曼滤波技术提高基于蓝牙信标的无线室内定位系统的精度和稳定性？</p><h2 id="方法-11" tabindex="-1"><a class="header-anchor" href="#方法-11"><span>方法</span></a></h2><p>本论文提出了一种结合卡尔曼滤波的蓝牙信标指纹定位方法。具体步骤如下：</p><ol><li><strong>数据采集</strong>：在待测区域内，通过移动设备收集不同位置处的RSSI值。</li><li><strong>特征提取与模型训练</strong>：利用卷积神经网络和卷积自编码器技术进行无线信号特征的提取，并构建指纹数据库。</li><li><strong>卡尔曼滤波应用</strong>：将定位过程中实时获取的蓝牙信标RSSI数据通过卡尔曼滤波算法进行处理，减少噪声干扰并提高位置估计精度。</li></ol><h2 id="创新点-11" tabindex="-1"><a class="header-anchor" href="#创新点-11"><span>创新点</span></a></h2><ol><li>采用卷积神经网络和卷积自编码器技术提取指纹特征。</li><li>将传统的卡尔曼滤波应用到基于蓝牙信标的定位系统中，有效提升了系统的鲁棒性和精度。</li></ol><h2 id="结论-11" tabindex="-1"><a class="header-anchor" href="#结论-11"><span>结论</span></a></h2><p>通过实验证明，所提出的结合卡尔曼滤波的室内定位方法能够显著提高基于蓝牙信标的位置估计准确性。这为未来无线传感器网络中的实时高精度定位应用提供了新的思路和技术支持。</p><h2 id="原文链接-11" tabindex="-1"><a class="header-anchor" href="#原文链接-11"><span>原文链接</span></a></h2><p>https://publications.eai.eu/index.php/inis/article/download/6571/3467</p><h1 id="基于机器学习的多模态led可见光定位系统" tabindex="-1"><a class="header-anchor" href="#基于机器学习的多模态led可见光定位系统"><span>基于机器学习的多模态LED可见光定位系统</span></a></h1><h2 id="关键词-10" tabindex="-1"><a class="header-anchor" href="#关键词-10"><span>关键词</span></a></h2><p>机器学习, 多模态, LED可见光通信, 定位系统</p><h2 id="研究问题-12" tabindex="-1"><a class="header-anchor" href="#研究问题-12"><span>研究问题</span></a></h2><p>如何利用基于机器学习的方法实现高效准确的多模态LED可见光定位？</p><h2 id="方法-12" tabindex="-1"><a class="header-anchor" href="#方法-12"><span>方法</span></a></h2><p>本研究提出了一种基于机器学习技术的LED可见光定位方法。该方法通过集成多种模式的数据（包括RGB图像、深度信息等），采用深度神经网络进行数据处理和特征提取，从而提高定位精度。</p><h2 id="创新点-12" tabindex="-1"><a class="header-anchor" href="#创新点-12"><span>创新点</span></a></h2><ol><li>本文首次将多模态融合的技术应用于可见光通信领域的定位问题中。</li><li>提出了一种基于机器学习的高效算法框架，能够有效整合多种传感器输入的数据。</li><li>实验结果表明，该方法相比传统的单模式数据处理技术具有显著的优势，在实际应用中的表现尤为突出。</li></ol><h2 id="结论-12" tabindex="-1"><a class="header-anchor" href="#结论-12"><span>结论</span></a></h2><p>本研究通过采用多模态融合技术和机器学习方法实现了高精度的LED可见光定位系统。实验结果显示，这种方法在复杂环境下的鲁棒性和抗干扰能力得到了显著提升。未来的工作将进一步优化算法模型，并探索更多应用场景的可能性。</p><h2 id="原文链接-12" tabindex="-1"><a class="header-anchor" href="#原文链接-12"><span>原文链接</span></a></h2><p>https://www.opticsjournal.net/Articles/OJ55bb9f01d9671f19/FullText</p><h1 id="智能农业联合收割机自主导航系统的设计与测试" tabindex="-1"><a class="header-anchor" href="#智能农业联合收割机自主导航系统的设计与测试"><span>智能农业联合收割机自主导航系统的设计与测试</span></a></h1><h2 id="关键词-11" tabindex="-1"><a class="header-anchor" href="#关键词-11"><span>关键词：</span></a></h2><p>智能农业；联合收割机；自动导航系统</p><h2 id="研究问题-13" tabindex="-1"><a class="header-anchor" href="#研究问题-13"><span>研究问题：</span></a></h2><p>如何设计并实现一种基于北斗卫星定位的联合收割机自动导航系统，使其能够完成田间作业中的自主导航和定位。</p><h2 id="方法-13" tabindex="-1"><a class="header-anchor" href="#方法-13"><span>方法：</span></a></h2><p>本文提出了一种基于北斗卫星定位系统的联合收割机自动导航系统设计方案。该方案结合了惯性导航系统和视觉导航系统，实现了联合收割机在田间作业时的自主导航与定位功能。通过将系统应用于实际农业操作中（包括小麦、玉米收获等任务），验证其性能。</p><h2 id="创新点-13" tabindex="-1"><a class="header-anchor" href="#创新点-13"><span>创新点：</span></a></h2><ol><li>设计了一种基于北斗卫星定位系统的联合收割机自动导航系统。</li><li>该系统结合了惯性导航系统和视觉导航系统，提高了导航精度与稳定性。</li></ol><h2 id="结论-13" tabindex="-1"><a class="header-anchor" href="#结论-13"><span>结论：</span></a></h2><p>实验结果表明，所设计的联合收割机自主导航系统能够有效地实现高精度、稳定的自主导航与定位功能。这为智能农业技术的应用提供了有效的技术支持。</p><h2 id="原文链接-13" tabindex="-1"><a class="header-anchor" href="#原文链接-13"><span>原文链接</span></a></h2><p>https://www.aeeisp.com/njhyj/en/article/pdf/preview/10.13427/j.cnki.njyi.20240604.001.pdf</p><h1 id="基于双频wi-fi信号测量的室内定位中的信号融合学习方法" tabindex="-1"><a class="header-anchor" href="#基于双频wi-fi信号测量的室内定位中的信号融合学习方法"><span>基于双频Wi-Fi信号测量的室内定位中的信号融合学习方法</span></a></h1><h2 id="关键词-12" tabindex="-1"><a class="header-anchor" href="#关键词-12"><span>关键词</span></a></h2><p>双频Wi-Fi信号，室内定位，信号融合，机器学习</p><h2 id="研究问题-14" tabindex="-1"><a class="header-anchor" href="#研究问题-14"><span>研究问题</span></a></h2><p>如何有效地利用2.4GHz和5GHz双频Wi-Fi信号进行室内定位，并提高定位精度？</p><h2 id="方法-14" tabindex="-1"><a class="header-anchor" href="#方法-14"><span>方法</span></a></h2><p>本文提出了一种基于双频Wi-Fi信号的室内定位方法。首先收集了在不同环境下的2.4GHz和5GHz Wi-Fi信号强度数据，然后通过机器学习算法对这些信号进行了融合处理。研究中使用了多种机器学习模型进行比较实验，最终选择了性能最佳的方法。</p><h2 id="创新点-14" tabindex="-1"><a class="header-anchor" href="#创新点-14"><span>创新点</span></a></h2><ol><li>针对双频Wi-Fi信号的特点设计了一种新的室内定位方法。</li><li>提出了一种有效的信号融合技术来提高定位精度。</li><li>通过大量数据验证了所提方法的有效性和鲁棒性。</li></ol><h2 id="结论-14" tabindex="-1"><a class="header-anchor" href="#结论-14"><span>结论</span></a></h2><p>本文提出的方法能够有效利用双频Wi-Fi信号进行室内定位，并且在实验中表现出较高的精度。这为未来的室内定位研究提供了新的思路和方向。</p><h2 id="原文链接-14" tabindex="-1"><a class="header-anchor" href="#原文链接-14"><span>原文链接</span></a></h2><p>https://www.sciencedirect.com/science/article/pii/S2542660524003767</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: zhangleilikejay@gmail.com">zhanglei</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/papers/20241122_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241122_室内定位"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>20241122_室内定位</span></div></a><a class="route-link auto-link next" href="/papers/20241129_%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D.html" aria-label="20241129_室内定位"><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>20241129_室内定位</span></div></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-DmZfg1in.js" defer></script>
  </body>
</html>
